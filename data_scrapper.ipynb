{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ipdb\n",
    "import wget\n",
    "import os\n",
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.loads(\"./data/paperwithcode/papers-with-abstracts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path=\"./data/paperwithcode/\", refresh=False):\n",
    "    \n",
    "    if refresh:\n",
    "        print('Beginning file download')\n",
    "        link_all_paper_abstract = \"https://paperswithcode.com/media/about/papers-with-abstracts.json.gz\"\n",
    "\n",
    "        # check if there is a directory data/paperwithcode\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            \n",
    "        # downloading the file, and saving into our path    \n",
    "        wget.download(link_all_paper_abstract, path+'papers-with-abstracts.json')\n",
    "        print('Download complete')\n",
    "        \n",
    "    # Loading the data from json (deserialization)\n",
    "    with open(path+\"papers-with-abstracts.json\", \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(path=\"./data/paperwithcode/\", refresh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper_url': 'https://paperswithcode.com/paper/construction-inspection-through-spatial',\n",
       " 'arxiv_id': '1611.03566',\n",
       " 'title': 'Construction Inspection through Spatial Database',\n",
       " 'abstract': 'This paper presents a novel pipeline for development of an efficient set of\\ntools for extracting information from the video of a structure, captured by an\\nUnmanned Aircraft System (UAS) to produce as-built documentation to aid\\ninspection of large multi-storied building during construction. Our system uses\\nthe output from a Simultaneous Localization and Mapping system and a 3D CAD\\nmodel of the structure in order to construct a spatial database to store images\\ninto the 3D CAD model space. This allows the user to perform a spatial query\\nfor images through spatial indexing into the 3D CAD model space. The image\\nreturned by the spatial query is used to extract metric information. The\\nspatial database is also used to generate a 3D textured model which provides a\\nvisual as-built documentation.',\n",
       " 'url_abs': 'http://arxiv.org/abs/1611.03566v3',\n",
       " 'url_pdf': 'http://arxiv.org/pdf/1611.03566v3.pdf',\n",
       " 'proceeding': None,\n",
       " 'authors': ['Ahmad Hasan', 'Ashraf Qadir', 'Ian Nordeng', 'Jeremiah Neubert'],\n",
       " 'tasks': ['Simultaneous Localization and Mapping'],\n",
       " 'date': '2016-11-11'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http:', '', 'arxiv.org', 'pdf', '1611.03566v3.pdf']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'http://arxiv.org/pdf/1611.03566v3.pdf'.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/paperwithcode/1611.03566v3.pdf.Construction_Inspection_through_Spatial_Database.pdf'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query for a paper of interest, then download\n",
    "# paper = arxiv.query(id_list=[\"1707.08567\"])[0]\n",
    "# arxiv.download(paper)\n",
    "\n",
    "# You can skip the query step if you have the paper info!\n",
    "paper2 = {\"pdf_url\": \"http://arxiv.org/pdf/1611.03566v3.pdf\",\n",
    "          \"title\": 'Construction Inspection through Spatial Database'}\n",
    "\n",
    "arxiv.download(paper2, dirpath=\"./data/paperwithcode/\")\n",
    "# for arxiv_id : None\n",
    "# wget.download(\"https://www.researchgate.net/profile/Madson_Dias/publication/328819483_Optimally_Selected_Minimal_Learning_Machine/links/5d7a605e4585157fde0fce53/Optimally-Selected-Minimal-Learning-Machine.pdf\",'./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdirpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mslugify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mslugify\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f54ed116950\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprefer_source_tarfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslugify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslugify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefer_source_tarfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Download the .pdf corresponding to the result object 'obj'. If prefer_source_tarfile==True, download the source .tar.gz instead.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pdf_url'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Object has no PDF URL.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mdirpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdirpath\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mprefer_source_tarfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/pdf/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/src/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pdf_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mslugify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.tar.gz'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pdf_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mslugify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pdf'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/orkg/lib/python3.6/site-packages/arxiv/arxiv.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arxiv.download??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Construction_Inspection_through_Spatial_Database'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/paperwithcode//N16-1106.pdf'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download('https://www.aclweb.org/anthology/N16-1106.pdf', \"./data/paperwithcode/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper_url': 'https://paperswithcode.com/paper/dag-structured-long-short-term-memory-for',\n",
       " 'arxiv_id': None,\n",
       " 'title': 'DAG-Structured Long Short-Term Memory for Semantic Compositionality',\n",
       " 'abstract': '',\n",
       " 'url_abs': 'https://www.aclweb.org/anthology/N16-1106/',\n",
       " 'url_pdf': 'https://www.aclweb.org/anthology/N16-1106',\n",
       " 'proceeding': 'NAACL 2016 6',\n",
       " 'authors': ['Xiaodan Zhu', 'Parinaz Sobhani', 'Hongyu Guo'],\n",
       " 'tasks': ['Machine Translation',\n",
       "  'Semantic Composition',\n",
       "  'Sentiment Analysis',\n",
       "  'Speech Recognition'],\n",
       " 'date': '2016-06-01'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download(path + pdf_url, \"./data/paperwithcode/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Topic Models, ello'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data_fom_json(path, data, download_pdf = False):\n",
    "    \"\"\"\n",
    "    This function will help to save in text form, depening to the book and verse argument \n",
    "    given in parameter\n",
    "    \n",
    "    The data is maintly taken from the website https://www.jw.org/\n",
    "    \"\"\"\n",
    "    \n",
    "    for d in data:\n",
    "        \n",
    "        pdf_url = d['url_pdf']\n",
    "        tasks = d['tasks']\n",
    "        \n",
    "        title = d['title']\n",
    "            \n",
    "        if tasks == []:\n",
    "            tasks = \"N/A\"\n",
    "        else:\n",
    "            tasks = ', '.join(tasks)\n",
    "            \n",
    "        if len(pdf_url.split('.pdf')) != 2:\n",
    "            if pdf_url[-1] == '/':\n",
    "                pdf_url = pdf_url[:-1]+'.pdf'                \n",
    "            \n",
    "        # for arxiv_id : None\n",
    "        if download_pdf:\n",
    "            if d['arxiv_id'] != \"\":\n",
    "            \n",
    "                paper = {\"pdf_url\": pdf_url,\n",
    "                    \"title\": title}\n",
    "                \n",
    "                if not os.path.exists(path+\"pdf/\"):\n",
    "                    os.makedirs(path+\"pdf/\")\n",
    "\n",
    "                arxiv.download(pdf_url,\n",
    "                                   dirpath = path+\"pdf/\")\n",
    "            \n",
    "            else:\n",
    "                wget.download(pdf_url, \n",
    "                                  path+\"pdf/\")       \n",
    "        \n",
    "        try :\n",
    "            \n",
    "            if d['arxiv_id'] != \"\":\n",
    "                path_save = path+pdf_url.split('/')[-1]+'.'+'_'.join(title.split())+'.pdf'\n",
    "            else:\n",
    "                path_save = path+pdf_url.split('/')[-1]\n",
    "            \n",
    "            ipdb.set_trace()\n",
    "            with open(path+\"all_data.txt\", \"a\") as text_file:\n",
    "                text_file.write(path_save+\" \"+tasks+\"\\n\")\n",
    "\n",
    "        except Exception as inst:      \n",
    "            traceback.print_exc()\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_data_fom_json(\"./data/paperwithcode/\", data, download_pdf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orkg",
   "language": "python",
   "name": "orkg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
