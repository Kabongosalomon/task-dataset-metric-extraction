 true	1611.06624v3.pdf#2	YahooCQA; P@1	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	YahooCQA; P@1	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	YahooCQA; P@1	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	YahooCQA; P@1	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Human3.6M; MAR, walking, 400ms	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Human3.6M; MAR, walking, 400ms	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Human3.6M; MAR, walking, 400ms	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Human3.6M; MAR, walking, 400ms	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	NYU Depth v2; Mean IoU	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	NYU Depth v2; Mean IoU	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	NYU Depth v2; Mean IoU	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	NYU Depth v2; Mean IoU	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Atari 2600 Pooyan; Score	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Atari 2600 Pooyan; Score	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Atari 2600 Pooyan; Score	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Atari 2600 Pooyan; Score	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	CUB-200-2011 - 0-Shot; Top-1 Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	CUB-200-2011 - 0-Shot; Top-1 Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	CUB-200-2011 - 0-Shot; Top-1 Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	CUB-200-2011 - 0-Shot; Top-1 Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	USA Air-Traffic; Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	USA Air-Traffic; Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	USA Air-Traffic; Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	USA Air-Traffic; Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	SHREC 2017 track on 3D Hand Gesture Recognition; Speed  (FPS)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	SHREC 2017 track on 3D Hand Gesture Recognition; Speed  (FPS)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	SHREC 2017 track on 3D Hand Gesture Recognition; Speed  (FPS)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	SHREC 2017 track on 3D Hand Gesture Recognition; Speed  (FPS)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	UCF-101 16 frames, Unconditional, Single GPU; Inception Score	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	UCF-101 16 frames, Unconditional, Single GPU; Inception Score	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	UCF-101 16 frames, Unconditional, Single GPU; Inception Score	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	UCF-101 16 frames, Unconditional, Single GPU; Inception Score	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	JHMDB Pose Tracking; PCK@0.5	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	JHMDB Pose Tracking; PCK@0.5	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	JHMDB Pose Tracking; PCK@0.5	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	JHMDB Pose Tracking; PCK@0.5	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	JHMDB Pose Tracking; PCK@0.4	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	JHMDB Pose Tracking; PCK@0.4	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	JHMDB Pose Tracking; PCK@0.4	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	JHMDB Pose Tracking; PCK@0.4	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	JHMDB Pose Tracking; PCK@0.3	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	JHMDB Pose Tracking; PCK@0.3	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	JHMDB Pose Tracking; PCK@0.3	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	JHMDB Pose Tracking; PCK@0.3	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Oxford 102 Flowers; PARAMS	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Oxford 102 Flowers; PARAMS	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Oxford 102 Flowers; PARAMS	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Oxford 102 Flowers; PARAMS	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; Jaccard (Decay)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; Jaccard (Decay)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; Jaccard (Decay)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; Jaccard (Decay)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	JHMDB Pose Tracking; PCK@0.2	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	JHMDB Pose Tracking; PCK@0.2	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	JHMDB Pose Tracking; PCK@0.2	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	JHMDB Pose Tracking; PCK@0.2	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	JHMDB Pose Tracking; PCK@0.1	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	JHMDB Pose Tracking; PCK@0.1	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	JHMDB Pose Tracking; PCK@0.1	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	JHMDB Pose Tracking; PCK@0.1	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	COCO test-challenge; ARL	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	COCO test-challenge; ARL	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	COCO test-challenge; ARL	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	COCO test-challenge; ARL	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2017 (test-dev); Jaccard (Decay)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2017 (test-dev); Jaccard (Decay)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2017 (test-dev); Jaccard (Decay)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2017 (test-dev); Jaccard (Decay)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	COCO test-challenge; ARM	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	COCO test-challenge; ARM	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	COCO test-challenge; ARM	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	COCO test-challenge; ARM	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; F-measure (Decay)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; F-measure (Decay)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; F-measure (Decay)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; F-measure (Decay)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	CRAG; Dice	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	CRAG; Dice	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	CRAG; Dice	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	CRAG; Dice	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Caltech-256 5-way (1-shot); Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Caltech-256 5-way (1-shot); Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Caltech-256 5-way (1-shot); Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Caltech-256 5-way (1-shot); Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	SemEval 2007 Task 17; F1	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	SemEval 2007 Task 17; F1	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	SemEval 2007 Task 17; F1	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	SemEval 2007 Task 17; F1	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	ImageNet; Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	ImageNet; Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	ImageNet; Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	ImageNet; Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Tiny-ImageNet; Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Tiny-ImageNet; Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Tiny-ImageNet; Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Tiny-ImageNet; Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	CIFAR-10; Search Time (GPU days)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	CIFAR-10; Search Time (GPU days)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	CIFAR-10; Search Time (GPU days)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	CIFAR-10; Search Time (GPU days)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	WikiBio; BLEU	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	WikiBio; BLEU	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	WikiBio; BLEU	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	WikiBio; BLEU	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	KITTI Pedestrians Hard; AP	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	KITTI Pedestrians Hard; AP	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	KITTI Pedestrians Hard; AP	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	KITTI Pedestrians Hard; AP	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	EUR-Lex; P@5	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	EUR-Lex; P@5	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	EUR-Lex; P@5	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	EUR-Lex; P@5	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	WIDER Face (Medium); AP	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	WIDER Face (Medium); AP	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	WIDER Face (Medium); AP	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	WIDER Face (Medium); AP	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	UCF-101 16 frames, 64x64, Unconditional; Inception Score	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	UCF-101 16 frames, 64x64, Unconditional; Inception Score	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	UCF-101 16 frames, 64x64, Unconditional; Inception Score	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	UCF-101 16 frames, 64x64, Unconditional; Inception Score	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Atari 2600 Private Eye; Score	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Atari 2600 Private Eye; Score	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Atari 2600 Private Eye; Score	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Atari 2600 Private Eye; Score	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	VisDial v0.9 val; R@10	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	VisDial v0.9 val; R@10	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	VisDial v0.9 val; R@10	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	VisDial v0.9 val; R@10	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; F-measure (Mean)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; F-measure (Mean)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; F-measure (Mean)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; F-measure (Mean)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; F-measure (Recall)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; F-measure (Recall)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; F-measure (Recall)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; F-measure (Recall)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	FC100 5-way (5-shot); Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	FC100 5-way (5-shot); Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	FC100 5-way (5-shot); Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	FC100 5-way (5-shot); Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	YouTube; mIoU	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	YouTube; mIoU	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	YouTube; mIoU	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	YouTube; mIoU	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	ActivityNet-1.3; mAP@0.5	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	ActivityNet-1.3; mAP@0.5	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	ActivityNet-1.3; mAP@0.5	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	ActivityNet-1.3; mAP@0.5	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	COCO test-challenge; APL	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	COCO test-challenge; APL	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	COCO test-challenge; APL	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	COCO test-challenge; APL	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	CoNLL Dutch; F1	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	CoNLL Dutch; F1	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	CoNLL Dutch; F1	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	CoNLL Dutch; F1	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Florence 3D; Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Florence 3D; Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Florence 3D; Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Florence 3D; Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Ultra Video Group HD - 4x upscaling; Average PSNR	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Ultra Video Group HD - 4x upscaling; Average PSNR	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Ultra Video Group HD - 4x upscaling; Average PSNR	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Ultra Video Group HD - 4x upscaling; Average PSNR	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	WikiHop; Test	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	WikiHop; Test	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	WikiHop; Test	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	WikiHop; Test	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	YAGO3-10; Hits@1	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	YAGO3-10; Hits@1	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	YAGO3-10; Hits@1	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	YAGO3-10; Hits@1	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DBLP (PACT) 14k; Macro-F1 (60% training data)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DBLP (PACT) 14k; Macro-F1 (60% training data)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DBLP (PACT) 14k; Macro-F1 (60% training data)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DBLP (PACT) 14k; Macro-F1 (60% training data)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	MLDoc Zero-Shot English-to-Chinese; Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	MLDoc Zero-Shot English-to-Chinese; Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	MLDoc Zero-Shot English-to-Chinese; Accuracy	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	MLDoc Zero-Shot English-to-Chinese; Accuracy	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	WikiQA; MRR	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	WikiQA; MRR	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	WikiQA; MRR	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	WikiQA; MRR	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Cityscapes test; PQ	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Cityscapes test; PQ	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Cityscapes test; PQ	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Cityscapes test; PQ	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; Jaccard (Recall)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; Jaccard (Recall)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; Jaccard (Recall)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; Jaccard (Recall)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; J&F	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; J&F	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; J&F	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; J&F	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	FGVC Aircraft; FLOPS	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	FGVC Aircraft; FLOPS	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	FGVC Aircraft; FLOPS	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	FGVC Aircraft; FLOPS	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Set14 - 4x upscaling; MOS	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Set14 - 4x upscaling; MOS	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Set14 - 4x upscaling; MOS	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Set14 - 4x upscaling; MOS	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	GTEA; Edit	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	GTEA; Edit	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	GTEA; Edit	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	GTEA; Edit	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	ActEV; mAP	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	ActEV; mAP	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	ActEV; mAP	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	ActEV; mAP	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	WN18RR; MR	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	WN18RR; MR	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	WN18RR; MR	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	WN18RR; MR	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	MSCOCO; Frame (fps)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	MSCOCO; Frame (fps)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	MSCOCO; Frame (fps)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	MSCOCO; Frame (fps)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	VQA-CP; Score	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	VQA-CP; Score	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	VQA-CP; Score	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	VQA-CP; Score	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Total-Text; Precision	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Total-Text; Precision	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Total-Text; Precision	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Total-Text; Precision	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; Jaccard (Mean)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	DAVIS 2016; Jaccard (Mean)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; Jaccard (Mean)	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	DAVIS 2016; Jaccard (Mean)	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Cityscapes Labels-to-Photo; FID	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#2	Cityscapes Labels-to-Photo; FID	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Cityscapes Labels-to-Photo; FID	Image generator z t  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	1611.06624v3.pdf#4	Cityscapes Labels-to-Photo; FID	Image generator ? R 100  Table 1. Network configuration of the generator. The second row  represents the input variables. "linear (�)" is the number of output  units in the linear layer. The parameters in the convolutional and  the deconvolutional layer are denoted as "conv/deconv ((kernel  size), (output channels), (padding), (strides))."
true	2002.03651v4.pdf#68.6%	YahooCQA; P@1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	YahooCQA; P@1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	YahooCQA; P@1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	YahooCQA; P@1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	YahooCQA; P@1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	YahooCQA; P@1	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Human3.6M; MAR, walking, 400ms	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Human3.6M; MAR, walking, 400ms	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Human3.6M; MAR, walking, 400ms	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Human3.6M; MAR, walking, 400ms	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Human3.6M; MAR, walking, 400ms	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Human3.6M; MAR, walking, 400ms	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	NYU Depth v2; Mean IoU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	NYU Depth v2; Mean IoU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	NYU Depth v2; Mean IoU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	NYU Depth v2; Mean IoU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	NYU Depth v2; Mean IoU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	NYU Depth v2; Mean IoU	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Atari 2600 Pooyan; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Atari 2600 Pooyan; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Atari 2600 Pooyan; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Atari 2600 Pooyan; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Atari 2600 Pooyan; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Atari 2600 Pooyan; Score	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	CUB-200-2011 - 0-Shot; Top-1 Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	CUB-200-2011 - 0-Shot; Top-1 Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	CUB-200-2011 - 0-Shot; Top-1 Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	CUB-200-2011 - 0-Shot; Top-1 Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	CUB-200-2011 - 0-Shot; Top-1 Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	CUB-200-2011 - 0-Shot; Top-1 Accuracy	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	USA Air-Traffic; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	USA Air-Traffic; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	USA Air-Traffic; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	USA Air-Traffic; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	USA Air-Traffic; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	USA Air-Traffic; Accuracy	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	SHREC 2017 track on 3D Hand Gesture Recognition; Speed  (FPS)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	SHREC 2017 track on 3D Hand Gesture Recognition; Speed  (FPS)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	SHREC 2017 track on 3D Hand Gesture Recognition; Speed  (FPS)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	SHREC 2017 track on 3D Hand Gesture Recognition; Speed  (FPS)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	SHREC 2017 track on 3D Hand Gesture Recognition; Speed  (FPS)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	SHREC 2017 track on 3D Hand Gesture Recognition; Speed  (FPS)	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	UCF-101 16 frames, Unconditional, Single GPU; Inception Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	UCF-101 16 frames, Unconditional, Single GPU; Inception Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	UCF-101 16 frames, Unconditional, Single GPU; Inception Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	UCF-101 16 frames, Unconditional, Single GPU; Inception Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	UCF-101 16 frames, Unconditional, Single GPU; Inception Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	UCF-101 16 frames, Unconditional, Single GPU; Inception Score	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	JHMDB Pose Tracking; PCK@0.5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	JHMDB Pose Tracking; PCK@0.5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	JHMDB Pose Tracking; PCK@0.5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	JHMDB Pose Tracking; PCK@0.5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	JHMDB Pose Tracking; PCK@0.5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	JHMDB Pose Tracking; PCK@0.5	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	JHMDB Pose Tracking; PCK@0.4	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	JHMDB Pose Tracking; PCK@0.4	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	JHMDB Pose Tracking; PCK@0.4	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	JHMDB Pose Tracking; PCK@0.4	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	JHMDB Pose Tracking; PCK@0.4	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	JHMDB Pose Tracking; PCK@0.4	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	JHMDB Pose Tracking; PCK@0.3	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	JHMDB Pose Tracking; PCK@0.3	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	JHMDB Pose Tracking; PCK@0.3	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	JHMDB Pose Tracking; PCK@0.3	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	JHMDB Pose Tracking; PCK@0.3	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	JHMDB Pose Tracking; PCK@0.3	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Oxford 102 Flowers; PARAMS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Oxford 102 Flowers; PARAMS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Oxford 102 Flowers; PARAMS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Oxford 102 Flowers; PARAMS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Oxford 102 Flowers; PARAMS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Oxford 102 Flowers; PARAMS	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	DAVIS 2016; Jaccard (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	DAVIS 2016; Jaccard (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	DAVIS 2016; Jaccard (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	DAVIS 2016; Jaccard (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	DAVIS 2016; Jaccard (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	DAVIS 2016; Jaccard (Decay)	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	JHMDB Pose Tracking; PCK@0.2	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	JHMDB Pose Tracking; PCK@0.2	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	JHMDB Pose Tracking; PCK@0.2	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	JHMDB Pose Tracking; PCK@0.2	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	JHMDB Pose Tracking; PCK@0.2	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	JHMDB Pose Tracking; PCK@0.2	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	JHMDB Pose Tracking; PCK@0.1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	JHMDB Pose Tracking; PCK@0.1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	JHMDB Pose Tracking; PCK@0.1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	JHMDB Pose Tracking; PCK@0.1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	JHMDB Pose Tracking; PCK@0.1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	JHMDB Pose Tracking; PCK@0.1	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	COCO test-challenge; ARL	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	COCO test-challenge; ARL	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	COCO test-challenge; ARL	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	COCO test-challenge; ARL	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	COCO test-challenge; ARL	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	COCO test-challenge; ARL	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	DAVIS 2017 (test-dev); Jaccard (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	DAVIS 2017 (test-dev); Jaccard (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	DAVIS 2017 (test-dev); Jaccard (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	DAVIS 2017 (test-dev); Jaccard (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	DAVIS 2017 (test-dev); Jaccard (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	DAVIS 2017 (test-dev); Jaccard (Decay)	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	COCO test-challenge; ARM	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	COCO test-challenge; ARM	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	COCO test-challenge; ARM	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	COCO test-challenge; ARM	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	COCO test-challenge; ARM	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	COCO test-challenge; ARM	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	DAVIS 2016; F-measure (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	DAVIS 2016; F-measure (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	DAVIS 2016; F-measure (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	DAVIS 2016; F-measure (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	DAVIS 2016; F-measure (Decay)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	DAVIS 2016; F-measure (Decay)	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	CRAG; Dice	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	CRAG; Dice	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	CRAG; Dice	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	CRAG; Dice	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	CRAG; Dice	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	CRAG; Dice	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Caltech-256 5-way (1-shot); Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Caltech-256 5-way (1-shot); Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Caltech-256 5-way (1-shot); Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Caltech-256 5-way (1-shot); Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Caltech-256 5-way (1-shot); Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Caltech-256 5-way (1-shot); Accuracy	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	SemEval 2007 Task 17; F1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	SemEval 2007 Task 17; F1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	SemEval 2007 Task 17; F1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	SemEval 2007 Task 17; F1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	SemEval 2007 Task 17; F1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	SemEval 2007 Task 17; F1	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	ImageNet; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	ImageNet; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	ImageNet; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	ImageNet; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	ImageNet; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	ImageNet; Accuracy	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Tiny-ImageNet; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Tiny-ImageNet; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Tiny-ImageNet; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Tiny-ImageNet; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Tiny-ImageNet; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Tiny-ImageNet; Accuracy	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	CIFAR-10; Search Time (GPU days)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	CIFAR-10; Search Time (GPU days)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	CIFAR-10; Search Time (GPU days)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	CIFAR-10; Search Time (GPU days)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	CIFAR-10; Search Time (GPU days)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	CIFAR-10; Search Time (GPU days)	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	WikiBio; BLEU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	WikiBio; BLEU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	WikiBio; BLEU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	WikiBio; BLEU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	WikiBio; BLEU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	WikiBio; BLEU	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	KITTI Pedestrians Hard; AP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	KITTI Pedestrians Hard; AP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	KITTI Pedestrians Hard; AP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	KITTI Pedestrians Hard; AP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	KITTI Pedestrians Hard; AP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	KITTI Pedestrians Hard; AP	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	EUR-Lex; P@5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	EUR-Lex; P@5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	EUR-Lex; P@5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	EUR-Lex; P@5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	EUR-Lex; P@5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	EUR-Lex; P@5	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	WIDER Face (Medium); AP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	WIDER Face (Medium); AP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	WIDER Face (Medium); AP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	WIDER Face (Medium); AP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	WIDER Face (Medium); AP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	WIDER Face (Medium); AP	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	UCF-101 16 frames, 64x64, Unconditional; Inception Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	UCF-101 16 frames, 64x64, Unconditional; Inception Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	UCF-101 16 frames, 64x64, Unconditional; Inception Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	UCF-101 16 frames, 64x64, Unconditional; Inception Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	UCF-101 16 frames, 64x64, Unconditional; Inception Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	UCF-101 16 frames, 64x64, Unconditional; Inception Score	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Atari 2600 Private Eye; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Atari 2600 Private Eye; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Atari 2600 Private Eye; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Atari 2600 Private Eye; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Atari 2600 Private Eye; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Atari 2600 Private Eye; Score	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	VisDial v0.9 val; R@10	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	VisDial v0.9 val; R@10	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	VisDial v0.9 val; R@10	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	VisDial v0.9 val; R@10	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	VisDial v0.9 val; R@10	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	VisDial v0.9 val; R@10	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	DAVIS 2016; F-measure (Mean)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	DAVIS 2016; F-measure (Mean)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	DAVIS 2016; F-measure (Mean)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	DAVIS 2016; F-measure (Mean)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	DAVIS 2016; F-measure (Mean)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	DAVIS 2016; F-measure (Mean)	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	DAVIS 2016; F-measure (Recall)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	DAVIS 2016; F-measure (Recall)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	DAVIS 2016; F-measure (Recall)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	DAVIS 2016; F-measure (Recall)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	DAVIS 2016; F-measure (Recall)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	DAVIS 2016; F-measure (Recall)	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	FC100 5-way (5-shot); Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	FC100 5-way (5-shot); Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	FC100 5-way (5-shot); Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	FC100 5-way (5-shot); Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	FC100 5-way (5-shot); Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	FC100 5-way (5-shot); Accuracy	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	YouTube; mIoU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	YouTube; mIoU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	YouTube; mIoU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	YouTube; mIoU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	YouTube; mIoU	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	YouTube; mIoU	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	ActivityNet-1.3; mAP@0.5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	ActivityNet-1.3; mAP@0.5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	ActivityNet-1.3; mAP@0.5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	ActivityNet-1.3; mAP@0.5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	ActivityNet-1.3; mAP@0.5	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	ActivityNet-1.3; mAP@0.5	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	COCO test-challenge; APL	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	COCO test-challenge; APL	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	COCO test-challenge; APL	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	COCO test-challenge; APL	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	COCO test-challenge; APL	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	COCO test-challenge; APL	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	CoNLL Dutch; F1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	CoNLL Dutch; F1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	CoNLL Dutch; F1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	CoNLL Dutch; F1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	CoNLL Dutch; F1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	CoNLL Dutch; F1	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Florence 3D; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Florence 3D; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Florence 3D; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Florence 3D; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Florence 3D; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Florence 3D; Accuracy	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Ultra Video Group HD - 4x upscaling; Average PSNR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Ultra Video Group HD - 4x upscaling; Average PSNR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Ultra Video Group HD - 4x upscaling; Average PSNR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Ultra Video Group HD - 4x upscaling; Average PSNR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Ultra Video Group HD - 4x upscaling; Average PSNR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Ultra Video Group HD - 4x upscaling; Average PSNR	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	WikiHop; Test	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	WikiHop; Test	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	WikiHop; Test	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	WikiHop; Test	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	WikiHop; Test	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	WikiHop; Test	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	YAGO3-10; Hits@1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	YAGO3-10; Hits@1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	YAGO3-10; Hits@1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	YAGO3-10; Hits@1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	YAGO3-10; Hits@1	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	YAGO3-10; Hits@1	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	DBLP (PACT) 14k; Macro-F1 (60% training data)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	DBLP (PACT) 14k; Macro-F1 (60% training data)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	DBLP (PACT) 14k; Macro-F1 (60% training data)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	DBLP (PACT) 14k; Macro-F1 (60% training data)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	DBLP (PACT) 14k; Macro-F1 (60% training data)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	DBLP (PACT) 14k; Macro-F1 (60% training data)	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	MLDoc Zero-Shot English-to-Chinese; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	MLDoc Zero-Shot English-to-Chinese; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	MLDoc Zero-Shot English-to-Chinese; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	MLDoc Zero-Shot English-to-Chinese; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	MLDoc Zero-Shot English-to-Chinese; Accuracy	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	MLDoc Zero-Shot English-to-Chinese; Accuracy	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	WikiQA; MRR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	WikiQA; MRR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	WikiQA; MRR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	WikiQA; MRR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	WikiQA; MRR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	WikiQA; MRR	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Cityscapes test; PQ	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Cityscapes test; PQ	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Cityscapes test; PQ	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Cityscapes test; PQ	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Cityscapes test; PQ	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Cityscapes test; PQ	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	DAVIS 2016; Jaccard (Recall)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	DAVIS 2016; Jaccard (Recall)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	DAVIS 2016; Jaccard (Recall)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	DAVIS 2016; Jaccard (Recall)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	DAVIS 2016; Jaccard (Recall)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	DAVIS 2016; Jaccard (Recall)	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	DAVIS 2016; J&F	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	DAVIS 2016; J&F	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	DAVIS 2016; J&F	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	DAVIS 2016; J&F	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	DAVIS 2016; J&F	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	DAVIS 2016; J&F	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	FGVC Aircraft; FLOPS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	FGVC Aircraft; FLOPS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	FGVC Aircraft; FLOPS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	FGVC Aircraft; FLOPS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	FGVC Aircraft; FLOPS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	FGVC Aircraft; FLOPS	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Set14 - 4x upscaling; MOS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Set14 - 4x upscaling; MOS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Set14 - 4x upscaling; MOS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Set14 - 4x upscaling; MOS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Set14 - 4x upscaling; MOS	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Set14 - 4x upscaling; MOS	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	GTEA; Edit	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	GTEA; Edit	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	GTEA; Edit	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	GTEA; Edit	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	GTEA; Edit	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	GTEA; Edit	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	ActEV; mAP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	ActEV; mAP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	ActEV; mAP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	ActEV; mAP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	ActEV; mAP	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	ActEV; mAP	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	WN18RR; MR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	WN18RR; MR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	WN18RR; MR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	WN18RR; MR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	WN18RR; MR	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	WN18RR; MR	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	MSCOCO; Frame (fps)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	MSCOCO; Frame (fps)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	MSCOCO; Frame (fps)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	MSCOCO; Frame (fps)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	MSCOCO; Frame (fps)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	MSCOCO; Frame (fps)	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	VQA-CP; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	VQA-CP; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	VQA-CP; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	VQA-CP; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	VQA-CP; Score	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	VQA-CP; Score	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Total-Text; Precision	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Total-Text; Precision	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Total-Text; Precision	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Total-Text; Precision	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Total-Text; Precision	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Total-Text; Precision	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	DAVIS 2016; Jaccard (Mean)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	DAVIS 2016; Jaccard (Mean)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	DAVIS 2016; Jaccard (Mean)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	DAVIS 2016; Jaccard (Mean)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	DAVIS 2016; Jaccard (Mean)	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	DAVIS 2016; Jaccard (Mean)	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#68.6%	Cityscapes Labels-to-Photo; FID	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.8%	Cityscapes Labels-to-Photo; FID	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#55.0	Cityscapes Labels-to-Photo; FID	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . fps  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#64.7%	Cityscapes Labels-to-Photo; FID	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . J ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#71.3%	Cityscapes Labels-to-Photo; FID	Evaluation ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
true	2002.03651v4.pdf#3.1.	Cityscapes Labels-to-Photo; FID	of the entire targets are generated , and then overlapped . ( 0 . 75?1 . 25 ) for data augmentation in fine - tuning stage . 3 . F ?  Table 3: Ablation studies on DAVIS 2016 validation set. RM  indicates using our novel refine modules instead of general  ones. PM indicates using previous frame's coarse mask as a  specifier, and Clue indicates using the Clue as a specifier.
