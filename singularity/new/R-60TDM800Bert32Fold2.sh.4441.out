Directory ../data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold2/models/BERT/ Exist
WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From run_classifier_sci.py:1079: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From run_classifier_sci.py:865: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0620 15:52:30.884744 140061924329280 module_wrapper.py:139] From run_classifier_sci.py:865: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From run_classifier_sci.py:865: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0620 15:52:30.884960 140061924329280 module_wrapper.py:139] From run_classifier_sci.py:865: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0620 15:52:30.885375 140061924329280 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

WARNING:tensorflow:From run_classifier_sci.py:890: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W0620 15:52:30.888030 140061924329280 module_wrapper.py:139] From run_classifier_sci.py:890: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0620 15:52:30.970052 140061924329280 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f62382ea378>) includes params argument, but params are not passed to Estimator.
W0620 15:52:32.707148 140061924329280 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f62382ea378>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Using config: {'_model_dir': '../data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold2/models/BERT/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f622d5d0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}
I0620 15:52:32.708999 140061924329280 estimator.py:212] Using config: {'_model_dir': '../data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold2/models/BERT/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f622d5d0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}
INFO:tensorflow:_TPUContext: eval_on_tpu True
I0620 15:52:32.709668 140061924329280 tpu_context.py:220] _TPUContext: eval_on_tpu True
WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.
W0620 15:52:32.710176 140061924329280 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.
WARNING:tensorflow:From run_classifier_sci.py:561: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.

W0620 15:52:33.138199 140061924329280 module_wrapper.py:139] From run_classifier_sci.py:561: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.

WARNING:tensorflow:From run_classifier_sci.py:565: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0620 15:52:33.139825 140061924329280 module_wrapper.py:139] From run_classifier_sci.py:565: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Writing example 0 of 13071
I0620 15:52:33.140010 140061924329280 run_classifier_sci.py:565] Writing example 0 of 13071
INFO:tensorflow:*** Example ***
I0620 15:52:33.147218 140061924329280 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-0
I0620 15:52:33.147378 140061924329280 run_classifier_sci.py:539] guid: test-0
INFO:tensorflow:tokens: [CLS] sentiment analysis ; sub ##j ; accuracy [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 15:52:33.147629 140061924329280 run_classifier_sci.py:541] tokens: [CLS] sentiment analysis ; sub ##j ; accuracy [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 15792 4106 1025 4942 3501 1025 10640 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
I0620 15:52:33.147909 140061924329280 run_classifier_sci.py:542] input_ids: 101 15792 4106 1025 4942 3501 1025 10640 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 15:52:33.148215 140061924329280 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 15:52:33.148379 140061924329280 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 15:52:33.148444 140061924329280 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 15:52:33.155404 140061924329280 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-1
I0620 15:52:33.155508 140061924329280 run_classifier_sci.py:539] guid: test-1
INFO:tensorflow:tokens: [CLS] text classification ; tre ##c ; error [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 15:52:33.155710 140061924329280 run_classifier_sci.py:541] tokens: [CLS] text classification ; tre ##c ; error [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 3793 5579 1025 29461 2278 1025 7561 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
I0620 15:52:33.155939 140061924329280 run_classifier_sci.py:542] input_ids: 101 3793 5579 1025 29461 2278 1025 7561 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 15:52:33.156147 140061924329280 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 15:52:33.156312 140061924329280 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 15:52:33.156375 140061924329280 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 15:52:33.162948 140061924329280 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-2
I0620 15:52:33.163048 140061924329280 run_classifier_sci.py:539] guid: test-2
INFO:tensorflow:tokens: [CLS] question answering ; squad ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 15:52:33.163236 140061924329280 run_classifier_sci.py:541] tokens: [CLS] question answering ; squad ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 3160 10739 1025 4686 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0 0
I0620 15:52:33.163449 140061924329280 run_classifier_sci.py:542] input_ids: 101 3160 10739 1025 4686 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
I0620 15:52:33.163660 140061924329280 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
I0620 15:52:33.164014 140061924329280 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 15:52:33.164190 140061924329280 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 15:52:33.170923 140061924329280 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-3
I0620 15:52:33.171074 140061924329280 run_classifier_sci.py:539] guid: test-3
INFO:tensorflow:tokens: [CLS] relation prediction ; f ##b ##15 ##k - 237 ; h @ 1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 15:52:33.171314 140061924329280 run_classifier_sci.py:541] tokens: [CLS] relation prediction ; f ##b ##15 ##k - 237 ; h @ 1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 7189 17547 1025 1042 2497 16068 2243 1011 23297 1025 1044 1030 1015 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0
I0620 15:52:33.171552 140061924329280 run_classifier_sci.py:542] input_ids: 101 7189 17547 1025 1042 2497 16068 2243 1011 23297 1025 1044 1030 1015 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
I0620 15:52:33.171881 140061924329280 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
I0620 15:52:33.172074 140061924329280 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 15:52:33.172146 140061924329280 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 15:52:33.178867 140061924329280 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-4
I0620 15:52:33.178970 140061924329280 run_classifier_sci.py:539] guid: test-4
INFO:tensorflow:tokens: [CLS] word sense di ##sam ##bi ##gua ##tion ; se ##me ##val 2013 ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 15:52:33.179244 140061924329280 run_classifier_sci.py:541] tokens: [CLS] word sense di ##sam ##bi ##gua ##tion ; se ##me ##val 2013 ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 2773 3168 4487 21559 5638 19696 3508 1025 7367 4168 10175 2286 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0
I0620 15:52:33.179486 140061924329280 run_classifier_sci.py:542] input_ids: 101 2773 3168 4487 21559 5638 19696 3508 1025 7367 4168 10175 2286 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
I0620 15:52:33.179809 140061924329280 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
I0620 15:52:33.180027 140061924329280 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 15:52:33.180098 140061924329280 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:Writing example 10000 of 13071
I0620 15:53:25.896572 140061924329280 run_classifier_sci.py:565] Writing example 10000 of 13071
INFO:tensorflow:***** Running prediction*****
I0620 15:53:42.087879 140061924329280 run_classifier_sci.py:1040] ***** Running prediction*****
INFO:tensorflow:  Num examples = 13071 (13071 actual, 0 padding)
I0620 15:53:42.088499 140061924329280 run_classifier_sci.py:1043]   Num examples = 13071 (13071 actual, 0 padding)
INFO:tensorflow:  Batch size = 6
I0620 15:53:42.088937 140061924329280 run_classifier_sci.py:1044]   Batch size = 6
WARNING:tensorflow:From run_classifier_sci.py:592: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

W0620 15:53:42.090849 140061924329280 module_wrapper.py:139] From run_classifier_sci.py:592: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

INFO:tensorflow:***** Predict results *****
I0620 15:53:42.091532 140061924329280 run_classifier_sci.py:1059] ***** Predict results *****
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
W0620 15:53:42.156796 140061924329280 deprecation.py:506] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From run_classifier_sci.py:628: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.map_and_batch(...)`.
W0620 15:53:42.182938 140061924329280 deprecation.py:323] From run_classifier_sci.py:628: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.map_and_batch(...)`.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.
W0620 15:53:42.183152 140061924329280 deprecation.py:323] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0620 15:53:42.244248 140061924329280 module_wrapper.py:139] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From run_classifier_sci.py:608: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0620 15:53:42.336189 140061924329280 deprecation.py:323] From run_classifier_sci.py:608: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Calling model_fn.
I0620 15:53:42.350214 140061924329280 estimator.py:1148] Calling model_fn.
INFO:tensorflow:Running infer on CPU
I0620 15:53:42.350465 140061924329280 tpu_estimator.py:3124] Running infer on CPU
INFO:tensorflow:*** Features ***
I0620 15:53:42.350804 140061924329280 run_classifier_sci.py:708] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (?, 512)
I0620 15:53:42.350975 140061924329280 run_classifier_sci.py:710]   name = input_ids, shape = (?, 512)
INFO:tensorflow:  name = input_mask, shape = (?, 512)
I0620 15:53:42.351110 140061924329280 run_classifier_sci.py:710]   name = input_mask, shape = (?, 512)
INFO:tensorflow:  name = is_real_example, shape = (?,)
I0620 15:53:42.351234 140061924329280 run_classifier_sci.py:710]   name = is_real_example, shape = (?,)
INFO:tensorflow:  name = label_ids, shape = (?,)
I0620 15:53:42.351351 140061924329280 run_classifier_sci.py:710]   name = label_ids, shape = (?,)
INFO:tensorflow:  name = segment_ids, shape = (?, 512)
I0620 15:53:42.351468 140061924329280 run_classifier_sci.py:710]   name = segment_ids, shape = (?, 512)
WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0620 15:53:42.357228 140061924329280 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:410: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0620 15:53:42.358588 140061924329280 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:410: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:491: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.

W0620 15:53:42.382493 140061924329280 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:491: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:672: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
W0620 15:53:42.425797 140061924329280 deprecation.py:323] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:672: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W0620 15:53:42.426999 140061924329280 deprecation.py:323] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From run_classifier_sci.py:728: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0620 15:53:43.869820 140061924329280 module_wrapper.py:139] From run_classifier_sci.py:728: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From run_classifier_sci.py:742: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.

W0620 15:53:43.877677 140061924329280 module_wrapper.py:139] From run_classifier_sci.py:742: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.

INFO:tensorflow:**** Trainable Variables ****
I0620 15:53:44.336346 140061924329280 run_classifier_sci.py:744] **** Trainable Variables ****
INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*
I0620 15:53:44.336527 140061924329280 run_classifier_sci.py:750]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*
I0620 15:53:44.336706 140061924329280 run_classifier_sci.py:750]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*
I0620 15:53:44.336846 140061924329280 run_classifier_sci.py:750]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.336974 140061924329280 run_classifier_sci.py:750]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.337089 140061924329280 run_classifier_sci.py:750]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.337199 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.337315 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.337423 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.337534 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.337642 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.337753 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.337860 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.337970 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.338076 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.338180 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.338285 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.338393 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.338502 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.338612 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.338717 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.338821 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.338924 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.339034 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.339138 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.339248 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.339352 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.339461 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.339565 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.339674 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.339778 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.339896 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.340006 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.340119 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.340225 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.340335 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.340440 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.340544 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.340648 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.340758 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.340862 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.340972 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.341077 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.341186 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.341289 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.341398 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.341501 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.341605 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.341710 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.341820 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.341923 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.342033 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.342137 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.342240 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.342343 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.342451 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.342555 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.342663 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.342766 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.342875 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.342978 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.343087 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.343192 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.343297 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.343405 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.343516 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.343620 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.343730 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.343842 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.343949 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.344053 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.344163 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.344266 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.344375 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.344479 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.344587 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.344691 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.344799 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.344903 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.345009 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.345113 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.345222 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.345326 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.345435 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.345538 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.345642 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.345745 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.345854 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.345958 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.346066 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.346169 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.346278 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.346381 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.346490 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.346595 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.346700 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.346803 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.346911 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.347014 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.347122 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.347225 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.347329 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.347432 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.347540 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.347643 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.347751 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.347867 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.347981 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.348086 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.348196 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.348302 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.348407 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.348510 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.348618 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.348722 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.348831 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.348934 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.349037 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.349140 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.349249 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.349353 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.349461 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.349564 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.349672 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.349776 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.349886 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.349990 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.350094 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.350197 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.350305 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.350409 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.350517 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.350620 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.350723 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.350826 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.350934 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.351037 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.351145 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.351250 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.351357 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.351463 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.351573 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.351676 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.351778 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.351889 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.352000 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.352103 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.352212 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.352316 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.352419 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.352523 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.352631 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.352734 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.352843 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.352946 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.353055 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.353160 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.353268 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.353371 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.353474 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.353577 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.353684 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.353787 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.353895 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.353999 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.354101 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.354205 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.354314 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.354417 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.354525 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.354603 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.354660 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.354708 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.354760 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.354808 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.354856 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.354902 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.354953 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.355000 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355050 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355098 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355145 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.355191 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355242 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.355288 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355340 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.355386 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355435 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.355482 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355531 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355578 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355624 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 15:53:44.355670 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 15:53:44.355719 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 15:53:44.355765 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355815 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355891 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.355964 140061924329280 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 15:53:44.356043 140061924329280 run_classifier_sci.py:750]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 15:53:44.356138 140061924329280 run_classifier_sci.py:750]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = output_weights:0, shape = (2, 768)
I0620 15:53:44.356248 140061924329280 run_classifier_sci.py:750]   name = output_weights:0, shape = (2, 768)
INFO:tensorflow:  name = output_bias:0, shape = (2,)
I0620 15:53:44.356325 140061924329280 run_classifier_sci.py:750]   name = output_bias:0, shape = (2,)
INFO:tensorflow:Done calling model_fn.
I0620 15:53:44.356688 140061924329280 estimator.py:1150] Done calling model_fn.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0620 15:53:44.493376 140061924329280 deprecation.py:323] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
INFO:tensorflow:Graph was finalized.
I0620 15:53:44.744259 140061924329280 monitored_session.py:240] Graph was finalized.
2021-06-20 15:53:44.744621: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2021-06-20 15:53:44.784230: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2021-06-20 15:53:44.788523: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d369393530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-06-20 15:53:44.788554: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-06-20 15:53:44.793744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-06-20 15:53:45.664999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d367332850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-06-20 15:53:45.665026: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2021-06-20 15:53:45.665830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:3d:00.0
2021-06-20 15:53:45.669726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-20 15:53:45.706768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-06-20 15:53:45.727364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-06-20 15:53:45.738483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-06-20 15:53:45.782304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-06-20 15:53:45.812686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-06-20 15:53:45.896720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-06-20 15:53:45.898237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2021-06-20 15:53:45.900544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-20 15:53:45.901856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-06-20 15:53:45.901875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2021-06-20 15:53:45.901882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2021-06-20 15:53:45.904454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10320 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from ../data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold2/models/BERT/model.ckpt-23956
I0620 15:53:45.906911 140061924329280 saver.py:1284] Restoring parameters from ../data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold2/models/BERT/model.ckpt-23956
INFO:tensorflow:Running local_init_op.
I0620 15:53:50.313822 140061924329280 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0620 15:53:50.372218 140061924329280 session_manager.py:502] Done running local_init_op.
2021-06-20 15:53:51.133882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
INFO:tensorflow:prediction_loop marked as finished
I0620 15:57:33.642845 140061924329280 error_handling.py:101] prediction_loop marked as finished
INFO:tensorflow:prediction_loop marked as finished
I0620 15:57:33.643572 140061924329280 error_handling.py:101] prediction_loop marked as finished
