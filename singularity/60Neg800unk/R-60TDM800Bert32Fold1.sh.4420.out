Directory ../data/paperwithcode/60Neg800unk/60Neg800unkFold1BertBatch32 Created
WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From run_classifier_sci.py:1079: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From run_classifier_sci.py:865: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0620 00:05:32.949502 140424640927552 module_wrapper.py:139] From run_classifier_sci.py:865: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From run_classifier_sci.py:865: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0620 00:05:32.949720 140424640927552 module_wrapper.py:139] From run_classifier_sci.py:865: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0620 00:05:32.950165 140424640927552 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

WARNING:tensorflow:From run_classifier_sci.py:890: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W0620 00:05:32.952356 140424640927552 module_wrapper.py:139] From run_classifier_sci.py:890: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0620 00:05:33.032015 140424640927552 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb6abc6b2f0>) includes params argument, but params are not passed to Estimator.
W0620 00:05:35.014790 140424640927552 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb6abc6b2f0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Using config: {'_model_dir': '../data/paperwithcode/60Neg800unk/60Neg800unkFold1BertBatch32', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6a0f52e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}
I0620 00:05:35.016691 140424640927552 estimator.py:212] Using config: {'_model_dir': '../data/paperwithcode/60Neg800unk/60Neg800unkFold1BertBatch32', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6a0f52e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}
INFO:tensorflow:_TPUContext: eval_on_tpu True
I0620 00:05:35.017382 140424640927552 tpu_context.py:220] _TPUContext: eval_on_tpu True
WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.
W0620 00:05:35.017880 140424640927552 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.
WARNING:tensorflow:From run_classifier_sci.py:561: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.

W0620 00:05:35.370560 140424640927552 module_wrapper.py:139] From run_classifier_sci.py:561: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.

WARNING:tensorflow:From run_classifier_sci.py:565: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0620 00:05:35.371749 140424640927552 module_wrapper.py:139] From run_classifier_sci.py:565: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Writing example 0 of 13071
I0620 00:05:35.371893 140424640927552 run_classifier_sci.py:565] Writing example 0 of 13071
INFO:tensorflow:*** Example ***
I0620 00:05:35.379193 140424640927552 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-0
I0620 00:05:35.379369 140424640927552 run_classifier_sci.py:539] guid: test-0
INFO:tensorflow:tokens: [CLS] sentiment analysis ; sub ##j ; accuracy [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 00:05:35.379622 140424640927552 run_classifier_sci.py:541] tokens: [CLS] sentiment analysis ; sub ##j ; accuracy [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 15792 4106 1025 4942 3501 1025 10640 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
I0620 00:05:35.379892 140424640927552 run_classifier_sci.py:542] input_ids: 101 15792 4106 1025 4942 3501 1025 10640 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 00:05:35.380196 140424640927552 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 00:05:35.380355 140424640927552 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 00:05:35.380417 140424640927552 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 00:05:35.387226 140424640927552 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-1
I0620 00:05:35.387330 140424640927552 run_classifier_sci.py:539] guid: test-1
INFO:tensorflow:tokens: [CLS] text classification ; tre ##c ; error [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 00:05:35.387533 140424640927552 run_classifier_sci.py:541] tokens: [CLS] text classification ; tre ##c ; error [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 3793 5579 1025 29461 2278 1025 7561 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
I0620 00:05:35.387749 140424640927552 run_classifier_sci.py:542] input_ids: 101 3793 5579 1025 29461 2278 1025 7561 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 00:05:35.387953 140424640927552 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 00:05:35.388107 140424640927552 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 00:05:35.388169 140424640927552 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 00:05:35.394909 140424640927552 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-2
I0620 00:05:35.395014 140424640927552 run_classifier_sci.py:539] guid: test-2
INFO:tensorflow:tokens: [CLS] question answering ; squad ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 00:05:35.395210 140424640927552 run_classifier_sci.py:541] tokens: [CLS] question answering ; squad ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 3160 10739 1025 4686 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0 0
I0620 00:05:35.395426 140424640927552 run_classifier_sci.py:542] input_ids: 101 3160 10739 1025 4686 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
I0620 00:05:35.395638 140424640927552 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
I0620 00:05:35.395998 140424640927552 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 00:05:35.396174 140424640927552 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 00:05:35.402967 140424640927552 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-3
I0620 00:05:35.403102 140424640927552 run_classifier_sci.py:539] guid: test-3
INFO:tensorflow:tokens: [CLS] relation prediction ; f ##b ##15 ##k - 237 ; h @ 1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 00:05:35.403349 140424640927552 run_classifier_sci.py:541] tokens: [CLS] relation prediction ; f ##b ##15 ##k - 237 ; h @ 1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 7189 17547 1025 1042 2497 16068 2243 1011 23297 1025 1044 1030 1015 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0
I0620 00:05:35.403589 140424640927552 run_classifier_sci.py:542] input_ids: 101 7189 17547 1025 1042 2497 16068 2243 1011 23297 1025 1044 1030 1015 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
I0620 00:05:35.403927 140424640927552 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
I0620 00:05:35.404124 140424640927552 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 00:05:35.404197 140424640927552 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 00:05:35.411096 140424640927552 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-4
I0620 00:05:35.411252 140424640927552 run_classifier_sci.py:539] guid: test-4
INFO:tensorflow:tokens: [CLS] word sense di ##sam ##bi ##gua ##tion ; se ##me ##val 2013 ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 00:05:35.411496 140424640927552 run_classifier_sci.py:541] tokens: [CLS] word sense di ##sam ##bi ##gua ##tion ; se ##me ##val 2013 ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 2773 3168 4487 21559 5638 19696 3508 1025 7367 4168 10175 2286 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0
I0620 00:05:35.411742 140424640927552 run_classifier_sci.py:542] input_ids: 101 2773 3168 4487 21559 5638 19696 3508 1025 7367 4168 10175 2286 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
I0620 00:05:35.412074 140424640927552 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
I0620 00:05:35.412267 140424640927552 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 00:05:35.412337 140424640927552 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:Writing example 10000 of 13071
I0620 00:06:29.082645 140424640927552 run_classifier_sci.py:565] Writing example 10000 of 13071
INFO:tensorflow:***** Running prediction*****
I0620 00:06:45.592884 140424640927552 run_classifier_sci.py:1040] ***** Running prediction*****
INFO:tensorflow:  Num examples = 13071 (13071 actual, 0 padding)
I0620 00:06:45.593143 140424640927552 run_classifier_sci.py:1043]   Num examples = 13071 (13071 actual, 0 padding)
INFO:tensorflow:  Batch size = 6
I0620 00:06:45.593365 140424640927552 run_classifier_sci.py:1044]   Batch size = 6
WARNING:tensorflow:From run_classifier_sci.py:592: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

W0620 00:06:45.594393 140424640927552 module_wrapper.py:139] From run_classifier_sci.py:592: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

INFO:tensorflow:***** Predict results *****
I0620 00:06:45.594749 140424640927552 run_classifier_sci.py:1059] ***** Predict results *****
INFO:tensorflow:Could not find trained model in model_dir: ../data/paperwithcode/60Neg800unk/60Neg800unkFold1BertBatch32, running initialization to predict.
I0620 00:06:45.596700 140424640927552 estimator.py:615] Could not find trained model in model_dir: ../data/paperwithcode/60Neg800unk/60Neg800unkFold1BertBatch32, running initialization to predict.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
W0620 00:06:45.612754 140424640927552 deprecation.py:506] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From run_classifier_sci.py:628: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.map_and_batch(...)`.
W0620 00:06:45.639654 140424640927552 deprecation.py:323] From run_classifier_sci.py:628: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.map_and_batch(...)`.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.
W0620 00:06:45.639853 140424640927552 deprecation.py:323] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0620 00:06:45.701485 140424640927552 module_wrapper.py:139] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From run_classifier_sci.py:608: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0620 00:06:45.795329 140424640927552 deprecation.py:323] From run_classifier_sci.py:608: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Calling model_fn.
I0620 00:06:45.810520 140424640927552 estimator.py:1148] Calling model_fn.
INFO:tensorflow:Running infer on CPU
I0620 00:06:45.810778 140424640927552 tpu_estimator.py:3124] Running infer on CPU
INFO:tensorflow:*** Features ***
I0620 00:06:45.811153 140424640927552 run_classifier_sci.py:708] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (?, 512)
I0620 00:06:45.811326 140424640927552 run_classifier_sci.py:710]   name = input_ids, shape = (?, 512)
INFO:tensorflow:  name = input_mask, shape = (?, 512)
I0620 00:06:45.811468 140424640927552 run_classifier_sci.py:710]   name = input_mask, shape = (?, 512)
INFO:tensorflow:  name = is_real_example, shape = (?,)
I0620 00:06:45.811592 140424640927552 run_classifier_sci.py:710]   name = is_real_example, shape = (?,)
INFO:tensorflow:  name = label_ids, shape = (?,)
I0620 00:06:45.811711 140424640927552 run_classifier_sci.py:710]   name = label_ids, shape = (?,)
INFO:tensorflow:  name = segment_ids, shape = (?, 512)
I0620 00:06:45.811836 140424640927552 run_classifier_sci.py:710]   name = segment_ids, shape = (?, 512)
WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0620 00:06:45.817798 140424640927552 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:410: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0620 00:06:45.819170 140424640927552 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:410: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:491: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.

W0620 00:06:45.843958 140424640927552 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:491: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:672: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
W0620 00:06:45.889019 140424640927552 deprecation.py:323] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:672: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W0620 00:06:45.890326 140424640927552 deprecation.py:323] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From run_classifier_sci.py:728: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0620 00:06:47.387933 140424640927552 module_wrapper.py:139] From run_classifier_sci.py:728: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From run_classifier_sci.py:742: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.

W0620 00:06:47.395341 140424640927552 module_wrapper.py:139] From run_classifier_sci.py:742: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.

INFO:tensorflow:**** Trainable Variables ****
I0620 00:06:47.870686 140424640927552 run_classifier_sci.py:744] **** Trainable Variables ****
INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*
I0620 00:06:47.870886 140424640927552 run_classifier_sci.py:750]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*
I0620 00:06:47.871087 140424640927552 run_classifier_sci.py:750]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*
I0620 00:06:47.871230 140424640927552 run_classifier_sci.py:750]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.871357 140424640927552 run_classifier_sci.py:750]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.871482 140424640927552 run_classifier_sci.py:750]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.871596 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.871716 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.871837 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.871963 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.872074 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.872188 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.872297 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.872410 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.872517 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.872625 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.872733 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.872849 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.872961 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.873075 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.873183 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.873290 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.873398 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.873512 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.873620 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.873733 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.873840 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.873955 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.874063 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.874176 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.874284 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.874391 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.874500 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.874614 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.874722 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.874835 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.874941 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.875049 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.875155 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.875268 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.875376 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.875489 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.875596 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.875709 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.875816 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.875939 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.876047 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.876157 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.876267 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.876379 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.876487 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.876599 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.876706 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.876812 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.876919 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.877033 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.877140 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.877252 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.877359 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.877473 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.877579 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.877690 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.877799 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.877908 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.878015 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.878127 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.878234 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.878346 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.878453 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.878560 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.878666 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.878778 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.878885 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.878996 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.879102 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.879215 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.879321 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.879434 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.879545 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.879653 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.879760 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.879882 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.879992 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.880104 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.880212 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.880319 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.880426 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.880540 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.880647 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.880759 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.880865 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.880977 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.881085 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.881199 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.881307 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.881413 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.881520 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.881632 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.881739 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.881852 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.881960 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.882066 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.882171 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.882283 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.882389 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.882500 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.882607 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.882718 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.882826 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.882939 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.883047 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.883153 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.883259 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.883371 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.883477 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.883590 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.883696 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.883802 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.883916 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.884031 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.884139 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.884252 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.884359 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.884471 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.884581 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.884695 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.884800 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.884906 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.885012 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.885124 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.885230 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.885341 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.885448 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.885554 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.885661 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.885774 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.885881 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.885993 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.886100 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.886214 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.886322 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.886434 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.886540 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.886648 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.886754 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.886867 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.886973 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.887084 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.887190 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.887296 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.887402 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.887513 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.887619 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.887730 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.887844 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.887964 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.888072 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.888185 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.888291 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.888398 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.888504 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.888616 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.888723 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.888834 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.888940 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.889045 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.889151 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.889263 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.889368 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.889452 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.889508 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.889562 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.889611 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.889664 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.889713 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.889763 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.889812 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.889865 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.889914 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.889967 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890016 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890065 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.890113 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890165 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.890217 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890268 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.890317 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890369 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.890417 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890469 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890517 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890564 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:06:47.890612 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:06:47.890663 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:06:47.890711 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890763 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890811 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890858 140424640927552 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:06:47.890905 140424640927552 run_classifier_sci.py:750]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:06:47.890958 140424640927552 run_classifier_sci.py:750]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = output_weights:0, shape = (2, 768)
I0620 00:06:47.891027 140424640927552 run_classifier_sci.py:750]   name = output_weights:0, shape = (2, 768)
INFO:tensorflow:  name = output_bias:0, shape = (2,)
I0620 00:06:47.891094 140424640927552 run_classifier_sci.py:750]   name = output_bias:0, shape = (2,)
INFO:tensorflow:Done calling model_fn.
I0620 00:06:47.891472 140424640927552 estimator.py:1150] Done calling model_fn.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0620 00:06:48.034272 140424640927552 deprecation.py:323] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
INFO:tensorflow:Graph was finalized.
I0620 00:06:48.296820 140424640927552 monitored_session.py:240] Graph was finalized.
2021-06-20 00:06:48.297226: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2021-06-20 00:06:48.336170: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2021-06-20 00:06:48.340795: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8297360f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-06-20 00:06:48.340831: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-06-20 00:06:48.346391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-06-20 00:06:49.496813: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d829737bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-06-20 00:06:49.496840: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2021-06-20 00:06:49.497565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1e:00.0
2021-06-20 00:06:49.501526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-20 00:06:49.543805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-06-20 00:06:49.566223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-06-20 00:06:49.579653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-06-20 00:06:49.626519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-06-20 00:06:49.656563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-06-20 00:06:49.744815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-06-20 00:06:49.746410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2021-06-20 00:06:49.748992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-20 00:06:49.750343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-06-20 00:06:49.750362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2021-06-20 00:06:49.750370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2021-06-20 00:06:49.752893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10320 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:1e:00.0, compute capability: 7.5)
INFO:tensorflow:Running local_init_op.
I0620 00:06:53.993862 140424640927552 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0620 00:06:54.055871 140424640927552 session_manager.py:502] Done running local_init_op.
2021-06-20 00:06:54.866400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
INFO:tensorflow:prediction_loop marked as finished
I0620 00:10:43.115572 140424640927552 error_handling.py:101] prediction_loop marked as finished
INFO:tensorflow:prediction_loop marked as finished
I0620 00:10:43.116302 140424640927552 error_handling.py:101] prediction_loop marked as finished
