Directory ../data/paperwithcode/60Neg800unk/twofoldwithunk/fold1/models/BERT/ Exist
WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From run_classifier_sci.py:1079: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From run_classifier_sci.py:865: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0620 00:46:51.350228 140565109823296 module_wrapper.py:139] From run_classifier_sci.py:865: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From run_classifier_sci.py:865: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0620 00:46:51.350448 140565109823296 module_wrapper.py:139] From run_classifier_sci.py:865: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0620 00:46:51.350899 140565109823296 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

WARNING:tensorflow:From run_classifier_sci.py:890: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W0620 00:46:51.353075 140565109823296 module_wrapper.py:139] From run_classifier_sci.py:890: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0620 00:46:51.435255 140565109823296 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd7605ff378>) includes params argument, but params are not passed to Estimator.
W0620 00:46:53.081689 140565109823296 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd7605ff378>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Using config: {'_model_dir': '../data/paperwithcode/60Neg800unk/twofoldwithunk/fold1/models/BERT/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd7558e5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}
I0620 00:46:53.083555 140565109823296 estimator.py:212] Using config: {'_model_dir': '../data/paperwithcode/60Neg800unk/twofoldwithunk/fold1/models/BERT/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd7558e5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}
INFO:tensorflow:_TPUContext: eval_on_tpu True
I0620 00:46:53.084295 140565109823296 tpu_context.py:220] _TPUContext: eval_on_tpu True
WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.
W0620 00:46:53.084834 140565109823296 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.
WARNING:tensorflow:From run_classifier_sci.py:561: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.

W0620 00:46:53.435611 140565109823296 module_wrapper.py:139] From run_classifier_sci.py:561: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.

WARNING:tensorflow:From run_classifier_sci.py:565: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0620 00:46:53.436968 140565109823296 module_wrapper.py:139] From run_classifier_sci.py:565: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Writing example 0 of 13071
I0620 00:46:53.437175 140565109823296 run_classifier_sci.py:565] Writing example 0 of 13071
INFO:tensorflow:*** Example ***
I0620 00:46:53.444554 140565109823296 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-0
I0620 00:46:53.444673 140565109823296 run_classifier_sci.py:539] guid: test-0
INFO:tensorflow:tokens: [CLS] sentiment analysis ; sub ##j ; accuracy [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 00:46:53.444944 140565109823296 run_classifier_sci.py:541] tokens: [CLS] sentiment analysis ; sub ##j ; accuracy [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 15792 4106 1025 4942 3501 1025 10640 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
I0620 00:46:53.445207 140565109823296 run_classifier_sci.py:542] input_ids: 101 15792 4106 1025 4942 3501 1025 10640 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 00:46:53.445495 140565109823296 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 00:46:53.445650 140565109823296 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 00:46:53.445712 140565109823296 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 00:46:53.452769 140565109823296 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-1
I0620 00:46:53.452881 140565109823296 run_classifier_sci.py:539] guid: test-1
INFO:tensorflow:tokens: [CLS] text classification ; tre ##c ; error [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 00:46:53.453097 140565109823296 run_classifier_sci.py:541] tokens: [CLS] text classification ; tre ##c ; error [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 3793 5579 1025 29461 2278 1025 7561 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
I0620 00:46:53.453310 140565109823296 run_classifier_sci.py:542] input_ids: 101 3793 5579 1025 29461 2278 1025 7561 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 00:46:53.453506 140565109823296 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
I0620 00:46:53.453655 140565109823296 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 00:46:53.453716 140565109823296 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 00:46:53.460638 140565109823296 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-2
I0620 00:46:53.460741 140565109823296 run_classifier_sci.py:539] guid: test-2
INFO:tensorflow:tokens: [CLS] question answering ; squad ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 00:46:53.460962 140565109823296 run_classifier_sci.py:541] tokens: [CLS] question answering ; squad ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 3160 10739 1025 4686 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0 0
I0620 00:46:53.461190 140565109823296 run_classifier_sci.py:542] input_ids: 101 3160 10739 1025 4686 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
I0620 00:46:53.461412 140565109823296 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
I0620 00:46:53.461782 140565109823296 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 00:46:53.461976 140565109823296 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 00:46:53.468927 140565109823296 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-3
I0620 00:46:53.469069 140565109823296 run_classifier_sci.py:539] guid: test-3
INFO:tensorflow:tokens: [CLS] relation prediction ; f ##b ##15 ##k - 237 ; h @ 1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 00:46:53.469331 140565109823296 run_classifier_sci.py:541] tokens: [CLS] relation prediction ; f ##b ##15 ##k - 237 ; h @ 1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 7189 17547 1025 1042 2497 16068 2243 1011 23297 1025 1044 1030 1015 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0
I0620 00:46:53.469582 140565109823296 run_classifier_sci.py:542] input_ids: 101 7189 17547 1025 1042 2497 16068 2243 1011 23297 1025 1044 1030 1015 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
I0620 00:46:53.469934 140565109823296 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
I0620 00:46:53.470125 140565109823296 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 00:46:53.470197 140565109823296 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:*** Example ***
I0620 00:46:53.476987 140565109823296 run_classifier_sci.py:538] *** Example ***
INFO:tensorflow:guid: test-4
I0620 00:46:53.477144 140565109823296 run_classifier_sci.py:539] guid: test-4
INFO:tensorflow:tokens: [CLS] word sense di ##sam ##bi ##gua ##tion ; se ##me ##val 2013 ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
I0620 00:46:53.477386 140565109823296 run_classifier_sci.py:541] tokens: [CLS] word sense di ##sam ##bi ##gua ##tion ; se ##me ##val 2013 ; f1 [SEP] universal sentence en ##code ##r we present models for encoding sentences into em ##bed ##ding vectors that specifically target transfer learning to other nl ##p tasks . the models are efficient and result in accurate performance on diverse transfer tasks . two variants of the encoding models allow for trade - offs between accuracy and compute resources . for both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . comparisons are made with base - lines that use word level transfer learning via pre ##train ##ed word em ##bed ##ding ##s as well as baseline ##s do not use any transfer learning . we find that transfer learning using sentence em ##bed ##ding ##s tends to out ##per ##form word level transfer . with transfer learning via sentence em ##bed ##ding ##s , we observe surprisingly good performance with minimal amounts of supervised training data for ##a transfer task . we obtain encouraging results on word em ##bed ##ding association tests ( we ##at ) targeted at detecting model bias . our pre - trained sentence encoding models are made freely available for download and on t ##f hub . otherwise , hyper ##para ##meter ##s are tuned by cross ##val ##ida ##tion on the task training data when available or the evaluation test data when neither training nor dev data are provided training repeats ten times for each transfer task model with different randomly initial ##ized weights and we report evaluation results by averaging across runs to assess bias in our encoding models , we evaluate the strength of various associations learned by our model on we ##at word lists table 1 : transfer task evaluation sets 1 , 82 ##1 dev test 1 , 37 ##9 ) . table 2 : model performance on transfer tasks . use t is the universal sentence en ##code ##r ( use ) using transform ##er . use d is the universal en ##code ##r dan model . models tagged with baseline ##s with no transfer learning sentence & word em ##bed ##ding transfer learning - sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning mr ss ##t sts bench mp ##qa tre ##c sub ##j cr table 3 : task performance on ss ##t for varying amounts of training data . ss ##t 67 . 3 ##k represents the full training set . using only 1 , 000 examples for training , transfer learning from use t is able to obtain performance that rivals many of the other models trained on the full 67 . 3 thousand example training set . baseline ##s with no transfer learning sentence em ##bed ##ding transfer learning word em ##bed ##ding transfer learning sentence & word em ##bed ##ding transfer learning table 4 : word em ##bed ##ding association tests ( we ##at ) for glove [SEP]
INFO:tensorflow:input_ids: 101 2773 3168 4487 21559 5638 19696 3508 1025 7367 4168 10175 2286 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0
I0620 00:46:53.477627 140565109823296 run_classifier_sci.py:542] input_ids: 101 2773 3168 4487 21559 5638 19696 3508 1025 7367 4168 10175 2286 1025 20069 102 5415 6251 4372 16044 2099 2057 2556 4275 2005 17181 11746 2046 7861 8270 4667 19019 2008 4919 4539 4651 4083 2000 2060 17953 2361 8518 1012 1996 4275 2024 8114 1998 2765 1999 8321 2836 2006 7578 4651 8518 1012 2048 10176 1997 1996 17181 4275 3499 2005 3119 1011 12446 2090 10640 1998 24134 4219 1012 2005 2119 10176 1010 2057 8556 1998 3189 1996 3276 2090 2944 11619 1010 7692 8381 1010 1996 11343 1997 4651 4708 2731 2951 1010 1998 4708 2836 1012 18539 2024 2081 2007 2918 1011 3210 2008 2224 2773 2504 4651 4083 3081 3653 23654 2098 2773 7861 8270 4667 2015 2004 2092 2004 26163 2015 2079 2025 2224 2151 4651 4083 1012 2057 2424 2008 4651 4083 2478 6251 7861 8270 4667 2015 12102 2000 2041 4842 14192 2773 2504 4651 1012 2007 4651 4083 3081 6251 7861 8270 4667 2015 1010 2057 11949 10889 2204 2836 2007 10124 8310 1997 13588 2731 2951 2005 2050 4651 4708 1012 2057 6855 11434 3463 2006 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 9416 2012 25952 2944 13827 1012 2256 3653 1011 4738 6251 17181 4275 2024 2081 10350 2800 2005 8816 1998 2006 1056 2546 9594 1012 4728 1010 23760 28689 22828 2015 2024 15757 2011 2892 10175 8524 3508 2006 1996 4708 2731 2951 2043 2800 2030 1996 9312 3231 2951 2043 4445 2731 4496 16475 2951 2024 3024 2731 17993 2702 2335 2005 2169 4651 4708 2944 2007 2367 18154 3988 3550 15871 1998 2057 3189 9312 3463 2011 14985 2408 3216 2000 14358 13827 1999 2256 17181 4275 1010 2057 16157 1996 3997 1997 2536 8924 4342 2011 2256 2944 2006 2057 4017 2773 7201 2795 1015 1024 4651 4708 9312 4520 1015 1010 6445 2487 16475 3231 1015 1010 4261 2683 1007 1012 2795 1016 1024 2944 2836 2006 4651 8518 1012 2224 1056 2003 1996 5415 6251 4372 16044 2099 1006 2224 1007 2478 10938 2121 1012 2224 1040 2003 1996 5415 4372 16044 2099 4907 2944 1012 4275 26610 2007 26163 2015 2007 2053 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 1011 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 2720 7020 2102 8541 6847 6131 19062 29461 2278 4942 3501 13675 2795 1017 1024 4708 2836 2006 7020 2102 2005 9671 8310 1997 2731 2951 1012 7020 2102 6163 1012 1017 2243 5836 1996 2440 2731 2275 1012 2478 2069 1015 1010 2199 4973 2005 2731 1010 4651 4083 2013 2224 1056 2003 2583 2000 6855 2836 2008 9169 2116 1997 1996 2060 4275 4738 2006 1996 2440 6163 1012 1017 4595 2742 2731 2275 1012 26163 2015 2007 2053 4651 4083 6251 7861 8270 4667 4651 4083 2773 7861 8270 4667 4651 4083 6251 1004 2773 7861 8270 4667 4651 4083 2795 1018 1024 2773 7861 8270 4667 2523 5852 1006 2057 4017 1007 2005 15913 102 0 0 0
INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
I0620 00:46:53.477947 140565109823296 run_classifier_sci.py:543] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
I0620 00:46:53.478139 140565109823296 run_classifier_sci.py:544] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
INFO:tensorflow:label: true (id = 0)
I0620 00:46:53.478208 140565109823296 run_classifier_sci.py:545] label: true (id = 0)
INFO:tensorflow:Writing example 10000 of 13071
I0620 00:47:47.871551 140565109823296 run_classifier_sci.py:565] Writing example 10000 of 13071
INFO:tensorflow:***** Running prediction*****
I0620 00:48:04.530111 140565109823296 run_classifier_sci.py:1040] ***** Running prediction*****
INFO:tensorflow:  Num examples = 13071 (13071 actual, 0 padding)
I0620 00:48:04.530389 140565109823296 run_classifier_sci.py:1043]   Num examples = 13071 (13071 actual, 0 padding)
INFO:tensorflow:  Batch size = 6
I0620 00:48:04.530616 140565109823296 run_classifier_sci.py:1044]   Batch size = 6
WARNING:tensorflow:From run_classifier_sci.py:592: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

W0620 00:48:04.531618 140565109823296 module_wrapper.py:139] From run_classifier_sci.py:592: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

INFO:tensorflow:***** Predict results *****
I0620 00:48:04.531969 140565109823296 run_classifier_sci.py:1059] ***** Predict results *****
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
W0620 00:48:04.581694 140565109823296 deprecation.py:506] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From run_classifier_sci.py:628: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.map_and_batch(...)`.
W0620 00:48:04.608104 140565109823296 deprecation.py:323] From run_classifier_sci.py:628: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.map_and_batch(...)`.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.
W0620 00:48:04.608316 140565109823296 deprecation.py:323] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0620 00:48:04.673717 140565109823296 module_wrapper.py:139] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From run_classifier_sci.py:608: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0620 00:48:04.772024 140565109823296 deprecation.py:323] From run_classifier_sci.py:608: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Calling model_fn.
I0620 00:48:04.786715 140565109823296 estimator.py:1148] Calling model_fn.
INFO:tensorflow:Running infer on CPU
I0620 00:48:04.786950 140565109823296 tpu_estimator.py:3124] Running infer on CPU
INFO:tensorflow:*** Features ***
I0620 00:48:04.787290 140565109823296 run_classifier_sci.py:708] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (?, 512)
I0620 00:48:04.787463 140565109823296 run_classifier_sci.py:710]   name = input_ids, shape = (?, 512)
INFO:tensorflow:  name = input_mask, shape = (?, 512)
I0620 00:48:04.787597 140565109823296 run_classifier_sci.py:710]   name = input_mask, shape = (?, 512)
INFO:tensorflow:  name = is_real_example, shape = (?,)
I0620 00:48:04.787719 140565109823296 run_classifier_sci.py:710]   name = is_real_example, shape = (?,)
INFO:tensorflow:  name = label_ids, shape = (?,)
I0620 00:48:04.787844 140565109823296 run_classifier_sci.py:710]   name = label_ids, shape = (?,)
INFO:tensorflow:  name = segment_ids, shape = (?, 512)
I0620 00:48:04.787967 140565109823296 run_classifier_sci.py:710]   name = segment_ids, shape = (?, 512)
WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0620 00:48:04.794062 140565109823296 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:410: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0620 00:48:04.795534 140565109823296 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:410: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:491: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.

W0620 00:48:04.820272 140565109823296 module_wrapper.py:139] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:491: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.

WARNING:tensorflow:From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:672: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
W0620 00:48:04.865087 140565109823296 deprecation.py:323] From /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/BERT/modeling.py:672: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W0620 00:48:04.866370 140565109823296 deprecation.py:323] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From run_classifier_sci.py:728: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0620 00:48:06.371769 140565109823296 module_wrapper.py:139] From run_classifier_sci.py:728: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From run_classifier_sci.py:742: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.

W0620 00:48:06.379705 140565109823296 module_wrapper.py:139] From run_classifier_sci.py:742: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.

INFO:tensorflow:**** Trainable Variables ****
I0620 00:48:06.856864 140565109823296 run_classifier_sci.py:744] **** Trainable Variables ****
INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*
I0620 00:48:06.857066 140565109823296 run_classifier_sci.py:750]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*
I0620 00:48:06.857250 140565109823296 run_classifier_sci.py:750]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*
I0620 00:48:06.857391 140565109823296 run_classifier_sci.py:750]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.857518 140565109823296 run_classifier_sci.py:750]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.857633 140565109823296 run_classifier_sci.py:750]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.857743 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.857859 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.857970 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.858084 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.858191 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.858303 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.858411 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.858522 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.858629 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.858735 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.858840 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.858952 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.859061 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.859173 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.859279 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.859384 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.859489 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.859601 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.859707 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.859818 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.859936 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.860049 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.860155 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.860266 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.860372 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.860477 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.860581 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.860695 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.860803 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.860914 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.861020 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.861126 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.861231 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.861344 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.861449 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.861559 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.861665 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.861776 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.861883 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.861994 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.862101 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.862206 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.862313 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.862424 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.862531 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.862641 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.862747 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.862851 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.862956 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.863068 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.863174 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.863283 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.863388 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.863498 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.863603 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.863713 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.863819 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.863934 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.864046 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.864157 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.864263 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.864373 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.864478 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.864582 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.864686 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.864797 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.864902 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.865012 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.865117 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.865226 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.865332 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.865442 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.865547 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.865654 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.865760 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.865870 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.865975 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.866085 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.866190 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.866317 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.866429 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.866546 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.866658 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.866775 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.866886 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.867003 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.867115 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.867232 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.867346 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.867464 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.867569 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.867679 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.867784 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.867903 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.868010 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.868114 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.868218 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.868327 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.868432 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.868542 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.868647 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.868757 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.868862 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.868972 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.869080 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.869184 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.869290 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.869400 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.869506 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.869617 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.869722 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.869826 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.869930 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.870040 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.870145 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.870255 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.870359 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.870469 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.870574 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.870686 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.870792 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.870897 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.871001 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.871112 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.871217 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.871327 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.871432 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.871535 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.871639 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.871749 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.871871 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.871985 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.872091 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.872201 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.872307 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.872418 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.872524 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.872629 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.872733 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.872843 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.872948 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.873058 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.873162 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.873266 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.873370 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.873480 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.873584 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.873694 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.873799 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.873910 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.874016 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.874125 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.874229 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.874333 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.874437 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.874545 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.874649 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.874759 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.874862 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.874964 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.875068 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.875179 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.875283 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.875367 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.875421 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.875475 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.875523 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.875574 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.875622 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.875670 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.875718 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.875769 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.875817 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.875900 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.875992 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.876055 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.876105 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.876157 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.876204 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.876255 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.876303 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.876354 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.876402 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.876452 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.876499 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.876547 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
I0620 00:48:06.876593 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
I0620 00:48:06.876644 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
I0620 00:48:06.876710 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.876769 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.876819 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.876869 140565109823296 run_classifier_sci.py:750]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
I0620 00:48:06.876918 140565109823296 run_classifier_sci.py:750]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*
INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
I0620 00:48:06.876971 140565109823296 run_classifier_sci.py:750]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*
INFO:tensorflow:  name = output_weights:0, shape = (2, 768)
I0620 00:48:06.877041 140565109823296 run_classifier_sci.py:750]   name = output_weights:0, shape = (2, 768)
INFO:tensorflow:  name = output_bias:0, shape = (2,)
I0620 00:48:06.877117 140565109823296 run_classifier_sci.py:750]   name = output_bias:0, shape = (2,)
INFO:tensorflow:Done calling model_fn.
I0620 00:48:06.877892 140565109823296 estimator.py:1150] Done calling model_fn.
WARNING:tensorflow:From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0620 00:48:07.022060 140565109823296 deprecation.py:323] From /opt/conda/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
INFO:tensorflow:Graph was finalized.
I0620 00:48:07.283943 140565109823296 monitored_session.py:240] Graph was finalized.
2021-06-20 00:48:07.284468: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2021-06-20 00:48:07.324137: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2021-06-20 00:48:07.328913: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56213ac0a970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-06-20 00:48:07.328950: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-06-20 00:48:07.334783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-06-20 00:48:08.491584: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56213abf3c00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-06-20 00:48:08.491614: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2021-06-20 00:48:08.492350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1e:00.0
2021-06-20 00:48:08.496645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-20 00:48:08.538693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-06-20 00:48:08.562074: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-06-20 00:48:08.574795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-06-20 00:48:08.623099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-06-20 00:48:08.654203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-06-20 00:48:08.745820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-06-20 00:48:08.747126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2021-06-20 00:48:08.749653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-06-20 00:48:08.750882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-06-20 00:48:08.750900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2021-06-20 00:48:08.750908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2021-06-20 00:48:08.753489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10320 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:1e:00.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from ../data/paperwithcode/60Neg800unk/twofoldwithunk/fold1/models/BERT/model.ckpt-13349
I0620 00:48:08.756052 140565109823296 saver.py:1284] Restoring parameters from ../data/paperwithcode/60Neg800unk/twofoldwithunk/fold1/models/BERT/model.ckpt-13349
INFO:tensorflow:Running local_init_op.
I0620 00:48:25.473002 140565109823296 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0620 00:48:25.533489 140565109823296 session_manager.py:502] Done running local_init_op.
2021-06-20 00:48:26.340218: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
INFO:tensorflow:prediction_loop marked as finished
I0620 00:52:14.293650 140565109823296 error_handling.py:101] prediction_loop marked as finished
INFO:tensorflow:prediction_loop marked as finished
I0620 00:52:14.294209 140565109823296 error_handling.py:101] prediction_loop marked as finished
