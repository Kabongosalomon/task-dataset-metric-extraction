16 Dec 2020 11:16.43 [WARN ] GrobidHomeFinder          - No Grobid property was provided. Attempting to find Grobid home in the current directory...
16 Dec 2020 11:16.43 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 11:16.43 [WARN ] GrobidHomeFinder          - *** USING GROBID HOME: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home
16 Dec 2020 11:16.43 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 11:16.43 [WARN ] GrobidHomeFinder          - Grobid property file location was not explicitly set via 'org.grobid.property' system variable, defaulting to: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\config\grobid.properties
16 Dec 2020 11:16.44 [INFO ] LibraryLoader             - Loading external native CRF library
16 Dec 2020 11:16.44 [INFO ] LibraryLoader             - Loading Wapiti native library...
16 Dec 2020 11:16.44 [INFO ] LibraryLoader             - Library crfpp loaded
16 Dec 2020 11:16.44 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\fulltext\model.wapiti (size: 20462507)
16 Dec 2020 11:16.52 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\segmentation\model.wapiti (size: 15807193)
16 Dec 2020 11:16.57 [INFO ] Lexicon                   - Initiating dictionary
16 Dec 2020 11:16.57 [INFO ] Lexicon                   - End of Initialization of dictionary
16 Dec 2020 11:16.57 [INFO ] Lexicon                   - Initiating names
16 Dec 2020 11:16.57 [INFO ] Lexicon                   - End of initialization of names
16 Dec 2020 11:16.58 [INFO ] Lexicon                   - Initiating country codes
16 Dec 2020 11:16.58 [INFO ] Lexicon                   - End of initialization of country codes
16 Dec 2020 11:17.01 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\figure\model.wapiti (size: 679648)
16 Dec 2020 11:17.01 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\table\model.wapiti (size: 1337339)
16 Dec 2020 11:17.02 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\header\model.wapiti (size: 36094028)
16 Dec 2020 11:17.15 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\header\model.wapiti (size: 2225578)
16 Dec 2020 11:17.15 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\citation\model.wapiti (size: 393118)
16 Dec 2020 11:17.16 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\affiliation-address\model.wapiti (size: 2700194)
16 Dec 2020 11:17.20 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\date\model.wapiti (size: 102435)
16 Dec 2020 11:17.21 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\citation\model.wapiti (size: 16235248)
16 Dec 2020 11:17.25 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\reference-segmenter\model.wapiti (size: 4829569)
16 Dec 2020 11:17.48 [WARN ] GrobidHomeFinder          - No Grobid property was provided. Attempting to find Grobid home in the current directory...
16 Dec 2020 11:17.48 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 11:17.48 [WARN ] GrobidHomeFinder          - *** USING GROBID HOME: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home
16 Dec 2020 11:17.48 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 11:17.48 [WARN ] GrobidHomeFinder          - Grobid property file location was not explicitly set via 'org.grobid.property' system variable, defaulting to: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\config\grobid.properties
16 Dec 2020 11:17.48 [INFO ] LibraryLoader             - Loading external native CRF library
16 Dec 2020 11:17.48 [INFO ] LibraryLoader             - Loading Wapiti native library...
16 Dec 2020 11:17.48 [INFO ] LibraryLoader             - Library crfpp loaded
16 Dec 2020 11:17.49 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\fulltext\model.wapiti (size: 20462507)
16 Dec 2020 11:17.56 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\segmentation\model.wapiti (size: 15807193)
16 Dec 2020 11:18.01 [INFO ] Lexicon                   - Initiating dictionary
16 Dec 2020 11:18.01 [INFO ] Lexicon                   - End of Initialization of dictionary
16 Dec 2020 11:18.01 [INFO ] Lexicon                   - Initiating names
16 Dec 2020 11:18.01 [INFO ] Lexicon                   - End of initialization of names
16 Dec 2020 11:18.02 [INFO ] Lexicon                   - Initiating country codes
16 Dec 2020 11:18.02 [INFO ] Lexicon                   - End of initialization of country codes
16 Dec 2020 11:18.04 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\figure\model.wapiti (size: 679648)
16 Dec 2020 11:18.05 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\table\model.wapiti (size: 1337339)
16 Dec 2020 11:18.06 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\header\model.wapiti (size: 36094028)
16 Dec 2020 11:18.18 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\header\model.wapiti (size: 2225578)
16 Dec 2020 11:18.19 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\citation\model.wapiti (size: 393118)
16 Dec 2020 11:18.19 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\affiliation-address\model.wapiti (size: 2700194)
16 Dec 2020 11:18.24 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\date\model.wapiti (size: 102435)
16 Dec 2020 11:18.24 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\citation\model.wapiti (size: 16235248)
16 Dec 2020 11:18.29 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\reference-segmenter\model.wapiti (size: 4829569)
16 Dec 2020 11:47.32 [WARN ] GrobidHomeFinder          - No Grobid property was provided. Attempting to find Grobid home in the current directory...
16 Dec 2020 11:47.32 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 11:47.32 [WARN ] GrobidHomeFinder          - *** USING GROBID HOME: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home
16 Dec 2020 11:47.32 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 11:47.32 [WARN ] GrobidHomeFinder          - Grobid property file location was not explicitly set via 'org.grobid.property' system variable, defaulting to: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\config\grobid.properties
16 Dec 2020 11:47.32 [INFO ] LibraryLoader             - Loading external native CRF library
16 Dec 2020 11:47.32 [INFO ] LibraryLoader             - Loading Wapiti native library...
16 Dec 2020 11:47.32 [INFO ] LibraryLoader             - Library crfpp loaded
16 Dec 2020 11:47.33 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\fulltext\model.wapiti (size: 20462507)
16 Dec 2020 11:47.41 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\segmentation\model.wapiti (size: 15807193)
16 Dec 2020 11:47.46 [INFO ] Lexicon                   - Initiating dictionary
16 Dec 2020 11:47.46 [INFO ] Lexicon                   - End of Initialization of dictionary
16 Dec 2020 11:47.46 [INFO ] Lexicon                   - Initiating names
16 Dec 2020 11:47.46 [INFO ] Lexicon                   - End of initialization of names
16 Dec 2020 11:47.47 [INFO ] Lexicon                   - Initiating country codes
16 Dec 2020 11:47.47 [INFO ] Lexicon                   - End of initialization of country codes
16 Dec 2020 11:47.50 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\figure\model.wapiti (size: 679648)
16 Dec 2020 11:47.51 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\table\model.wapiti (size: 1337339)
16 Dec 2020 11:47.51 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\header\model.wapiti (size: 36094028)
16 Dec 2020 11:48.04 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\header\model.wapiti (size: 2225578)
16 Dec 2020 11:48.04 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\citation\model.wapiti (size: 393118)
16 Dec 2020 11:48.05 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\affiliation-address\model.wapiti (size: 2700194)
16 Dec 2020 11:48.10 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\date\model.wapiti (size: 102435)
16 Dec 2020 11:48.10 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\citation\model.wapiti (size: 16235248)
16 Dec 2020 11:48.14 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\reference-segmenter\model.wapiti (size: 4829569)
16 Dec 2020 11:57.28 [WARN ] GrobidHomeFinder          - No Grobid property was provided. Attempting to find Grobid home in the current directory...
16 Dec 2020 11:57.28 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 11:57.28 [WARN ] GrobidHomeFinder          - *** USING GROBID HOME: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home
16 Dec 2020 11:57.28 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 11:57.28 [WARN ] GrobidHomeFinder          - Grobid property file location was not explicitly set via 'org.grobid.property' system variable, defaulting to: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\config\grobid.properties
16 Dec 2020 11:57.28 [INFO ] LibraryLoader             - Loading external native CRF library
16 Dec 2020 11:57.29 [INFO ] LibraryLoader             - Loading Wapiti native library...
16 Dec 2020 11:57.29 [INFO ] LibraryLoader             - Library crfpp loaded
16 Dec 2020 11:57.29 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\fulltext\model.wapiti (size: 20462507)
16 Dec 2020 11:57.36 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\segmentation\model.wapiti (size: 15807193)
16 Dec 2020 11:57.41 [INFO ] Lexicon                   - Initiating dictionary
16 Dec 2020 11:57.41 [INFO ] Lexicon                   - End of Initialization of dictionary
16 Dec 2020 11:57.41 [INFO ] Lexicon                   - Initiating names
16 Dec 2020 11:57.41 [INFO ] Lexicon                   - End of initialization of names
16 Dec 2020 11:57.42 [INFO ] Lexicon                   - Initiating country codes
16 Dec 2020 11:57.42 [INFO ] Lexicon                   - End of initialization of country codes
16 Dec 2020 11:57.45 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\figure\model.wapiti (size: 679648)
16 Dec 2020 11:57.45 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\table\model.wapiti (size: 1337339)
16 Dec 2020 11:57.46 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\header\model.wapiti (size: 36094028)
16 Dec 2020 11:57.59 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\header\model.wapiti (size: 2225578)
16 Dec 2020 11:57.59 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\citation\model.wapiti (size: 393118)
16 Dec 2020 11:57.59 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\affiliation-address\model.wapiti (size: 2700194)
16 Dec 2020 11:58.03 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\date\model.wapiti (size: 102435)
16 Dec 2020 11:58.04 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\citation\model.wapiti (size: 16235248)
16 Dec 2020 11:58.08 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\reference-segmenter\model.wapiti (size: 4829569)
16 Dec 2020 15:42.50 [WARN ] GrobidHomeFinder          - No Grobid property was provided. Attempting to find Grobid home in the current directory...
16 Dec 2020 15:42.50 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 15:42.50 [WARN ] GrobidHomeFinder          - *** USING GROBID HOME: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home
16 Dec 2020 15:42.50 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 15:42.50 [WARN ] GrobidHomeFinder          - Grobid property file location was not explicitly set via 'org.grobid.property' system variable, defaulting to: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\config\grobid.properties
16 Dec 2020 15:42.50 [INFO ] LibraryLoader             - Loading external native CRF library
16 Dec 2020 15:42.50 [INFO ] LibraryLoader             - Loading Wapiti native library...
16 Dec 2020 15:42.51 [INFO ] LibraryLoader             - Library crfpp loaded
16 Dec 2020 15:42.51 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\fulltext\model.wapiti (size: 20462507)
16 Dec 2020 15:42.59 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\segmentation\model.wapiti (size: 15807193)
16 Dec 2020 15:43.04 [INFO ] Lexicon                   - Initiating dictionary
16 Dec 2020 15:43.04 [INFO ] Lexicon                   - End of Initialization of dictionary
16 Dec 2020 15:43.04 [INFO ] Lexicon                   - Initiating names
16 Dec 2020 15:43.04 [INFO ] Lexicon                   - End of initialization of names
16 Dec 2020 15:43.05 [INFO ] Lexicon                   - Initiating country codes
16 Dec 2020 15:43.05 [INFO ] Lexicon                   - End of initialization of country codes
16 Dec 2020 15:43.08 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\figure\model.wapiti (size: 679648)
16 Dec 2020 15:43.09 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\table\model.wapiti (size: 1337339)
16 Dec 2020 15:43.10 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\header\model.wapiti (size: 36094028)
16 Dec 2020 15:43.23 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\header\model.wapiti (size: 2225578)
16 Dec 2020 15:43.24 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\citation\model.wapiti (size: 393118)
16 Dec 2020 15:43.24 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\affiliation-address\model.wapiti (size: 2700194)
16 Dec 2020 15:43.29 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\date\model.wapiti (size: 102435)
16 Dec 2020 15:43.30 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\citation\model.wapiti (size: 16235248)
16 Dec 2020 15:43.35 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\reference-segmenter\model.wapiti (size: 4829569)
16 Dec 2020 16:01.13 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:01.13 [INFO ] ReferenceMarkerMatcher    -   Bengio, Y, Ducharme, R, and Vincent, P. A neural probabilis-
tic language model. Journal of Machine Learning Research, 
2003. URL http://ukpmc.ac.uk/abstract/CIT/ 
412956.
16 Dec 2020 16:01.13 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:01.13 [INFO ] ReferenceMarkerMatcher    -   Bengio, Yoshua and Senecal, J-S. Adaptive importance sampling 
to accelerate training of a neural probabilistic language model. 
Neural Networks, IEEE Transactions on, 19(4):713-722, 2008. 
Och, Franz Josef and Ney, Hermann. A systematic comparison of 
various statistical alignment models. Computational Linguis-
tics, 29(1):19-51, 2003.
16 Dec 2020 16:01.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:01.18 [INFO ] ReferenceMarkerMatcher    -   Bengio, Y, Ducharme, R, and Vincent, P. A neural probabilis-
tic language model. Journal of Machine Learning Research, 
2003. URL http://ukpmc.ac.uk/abstract/CIT/ 
412956.
16 Dec 2020 16:01.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:01.18 [INFO ] ReferenceMarkerMatcher    -   Bengio, Yoshua and Senecal, J-S. Adaptive importance sampling 
to accelerate training of a neural probabilistic language model. 
Neural Networks, IEEE Transactions on, 19(4):713-722, 2008. 
Och, Franz Josef and Ney, Hermann. A systematic comparison of 
various statistical alignment models. Computational Linguis-
tics, 29(1):19-51, 2003.
16 Dec 2020 16:06.01 [ERROR] FullTextParser            - DocumentPointer for block 14 points to 50 token, but block token size is 49
16 Dec 2020 16:06.07 [ERROR] FullTextParser            - DocumentPointer for block 14 points to 50 token, but block token size is 49
16 Dec 2020 16:06.10 [ERROR] FullTextParser            - DocumentPointer for block 14 points to 50 token, but block token size is 49
16 Dec 2020 16:06.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:06.31 [INFO ] ReferenceMarkerMatcher    -   Srivastava, Nitish and Salakhutdinov, Ruslan. Discriminative transfer learning with tree-based pri-
ors. In NIPS. 2013.
16 Dec 2020 16:06.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:06.31 [INFO ] ReferenceMarkerMatcher    -   Srivastava, Rupesh K, Masci, Jonathan, Kazerounian, Sohrob, Gomez, Faustino, and Schmidhuber, 
Jürgen. Compete to compute. In NIPS. 2013.
16 Dec 2020 16:06.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:06.31 [INFO ] ReferenceMarkerMatcher    -   Simonyan, Karen and Zisserman, Andrew. Very deep convolutional networks for large-scale image 
recognition. In arxiv:cs/arXiv:1409.1556, 2014.
16 Dec 2020 16:06.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:06.31 [INFO ] ReferenceMarkerMatcher    -   Simonyan, Karen, Vedaldi, Andrea, and Zisserman, Andrew. Deep inside convolutional networks: 
Visualising image classification models and saliency maps. In 1312.6034, also appeared at ICLR 
Workshop 2014, 2014. URL http://arxiv.org/abs/1312.6034.
16 Dec 2020 16:06.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:06.37 [INFO ] ReferenceMarkerMatcher    -   Srivastava, Nitish and Salakhutdinov, Ruslan. Discriminative transfer learning with tree-based pri-
ors. In NIPS. 2013.
16 Dec 2020 16:06.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:06.37 [INFO ] ReferenceMarkerMatcher    -   Srivastava, Rupesh K, Masci, Jonathan, Kazerounian, Sohrob, Gomez, Faustino, and Schmidhuber, 
Jürgen. Compete to compute. In NIPS. 2013.
16 Dec 2020 16:06.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:06.37 [INFO ] ReferenceMarkerMatcher    -   Simonyan, Karen and Zisserman, Andrew. Very deep convolutional networks for large-scale image 
recognition. In arxiv:cs/arXiv:1409.1556, 2014.
16 Dec 2020 16:06.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:06.37 [INFO ] ReferenceMarkerMatcher    -   Simonyan, Karen, Vedaldi, Andrea, and Zisserman, Andrew. Deep inside convolutional networks: 
Visualising image classification models and saliency maps. In 1312.6034, also appeared at ICLR 
Workshop 2014, 2014. URL http://arxiv.org/abs/1312.6034.
16 Dec 2020 16:06.59 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:06.59 [INFO ] ReferenceMarkerMatcher    -   Chen, X. and Yuille, A. L. Articulated pose estimation by a graphical model with image dependent 
pairwise relations. In NIPS, 2014.
16 Dec 2020 16:06.59 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:06.59 [INFO ] ReferenceMarkerMatcher    -   Chen, L.-C., Schwing, A., Yuille, A., and Urtasun, R. Learning deep structured models. 
arXiv:1407.2538, 2014.
16 Dec 2020 16:07.06 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:07.06 [INFO ] ReferenceMarkerMatcher    -   Chen, X. and Yuille, A. L. Articulated pose estimation by a graphical model with image dependent 
pairwise relations. In NIPS, 2014.
16 Dec 2020 16:07.06 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:07.06 [INFO ] ReferenceMarkerMatcher    -   Chen, L.-C., Schwing, A., Yuille, A., and Urtasun, R. Learning deep structured models. 
arXiv:1407.2538, 2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.23 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:10.28 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.22 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:33.33 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 16:36.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:36.03 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding 
variational bayes. In Proceedings of ICLR, 2014.
16 Dec 2020 16:36.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:36.03 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Proceedings 
of NIPS, 2014.
16 Dec 2020 16:36.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:36.03 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding 
variational bayes. In Proceedings of ICLR, 2014.
16 Dec 2020 16:36.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:36.03 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Proceedings 
of NIPS, 2014.
16 Dec 2020 16:36.11 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:36.11 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding 
variational bayes. In Proceedings of ICLR, 2014.
16 Dec 2020 16:36.11 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:36.11 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Proceedings 
of NIPS, 2014.
16 Dec 2020 16:36.11 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:36.11 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding 
variational bayes. In Proceedings of ICLR, 2014.
16 Dec 2020 16:36.11 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:36.11 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Proceedings 
of NIPS, 2014.
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    -   Hochreiter, S. The vanishing gradient problem during learning recurrent neural nets and problem solutions. 
International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(2):107-116, 1998.
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    -   Schraudolph, N. N. Centering neural network gradient factor. In Orr, G. B. and Müller, K.-R. (eds.), Neural 
Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 207-226. Springer, 
1998.
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    -   Yang, H. H. and Amari, S.-I. Complexity issues in natural gradient descent method for training multilayer 
perceptrons. Neural Computation, 10(8), 1998.
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    -   Amari, S.-I. Natural gradient works efficiently in learning. Neural Computation, 10(2):251-276, 1998. 
Clevert, D.-A., Unterthiner, T., Mayr, A., and Hochreiter, S. Rectified factor networks. In Cortes, C., Lawrence, 
N. D., Lee, D. D., Sugiyama, M., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 
28. Curran Associates, Inc., 2015.
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    -   LeCun, Y., Bottou, L., Orr, G. B., and Müller, K.-R. Efficient backprop. In Orr, G. B. and Müller, K.-R. 
(eds.), Neural Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 9-50. 
Springer, 1998.
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    -   Hochreiter, S. The vanishing gradient problem during learning recurrent neural nets and problem solutions. 
International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(2):107-116, 1998.
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    -   Schraudolph, N. N. Centering neural network gradient factor. In Orr, G. B. and Müller, K.-R. (eds.), Neural 
Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 207-226. Springer, 
1998.
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    -   Yang, H. H. and Amari, S.-I. Complexity issues in natural gradient descent method for training multilayer 
perceptrons. Neural Computation, 10(8), 1998.
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    -   Amari, S.-I. Natural gradient works efficiently in learning. Neural Computation, 10(2):251-276, 1998. 
Clevert, D.-A., Unterthiner, T., Mayr, A., and Hochreiter, S. Rectified factor networks. In Cortes, C., Lawrence, 
N. D., Lee, D. D., Sugiyama, M., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 
28. Curran Associates, Inc., 2015.
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.45 [INFO ] ReferenceMarkerMatcher    -   LeCun, Y., Bottou, L., Orr, G. B., and Müller, K.-R. Efficient backprop. In Orr, G. B. and Müller, K.-R. 
(eds.), Neural Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 9-50. 
Springer, 1998.
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    -   Hochreiter, S. The vanishing gradient problem during learning recurrent neural nets and problem solutions. 
International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(2):107-116, 1998.
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    -   Schraudolph, N. N. Centering neural network gradient factor. In Orr, G. B. and Müller, K.-R. (eds.), Neural 
Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 207-226. Springer, 
1998.
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    -   Yang, H. H. and Amari, S.-I. Complexity issues in natural gradient descent method for training multilayer 
perceptrons. Neural Computation, 10(8), 1998.
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    -   Amari, S.-I. Natural gradient works efficiently in learning. Neural Computation, 10(2):251-276, 1998. 
Clevert, D.-A., Unterthiner, T., Mayr, A., and Hochreiter, S. Rectified factor networks. In Cortes, C., Lawrence, 
N. D., Lee, D. D., Sugiyama, M., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 
28. Curran Associates, Inc., 2015.
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    -   LeCun, Y., Bottou, L., Orr, G. B., and Müller, K.-R. Efficient backprop. In Orr, G. B. and Müller, K.-R. 
(eds.), Neural Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 9-50. 
Springer, 1998.
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    -   Hochreiter, S. The vanishing gradient problem during learning recurrent neural nets and problem solutions. 
International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(2):107-116, 1998.
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    -   Schraudolph, N. N. Centering neural network gradient factor. In Orr, G. B. and Müller, K.-R. (eds.), Neural 
Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 207-226. Springer, 
1998.
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    -   Yang, H. H. and Amari, S.-I. Complexity issues in natural gradient descent method for training multilayer 
perceptrons. Neural Computation, 10(8), 1998.
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    -   Amari, S.-I. Natural gradient works efficiently in learning. Neural Computation, 10(2):251-276, 1998. 
Clevert, D.-A., Unterthiner, T., Mayr, A., and Hochreiter, S. Rectified factor networks. In Cortes, C., Lawrence, 
N. D., Lee, D. D., Sugiyama, M., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 
28. Curran Associates, Inc., 2015.
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:37.52 [INFO ] ReferenceMarkerMatcher    -   LeCun, Y., Bottou, L., Orr, G. B., and Müller, K.-R. Efficient backprop. In Orr, G. B. and Müller, K.-R. 
(eds.), Neural Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 9-50. 
Springer, 1998.
16 Dec 2020 16:42.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:42.50 [INFO ] ReferenceMarkerMatcher    -   [Luong et al.2015] Thang Luong, Ilya Sutskever, 
Quoc V. Le, Oriol Vinyals, and Wojciech Zaremba. 
2015. Addressing the rare word problem in neural 
machine translation. In Proceedings of the 53rd
16 Dec 2020 16:42.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:42.50 [INFO ] ReferenceMarkerMatcher    -   [Li et al.2015] Jiwei Li, Minh-Thang Luong, and Dan 
Jurafsky. 2015. A hierarchical neural autoen-
coder for paragraphs and documents. 
CoRR, 
abs/1506.01057. 
[Wong et al.2008a] Kam-Fai Wong, Mingli Wu, and 
Wenjie Li. 2008a. Extractive summarization using 
supervised and semi-supervised learning. In Pro-
ceedings of the 22Nd International Conference on 
Computational Linguistics -Volume 1, pages 985-
992.
16 Dec 2020 16:42.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:42.57 [INFO ] ReferenceMarkerMatcher    -   [Luong et al.2015] Thang Luong, Ilya Sutskever, 
Quoc V. Le, Oriol Vinyals, and Wojciech Zaremba. 
2015. Addressing the rare word problem in neural 
machine translation. In Proceedings of the 53rd
16 Dec 2020 16:42.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:42.57 [INFO ] ReferenceMarkerMatcher    -   [Li et al.2015] Jiwei Li, Minh-Thang Luong, and Dan 
Jurafsky. 2015. A hierarchical neural autoen-
coder for paragraphs and documents. 
CoRR, 
abs/1506.01057. 
[Wong et al.2008a] Kam-Fai Wong, Mingli Wu, and 
Wenjie Li. 2008a. Extractive summarization using 
supervised and semi-supervised learning. In Pro-
ceedings of the 22Nd International Conference on 
Computational Linguistics -Volume 1, pages 985-
992.
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    -   DT42. Squeezenet keras implementation. https://github.com/DT42/squeezenet_ 
demo, 2016.
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    -   Guo Haria. convert squeezenet to mxnet. https://github.com/haria/SqueezeNet/ 
commit/0cf57539375fd5429275af36fc94c774503427c3, 2016.
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    -   Eddie Bell. A implementation of squeezenet in chainer. https://github.com/ejlb/ 
squeezenet-chainer, 2016.
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    -   Francois Chollet. Keras: Deep learning library for theano and tensorflow. https://keras.io, 
2016.
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    -   David Gschwend. Zynqnet: An fpga-accelerated embedded convolutional neural network. Master's 
thesis, Swiss Federal Institute of Technology Zurich (ETH-Zurich), 2016.
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    -   Philipp Gysel. Ristretto: Hardware-oriented approximation of convolutional neural networks. 
arXiv:1605.06402, 2016.
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    -   Sagar M Waghmare. FireModule.lua. https://github.com/Element-Research/dpnn/ 
blob/master/FireModule.lua, 2016.
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    -   Ronan Collobert, Koray Kavukcuoglu, and Clement Farabet. Torch7: A matlab-like environment 
for machine learning. In NIPS BigLearn Workshop, 2011. 
Consumer 
Reports. 
Teslas 
new 
autopilot: 
Better 
but 
still 
needs 
improvement. 
http://www.consumerreports.org/tesla/ 
tesla-new-autopilot-better-but-needs-improvement, 2016.
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    -   Dmytro Mishkin, Nikolay Sergievskiy, and Jiri Matas. Systematic evaluation of cnn advances on 
the imagenet. arXiv:1606.02228, 2016.
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.19 [INFO ] ReferenceMarkerMatcher    -   Christian Szegedy, Sergey Ioffe, and Vincent Vanhoucke. Inception-v4, inception-resnet and the 
impact of residual connections on learning. arXiv:1602.07261, 2016.
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    -   DT42. Squeezenet keras implementation. https://github.com/DT42/squeezenet_ 
demo, 2016.
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    -   Guo Haria. convert squeezenet to mxnet. https://github.com/haria/SqueezeNet/ 
commit/0cf57539375fd5429275af36fc94c774503427c3, 2016.
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    -   Eddie Bell. A implementation of squeezenet in chainer. https://github.com/ejlb/ 
squeezenet-chainer, 2016.
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    -   Francois Chollet. Keras: Deep learning library for theano and tensorflow. https://keras.io, 
2016.
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    -   David Gschwend. Zynqnet: An fpga-accelerated embedded convolutional neural network. Master's 
thesis, Swiss Federal Institute of Technology Zurich (ETH-Zurich), 2016.
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    -   Philipp Gysel. Ristretto: Hardware-oriented approximation of convolutional neural networks. 
arXiv:1605.06402, 2016.
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    -   Sagar M Waghmare. FireModule.lua. https://github.com/Element-Research/dpnn/ 
blob/master/FireModule.lua, 2016.
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    -   Ronan Collobert, Koray Kavukcuoglu, and Clement Farabet. Torch7: A matlab-like environment 
for machine learning. In NIPS BigLearn Workshop, 2011. 
Consumer 
Reports. 
Teslas 
new 
autopilot: 
Better 
but 
still 
needs 
improvement. 
http://www.consumerreports.org/tesla/ 
tesla-new-autopilot-better-but-needs-improvement, 2016.
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    -   Dmytro Mishkin, Nikolay Sergievskiy, and Jiri Matas. Systematic evaluation of cnn advances on 
the imagenet. arXiv:1606.02228, 2016.
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:43.26 [INFO ] ReferenceMarkerMatcher    -   Christian Szegedy, Sergey Ioffe, and Vincent Vanhoucke. Inception-v4, inception-resnet and the 
impact of residual connections on learning. arXiv:1602.07261, 2016.
16 Dec 2020 16:53.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:53.29 [INFO ] ReferenceMarkerMatcher    -   Song, Le and Dai, Bo. Robust low rank kernel embeddings 
of multivariate distributions. In Advances in Neural In-
formation Processing Systems (NIPS), pp. 3228-3236, 
2013.
16 Dec 2020 16:53.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:53.29 [INFO ] ReferenceMarkerMatcher    -   Song, Le, Fukumizu, Kenji, and Gretton, Arthur. Kernel 
embeddings of conditional distributions: A unified kernel 
framework for nonparametric inference in graphical mod-
els. IEEE Signal Processing Magazine, 30(4):98-111, 
2013.
16 Dec 2020 16:53.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:53.37 [INFO ] ReferenceMarkerMatcher    -   Song, Le and Dai, Bo. Robust low rank kernel embeddings 
of multivariate distributions. In Advances in Neural In-
formation Processing Systems (NIPS), pp. 3228-3236, 
2013.
16 Dec 2020 16:53.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 16:53.37 [INFO ] ReferenceMarkerMatcher    -   Song, Le, Fukumizu, Kenji, and Gretton, Arthur. Kernel 
embeddings of conditional distributions: A unified kernel 
framework for nonparametric inference in graphical mod-
els. IEEE Signal Processing Magazine, 30(4):98-111, 
2013.
16 Dec 2020 17:07.07 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 17:07.07 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 17:07.13 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 17:07.13 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 17:13.58 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:13.58 [INFO ] ReferenceMarkerMatcher    -   Related Work 
Natural language sentence matching (NLSM) has been stud-
ied for many years. Early approaches focused on designing 
hand-craft features to capture n-gram overlapping, word re-
ordering and syntactic alignments phenomena [Heilman and 
Smith, 2010; Wang and Ittycheriah, 2015]. This kind of 
method can work well on a specific task or dataset, but it's 
hard to generalize well to other tasks. 
With the availability of large-scale annotated 
datasets [Bowman et al., 2015], many deep learning models 
were proposed for NLSM. The first kind of framework 
is based the Siamese architecture [Bromley et al., 1993], 
where sentences are encoded into sentence vectors based 
on some neural network encoders, and then the relationship 
between two sentences was decided solely based on the two 
sentence vectors [Bowman et al., 2015; Yang et al., 2015;
16 Dec 2020 17:13.58 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:13.58 [INFO ] ReferenceMarkerMatcher    -   However, this kind of framework ignores 
the fact that the lower level interactive features between two 
4 [Rao et al., 2016] pointed out that there are two versions of 
TREC-QA dataset: raw-version and clean-version. In this work, 
we utilized the clean-version. Therefore, we only compare with ap-
proaches reporting performance on this dataset. 
5 http://trec.nist.gove/trec eval/ 
[Bowman et al., 2015] Samuel R Bowman, Gabor Angeli, 
Christopher Potts, and Christopher D Manning. A large 
annotated corpus for learning natural language inference. 
arXiv preprint arXiv:1508.05326, 2015. 
[Bromley et al., 1993] Jane Bromley, James W. Bentz, Léon 
Bottou, Isabelle Guyon, Yann LeCun, Cliff Moore, Eduard 
Säckinger, and Roopak Shah. Signature verification using 
a "siamese" time delay neural network. IJPRAI, 7(4):669-
688, 1993. 
[Chen et al., 2016] Qian Chen, Xiaodan Zhu, Zhenhua Ling, 
Si Wei, and Hui Jiang. Enhancing and combining sequen-
tial and tree lstm for natural language inference. arXiv 
preprint arXiv:1609.06038, 2016. 
[Cheng et al., 2016] Jianpeng Cheng, Li Dong, and Mirella 
Lapata. Long short-term memory-networks for machine 
reading. arXiv preprint arXiv:1601.06733, 2016. 
[He and Lin, 2016] Hua He and Jimmy Lin. Pairwise word 
interaction modeling with deep neural networks for se-
mantic similarity measurement. In NAACL, 2016. 
[Heilman and Smith, 2010] Michael Heilman and Noah A 
Smith. Tree edit models for recognizing textual entail-
ments, paraphrases, and answers to questions. In NAACL, 
2010. 
[Hochreiter and Schmidhuber, 1997] Sepp Hochreiter and 
Jürgen Schmidhuber. Long short-term memory. Neural 
computation, 9(8):1735-1780, 1997. 
[Kingma and Ba, 2014] Diederik Kingma and Jimmy Ba. 
Adam: A method for stochastic optimization. arXiv 
preprint arXiv:1412.6980, 2014. 
[LeCun et al., 2015] Yann LeCun, Yoshua Bengio, and Ge-
offrey Hinton. Deep learning. Nature, 521(7553):436-
444, 2015.
16 Dec 2020 17:14.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.03 [INFO ] ReferenceMarkerMatcher    -   Related Work 
Natural language sentence matching (NLSM) has been stud-
ied for many years. Early approaches focused on designing 
hand-craft features to capture n-gram overlapping, word re-
ordering and syntactic alignments phenomena [Heilman and 
Smith, 2010; Wang and Ittycheriah, 2015]. This kind of 
method can work well on a specific task or dataset, but it's 
hard to generalize well to other tasks. 
With the availability of large-scale annotated 
datasets [Bowman et al., 2015], many deep learning models 
were proposed for NLSM. The first kind of framework 
is based the Siamese architecture [Bromley et al., 1993], 
where sentences are encoded into sentence vectors based 
on some neural network encoders, and then the relationship 
between two sentences was decided solely based on the two 
sentence vectors [Bowman et al., 2015; Yang et al., 2015;
16 Dec 2020 17:14.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.03 [INFO ] ReferenceMarkerMatcher    -   However, this kind of framework ignores 
the fact that the lower level interactive features between two 
4 [Rao et al., 2016] pointed out that there are two versions of 
TREC-QA dataset: raw-version and clean-version. In this work, 
we utilized the clean-version. Therefore, we only compare with ap-
proaches reporting performance on this dataset. 
5 http://trec.nist.gove/trec eval/ 
[Bowman et al., 2015] Samuel R Bowman, Gabor Angeli, 
Christopher Potts, and Christopher D Manning. A large 
annotated corpus for learning natural language inference. 
arXiv preprint arXiv:1508.05326, 2015. 
[Bromley et al., 1993] Jane Bromley, James W. Bentz, Léon 
Bottou, Isabelle Guyon, Yann LeCun, Cliff Moore, Eduard 
Säckinger, and Roopak Shah. Signature verification using 
a "siamese" time delay neural network. IJPRAI, 7(4):669-
688, 1993. 
[Chen et al., 2016] Qian Chen, Xiaodan Zhu, Zhenhua Ling, 
Si Wei, and Hui Jiang. Enhancing and combining sequen-
tial and tree lstm for natural language inference. arXiv 
preprint arXiv:1609.06038, 2016. 
[Cheng et al., 2016] Jianpeng Cheng, Li Dong, and Mirella 
Lapata. Long short-term memory-networks for machine 
reading. arXiv preprint arXiv:1601.06733, 2016. 
[He and Lin, 2016] Hua He and Jimmy Lin. Pairwise word 
interaction modeling with deep neural networks for se-
mantic similarity measurement. In NAACL, 2016. 
[Heilman and Smith, 2010] Michael Heilman and Noah A 
Smith. Tree edit models for recognizing textual entail-
ments, paraphrases, and answers to questions. In NAACL, 
2010. 
[Hochreiter and Schmidhuber, 1997] Sepp Hochreiter and 
Jürgen Schmidhuber. Long short-term memory. Neural 
computation, 9(8):1735-1780, 1997. 
[Kingma and Ba, 2014] Diederik Kingma and Jimmy Ba. 
Adam: A method for stochastic optimization. arXiv 
preprint arXiv:1412.6980, 2014. 
[LeCun et al., 2015] Yann LeCun, Yoshua Bengio, and Ge-
offrey Hinton. Deep learning. Nature, 521(7553):436-
444, 2015.
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.21 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:14.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 17:17.55 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 17:17.55 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 17:18.01 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 17:18.01 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Rosasco, L.; and Poggio, T. A. 2016. Holo-
graphic Embeddings of Knowledge Graphs. In Proceedings 
of AAAI, 1955-1961.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Murphy, K.; Tresp, V.; and Gabrilovich, E. 
2016. A review of relational machine learning for knowledge 
graphs. Proceedings of the IEEE 104(1):11-33.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Rosasco, L.; and Poggio, T. A. 2016. Holo-
graphic Embeddings of Knowledge Graphs. In Proceedings 
of AAAI, 1955-1961.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Murphy, K.; Tresp, V.; and Gabrilovich, E. 
2016. A review of relational machine learning for knowledge 
graphs. Proceedings of the IEEE 104(1):11-33.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.47 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Rosasco, L.; and Poggio, T. A. 2016. Holo-
graphic Embeddings of Knowledge Graphs. In Proceedings 
of AAAI, 1955-1961.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Murphy, K.; Tresp, V.; and Gabrilovich, E. 
2016. A review of relational machine learning for knowledge 
graphs. Proceedings of the IEEE 104(1):11-33.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Rosasco, L.; and Poggio, T. A. 2016. Holo-
graphic Embeddings of Knowledge Graphs. In Proceedings 
of AAAI, 1955-1961.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Murphy, K.; Tresp, V.; and Gabrilovich, E. 
2016. A review of relational machine learning for knowledge 
graphs. Proceedings of the IEEE 104(1):11-33.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:27.54 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 17:28.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:28.31 [INFO ] ReferenceMarkerMatcher    -   Dai, A. M. and Le, Q. V. (2015). Semi-supervised sequence learning. In Advances in Neural 
Information Processing Systems, pages 3079-3087.
16 Dec 2020 17:28.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:28.31 [INFO ] ReferenceMarkerMatcher    -   Dai, A. M., Olah, C., and Le, Q. V. (2015). Document embedding with paragraph vectors. arXiv 
preprint arXiv:1507.07998.
16 Dec 2020 17:28.38 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:28.38 [INFO ] ReferenceMarkerMatcher    -   Dai, A. M. and Le, Q. V. (2015). Semi-supervised sequence learning. In Advances in Neural 
Information Processing Systems, pages 3079-3087.
16 Dec 2020 17:28.38 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:28.38 [INFO ] ReferenceMarkerMatcher    -   Dai, A. M., Olah, C., and Le, Q. V. (2015). Document embedding with paragraph vectors. arXiv 
preprint arXiv:1507.07998.
16 Dec 2020 17:36.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:36.27 [INFO ] ReferenceMarkerMatcher    -   Mobley, D. L., and Guthrie, J. P. 2014. Freesolv: a database 
of experimental and calculated hydration free energies, with 
input files. Journal of computer-aided molecular design 
28(7):711.
16 Dec 2020 17:36.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:36.27 [INFO ] ReferenceMarkerMatcher    -   Mobley, D. L.; Wymer, K. L.; Lim, N. M.; and Guthrie, J. P. 
2014. Blind prediction of solvation free energies from the 
sampl4 challenge. J Comput Aided Mol Des 28(3):135-150.
16 Dec 2020 17:36.32 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:36.32 [INFO ] ReferenceMarkerMatcher    -   Mobley, D. L., and Guthrie, J. P. 2014. Freesolv: a database 
of experimental and calculated hydration free energies, with 
input files. Journal of computer-aided molecular design 
28(7):711.
16 Dec 2020 17:36.32 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:36.32 [INFO ] ReferenceMarkerMatcher    -   Mobley, D. L.; Wymer, K. L.; Lim, N. M.; and Guthrie, J. P. 
2014. Blind prediction of solvation free energies from the 
sampl4 challenge. J Comput Aided Mol Des 28(3):135-150.
16 Dec 2020 17:45.44 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:45.44 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Bethge, M.; Hertzmann, A.; and Shecht-
man, E. 2016. Preserving color in neural artistic style trans-
fer. arXiv preprint arXiv:1606.05897.
16 Dec 2020 17:45.44 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:45.44 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Ecker, A. S.; and Bethge, M. 2016. Im-
age style transfer using convolutional neural networks. In 
Proceedings of the IEEE Conference on Computer Vision 
and Pattern Recognition, 2414-2423.
16 Dec 2020 17:45.44 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:45.44 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Bethge, M.; Hertzmann, A.; and Shecht-
man, E. 2016. Preserving color in neural artistic style trans-
fer. arXiv preprint arXiv:1606.05897.
16 Dec 2020 17:45.44 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:45.44 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Ecker, A. S.; and Bethge, M. 2016. Im-
age style transfer using convolutional neural networks. In 
Proceedings of the IEEE Conference on Computer Vision 
and Pattern Recognition, 2414-2423.
16 Dec 2020 17:45.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:45.50 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Bethge, M.; Hertzmann, A.; and Shecht-
man, E. 2016. Preserving color in neural artistic style trans-
fer. arXiv preprint arXiv:1606.05897.
16 Dec 2020 17:45.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:45.50 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Ecker, A. S.; and Bethge, M. 2016. Im-
age style transfer using convolutional neural networks. In 
Proceedings of the IEEE Conference on Computer Vision 
and Pattern Recognition, 2414-2423.
16 Dec 2020 17:45.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:45.50 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Bethge, M.; Hertzmann, A.; and Shecht-
man, E. 2016. Preserving color in neural artistic style trans-
fer. arXiv preprint arXiv:1606.05897.
16 Dec 2020 17:45.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:45.50 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Ecker, A. S.; and Bethge, M. 2016. Im-
age style transfer using convolutional neural networks. In 
Proceedings of the IEEE Conference on Computer Vision 
and Pattern Recognition, 2414-2423.
16 Dec 2020 17:46.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:46.46 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; and Mei, Q. 2015. Pte: Predictive text em-
bedding through large-scale heterogeneous text networks. In 
KDD, 1165-1174. ACM.
16 Dec 2020 17:46.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:46.46 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, 
Q. 2015. Line: Large-scale information network embed-
ding. In WWW, 1067-1077. International World Wide Web 
Conferences Steering Committee.
16 Dec 2020 17:46.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:46.46 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; and Mei, Q. 2015. Pte: Predictive text em-
bedding through large-scale heterogeneous text networks. In 
KDD, 1165-1174. ACM.
16 Dec 2020 17:46.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:46.46 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, 
Q. 2015. Line: Large-scale information network embed-
ding. In WWW, 1067-1077. International World Wide Web 
Conferences Steering Committee.
16 Dec 2020 17:46.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:46.52 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; and Mei, Q. 2015. Pte: Predictive text em-
bedding through large-scale heterogeneous text networks. In 
KDD, 1165-1174. ACM.
16 Dec 2020 17:46.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:46.52 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, 
Q. 2015. Line: Large-scale information network embed-
ding. In WWW, 1067-1077. International World Wide Web 
Conferences Steering Committee.
16 Dec 2020 17:46.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:46.52 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; and Mei, Q. 2015. Pte: Predictive text em-
bedding through large-scale heterogeneous text networks. In 
KDD, 1165-1174. ACM.
16 Dec 2020 17:46.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:46.52 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, 
Q. 2015. Line: Large-scale information network embed-
ding. In WWW, 1067-1077. International World Wide Web 
Conferences Steering Committee.
16 Dec 2020 17:49.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:49.03 [INFO ] ReferenceMarkerMatcher    -   Paulus, R.; Xiong, C.; and Socher, R. 2017. A deep rein-
forced model for abstractive summarization. arXiv preprint 
arXiv:1705.04304.
16 Dec 2020 17:49.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:49.03 [INFO ] ReferenceMarkerMatcher    -   Paulus, Xiong, and Socher (2017) combined reinforcement 
learning and self-attention to capture the long distance de-
pendencies nature of abstractive summarization. Vaswani et 
al. (2017) applied self-attention to neural machine transla-
tion and achieved the state-of-the-art results. Very recently, 
Shen et al. (2017) applied self-attention to language under-
standing task and achieved the state-of-the-art on various 
datasets. Our work follows this line to apply self-attention 
for learning long distance dependencies. Our experiments 
also show the effectiveness of self-attention mechanism on 
the sequence labeling task. 
Conclusion 
We proposed a deep attentional neural network for the task 
of semantic role labeling. We trained our SRL models with a 
depth of 10 and evaluated them on the CoNLL-2005 shared 
task dataset and the CoNLL-2012 shared task dataset. Our 
experimental results indicate that our models substantially 
improve SRL performances, leading to the new state-of-the-
art.
16 Dec 2020 17:49.10 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:49.10 [INFO ] ReferenceMarkerMatcher    -   Paulus, R.; Xiong, C.; and Socher, R. 2017. A deep rein-
forced model for abstractive summarization. arXiv preprint 
arXiv:1705.04304.
16 Dec 2020 17:49.10 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:49.10 [INFO ] ReferenceMarkerMatcher    -   Paulus, Xiong, and Socher (2017) combined reinforcement 
learning and self-attention to capture the long distance de-
pendencies nature of abstractive summarization. Vaswani et 
al. (2017) applied self-attention to neural machine transla-
tion and achieved the state-of-the-art results. Very recently, 
Shen et al. (2017) applied self-attention to language under-
standing task and achieved the state-of-the-art on various 
datasets. Our work follows this line to apply self-attention 
for learning long distance dependencies. Our experiments 
also show the effectiveness of self-attention mechanism on 
the sequence labeling task. 
Conclusion 
We proposed a deep attentional neural network for the task 
of semantic role labeling. We trained our SRL models with a 
depth of 10 and evaluated them on the CoNLL-2005 shared 
task dataset and the CoNLL-2012 shared task dataset. Our 
experimental results indicate that our models substantially 
improve SRL performances, leading to the new state-of-the-
art.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.27 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:53.33 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 17:54.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:54.12 [INFO ] ReferenceMarkerMatcher    -   Wang, S., and Jiang, J. 2017. Machine comprehension using 
Match-LSTM and answer pointer. In Proceedings of ICLR.
16 Dec 2020 17:54.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:54.12 [INFO ] ReferenceMarkerMatcher    -   Cui, Y.; Chen, Z.; Wei, S.; Wang, S.; Liu, T.; and Hu, G. 
2017. Attention-over-attention neural networks for reading 
comprehension. In Proceedings of ACL.
16 Dec 2020 17:54.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:54.12 [INFO ] ReferenceMarkerMatcher    -   Wang, W.; Yang, N.; Wei, F.; Chang, B.; and Zhou, M. 2017. 
Gated self-matching networks for reading comprehension 
and question answering. In Proceedings of ACL.
16 Dec 2020 17:54.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:54.17 [INFO ] ReferenceMarkerMatcher    -   Wang, S., and Jiang, J. 2017. Machine comprehension using 
Match-LSTM and answer pointer. In Proceedings of ICLR.
16 Dec 2020 17:54.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:54.17 [INFO ] ReferenceMarkerMatcher    -   Cui, Y.; Chen, Z.; Wei, S.; Wang, S.; Liu, T.; and Hu, G. 
2017. Attention-over-attention neural networks for reading 
comprehension. In Proceedings of ACL.
16 Dec 2020 17:54.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 17:54.17 [INFO ] ReferenceMarkerMatcher    -   Wang, W.; Yang, N.; Wei, F.; Chang, B.; and Zhou, M. 2017. 
Gated self-matching networks for reading comprehension 
and question answering. In Proceedings of ACL.
16 Dec 2020 18:02.10 [WARN ] CybozuLanguageDetector    - Cannot detect language because of: com.cybozu.labs.langdetect.LangDetectException: no features in text
16 Dec 2020 18:02.13 [WARN ] CybozuLanguageDetector    - Cannot detect language because of: com.cybozu.labs.langdetect.LangDetectException: no features in text
16 Dec 2020 18:02.18 [WARN ] CybozuLanguageDetector    - Cannot detect language because of: com.cybozu.labs.langdetect.LangDetectException: no features in text
16 Dec 2020 18:02.20 [WARN ] CybozuLanguageDetector    - Cannot detect language because of: com.cybozu.labs.langdetect.LangDetectException: no features in text
16 Dec 2020 18:26.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:26.27 [INFO ] ReferenceMarkerMatcher    -   Conneau, A. and D. Kiela 2018, May 7-12. SentEval: An evaluation toolkit for universal 
sentence representations. In N. Calzolari (Ed.), LREC 2018, Eleventh International 
Conference on Language Resources and Evaluation, Phoenix Seagaia Conference Center, 
Miyazaki, Japan, pp. 1699-1704.
16 Dec 2020 18:26.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:26.27 [INFO ] ReferenceMarkerMatcher    -   Conneau, A., G. Kruszewski, G. Lample, L. Barrault, and M. Baroni 2018. What you 
can cram into a single vector: Probing sentence embeddings for linguistic properties. In 
ACL.
16 Dec 2020 18:26.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:26.33 [INFO ] ReferenceMarkerMatcher    -   Conneau, A. and D. Kiela 2018, May 7-12. SentEval: An evaluation toolkit for universal 
sentence representations. In N. Calzolari (Ed.), LREC 2018, Eleventh International 
Conference on Language Resources and Evaluation, Phoenix Seagaia Conference Center, 
Miyazaki, Japan, pp. 1699-1704.
16 Dec 2020 18:26.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:26.33 [INFO ] ReferenceMarkerMatcher    -   Conneau, A., G. Kruszewski, G. Lample, L. Barrault, and M. Baroni 2018. What you 
can cram into a single vector: Probing sentence embeddings for linguistic properties. In 
ACL.
16 Dec 2020 18:29.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:29.53 [INFO ] ReferenceMarkerMatcher    -   Feynman Liang. Bachbot: Automatic composition in the style of bach chorales. Masters thesis, 
University of Cambridge, 2016.
16 Dec 2020 18:29.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:29.53 [INFO ] ReferenceMarkerMatcher    -   Elliot Waite. Generating long-term structure in songs and stories. https://magenta. 
tensorflow.org/2016/07/15/lookback-rnn-attention-rnn, 2016.
16 Dec 2020 18:29.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:29.53 [INFO ] ReferenceMarkerMatcher    -   Gaëtan Hadjeres, Jason Sakellariou, and François Pachet. Style imitation and chord invention in 
polyphonic music with exponential families. arXiv preprint arXiv:1609.05152, 2016.
16 Dec 2020 18:29.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:29.53 [INFO ] ReferenceMarkerMatcher    -   Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention 
model for natural language inference. In Proceedings of the Conference on Empirical Methods in 
Natural Language Processing, 2016.
16 Dec 2020 18:29.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:29.53 [INFO ] ReferenceMarkerMatcher    -   Benigno Uria, Marc-Alexandre Côté, Karol Gregor, Iain Murray, and Hugo Larochelle. Neural 
autoregressive distribution estimation. The Journal of Machine Learning Research, 17(1):7184-
7220, 2016.
16 Dec 2020 18:29.58 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:29.58 [INFO ] ReferenceMarkerMatcher    -   Feynman Liang. Bachbot: Automatic composition in the style of bach chorales. Masters thesis, 
University of Cambridge, 2016.
16 Dec 2020 18:29.58 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:29.58 [INFO ] ReferenceMarkerMatcher    -   Elliot Waite. Generating long-term structure in songs and stories. https://magenta. 
tensorflow.org/2016/07/15/lookback-rnn-attention-rnn, 2016.
16 Dec 2020 18:29.58 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:29.58 [INFO ] ReferenceMarkerMatcher    -   Gaëtan Hadjeres, Jason Sakellariou, and François Pachet. Style imitation and chord invention in 
polyphonic music with exponential families. arXiv preprint arXiv:1609.05152, 2016.
16 Dec 2020 18:29.58 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:29.58 [INFO ] ReferenceMarkerMatcher    -   Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention 
model for natural language inference. In Proceedings of the Conference on Empirical Methods in 
Natural Language Processing, 2016.
16 Dec 2020 18:29.58 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:29.58 [INFO ] ReferenceMarkerMatcher    -   Benigno Uria, Marc-Alexandre Côté, Karol Gregor, Iain Murray, and Hugo Larochelle. Neural 
autoregressive distribution estimation. The Journal of Machine Learning Research, 17(1):7184-
7220, 2016.
16 Dec 2020 18:31.22 [ERROR] FullTextParser            - DocumentPointer for block 46 points to 296 token, but block token size is 243
16 Dec 2020 18:31.25 [ERROR] FullTextParser            - DocumentPointer for block 46 points to 296 token, but block token size is 243
16 Dec 2020 18:31.26 [ERROR] FullTextParser            - DocumentPointer for block 46 points to 296 token, but block token size is 243
16 Dec 2020 18:36.00 [ERROR] FullTextParser            - DocumentPointer for block 327 points to 43 token, but block token size is 37
16 Dec 2020 18:36.08 [ERROR] FullTextParser            - DocumentPointer for block 327 points to 43 token, but block token size is 37
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    -   [Seo et al. 2016] Seo, M.; Kembhavi, A.; Farhadi, A.; and 
Hajishirzi, H. 2016. Bidirectional attention flow for ma-
chine comprehension. arXiv preprint arXiv:1611.01603. 
[Shen et al. 2016] Shen, Y.; Huang, P.-S.; Gao, J.; and Chen, 
W. 2016. Reasonet: Learning to stop reading in machine 
comprehension. arXiv preprint arXiv:1609.05284. 
[Srivastava et al. 2014] Srivastava, N.; Hinton, G. E.; 
Krizhevsky, A.; Sutskever, I.; and Salakhutdinov, R.
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    -   [Huang et al. 2017] Huang, H.; Zhu, C.; Shen, Y.; and Chen, 
W. 
2017. 
Fusionnet: Fusing via fully-aware atten-
tion with application to machine comprehension. CoRR 
abs/1711.07341. 
[Huang, Liu, and Weinberger 2016] Huang, G.; Liu, Z.; and 
Weinberger, K. Q. 2016. Densely connected convolutional 
networks. CoRR abs/1608.06993. 
[Kingma and Ba 2014] Kingma, D. P., and Ba, J. 2014. 
Adam: A method for stochastic optimization. 
CoRR 
abs/1412.6980. 
[Kumar et al. 2015] Kumar, A.; Irsoy, O.; Su, J.; Bradbury, 
J.; English, R.; Pierce, B.; Ondruska, P.; Gulrajani, I.; and 
Socher, R. 2015. Ask me anything: Dynamic memory 
networks for natural language processing. arXiv preprint 
arXiv:1506.07285. 
[Lee et al. 2016] Lee, K.; Kwiatkowski, T.; Parikh, A. P.; and 
Das, D. 2016. Learning recurrent span representations for 
extractive question answering. CoRR abs/1611.01436. 
[Levy et al. 2017] Levy, O.; Seo, M.; Choi, E.; and Zettle-
moyer, L. 2017. Zero-shot relation extraction via reading 
comprehension. arXiv preprint arXiv:1706.04115. 
[Liu et al. 2017] Liu, X.; Shen, Y.; Duh, K.; and Gao, J. 
2017. Stochastic answer networks for machine reading com-
prehension. CoRR abs/1712.03556. 
[Pennington, Socher, and Manning 2014] Pennington, 
J.;
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    -   Vinyals, Fortunato, and Jaitly 2015] Vinyals, O.; Fortunato, 
M.; and Jaitly, N. 2015. Pointer Networks. ArXiv e-prints. 
[Wang and Jiang 2016] Wang, S., and Jiang, J. 2016. Ma-
chine comprehension using match-lstm and answer pointer. 
CoRR abs/1608.07905. 
[Wang et al. 2017] Wang, W.; Yang, N.; Wei, F.; Chang, B.; 
and Zhou, M. 2017. Gated self-matching networks for read-
ing comprehension and question answering. In Proceedings 
of the 55th Annual Meeting of the Association for Computa-
tional Linguistics, ACL 2017, Vancouver, Canada, July 30 -
August 4, Volume 1: Long Papers, 189-198.
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    -   [Huang et al. 2017] Huang, H.; Zhu, C.; Shen, Y.; and Chen, 
W. 
2017. 
Fusionnet: Fusing via fully-aware atten-
tion with application to machine comprehension. CoRR 
abs/1711.07341. 
[Huang, Liu, and Weinberger 2016] Huang, G.; Liu, Z.; and 
Weinberger, K. Q. 2016. Densely connected convolutional 
networks. CoRR abs/1608.06993. 
[Kingma and Ba 2014] Kingma, D. P., and Ba, J. 2014. 
Adam: A method for stochastic optimization. 
CoRR 
abs/1412.6980. 
[Kumar et al. 2015] Kumar, A.; Irsoy, O.; Su, J.; Bradbury, 
J.; English, R.; Pierce, B.; Ondruska, P.; Gulrajani, I.; and 
Socher, R. 2015. Ask me anything: Dynamic memory 
networks for natural language processing. arXiv preprint 
arXiv:1506.07285. 
[Lee et al. 2016] Lee, K.; Kwiatkowski, T.; Parikh, A. P.; and 
Das, D. 2016. Learning recurrent span representations for 
extractive question answering. CoRR abs/1611.01436. 
[Levy et al. 2017] Levy, O.; Seo, M.; Choi, E.; and Zettle-
moyer, L. 2017. Zero-shot relation extraction via reading 
comprehension. arXiv preprint arXiv:1706.04115. 
[Liu et al. 2017] Liu, X.; Shen, Y.; Duh, K.; and Gao, J. 
2017. Stochastic answer networks for machine reading com-
prehension. CoRR abs/1712.03556. 
[Pennington, Socher, and Manning 2014] Pennington, 
J.;
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    -   [Hu et al. 2017] Hu, M.; Peng, Y.; Huang, Z.; Qiu, X.; 
Wei, F.; and Zhou, M. 2017. Reinforced mnemonic 
reader for machine reading comprehension. arXiv preprint 
arXiv:1705.02798. 
[Hu et al. 2018] Hu, M.; Peng, Y.; Huang, Z.; Yang, N.; 
Zhou, M.; et al. 2018. Read+ verify: Machine reading 
comprehension with unanswerable questions. arXiv preprint 
arXiv:1808.05759.
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    -   [Chen et al. 2017] Chen, D.; Fisch, A.; Weston, J.; and Bor-
des, A. 2017. Reading wikipedia to answer open-domain 
questions. CoRR abs/1704.00051. 
[Clark and Gardner 2017] Clark, C., and Gardner, M. 2017. 
Simple and effective multi-paragraph reading comprehen-
sion. arXiv preprint arXiv:1710.10723. 
[Cui et al. 2016] Cui, Y.; Chen, Z.; Wei, S.; Wang, S.; Liu, 
T.; and Hu, G. 2016. Attention-over-attention neu-
ral networks for reading comprehension. arXiv preprint 
arXiv:1607.04423. 
[Dhingra et al. 2016] Dhingra, B.; Liu, H.; Cohen, W. W.; 
and Salakhutdinov, R. 2016. Gated-attention readers for 
text comprehension. arXiv preprint arXiv:1606.01549. 
[Hermann et al. 2015] Hermann, K. M.; Kocisky, T.; Grefen-
stette, E.; Espeholt, L.; Kay, W.; Suleyman, M.; and Blun-
som, P. 2015. Teaching machines to read and compre-
hend. In Advances in Neural Information Processing Sys-
tems, 1684-1692.
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    -   [Sukhbaatar et al. 2015] Sukhbaatar, S.; Weston, J.; Fergus, 
R.; et al. 2015. End-to-end memory networks. In Advances 
in Neural Information Processing Systems, 2431-2439. 
[Tan et al. 2018] Tan, C.; Wei, F.; Zhou, Q.; Yang, N.; Lv, 
W.; and Zhou, M. 2018. I know there is no answer: Model-
ing answer validation for machine reading comprehension. 
In CCF International Conference on Natural Language Pro-
cessing and Chinese Computing, 85-97. Springer. 
[Vaswani et al. 2017] Vaswani, A.; Shazeer, N.; Parmar, N.; 
Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and 
Polosukhin, I. 2017. Attention is all you need. CoRR 
abs/1706.03762.
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    -   , Yan, and Wu 2018] Wang, W.; Yan, M.; and Wu, C. 
2018. Multi-granularity hierarchical attention fusion net-
works for reading comprehension and question answering. 
In Proceedings of the 56th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long Papers), 
volume 1, 1705-1714.
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    -   [Peters et al. 2018] Peters, M. E.; Neumann, M.; Iyyer, M.; 
Gardner, M.; Clark, C.; Lee, K.; and Zettlemoyer, L. 2018. 
Deep contextualized word representations. In Proc. of 
NAACL. 
[Rajpurkar et al. 2016] Rajpurkar, P.; Zhang, J.; Lopyrev, 
K.; and Liang, P. 
2016. 
SQuAD: 100,000+ ques-
tions for machine comprehension of text. arXiv preprint 
arXiv:1606.05250. 
[Rajpurkar, Jia, and Liang 2018] Rajpurkar, P.; Jia, R.; and 
Liang, P. 2018. Know What You Don't Know: Unanswer-
able Questions for SQuAD. ArXiv e-prints.
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    -   [Hu et al. 2017] Hu, M.; Peng, Y.; Huang, Z.; Qiu, X.; 
Wei, F.; and Zhou, M. 2017. Reinforced mnemonic 
reader for machine reading comprehension. arXiv preprint 
arXiv:1705.02798. 
[Hu et al. 2018] Hu, M.; Peng, Y.; Huang, Z.; Yang, N.; 
Zhou, M.; et al. 2018. Read+ verify: Machine reading 
comprehension with unanswerable questions. arXiv preprint 
arXiv:1808.05759.
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.46 [INFO ] ReferenceMarkerMatcher    -   [Sukhbaatar et al. 2015] Sukhbaatar, S.; Weston, J.; Fergus, 
R.; et al. 2015. End-to-end memory networks. In Advances 
in Neural Information Processing Systems, 2431-2439. 
[Tan et al. 2018] Tan, C.; Wei, F.; Zhou, Q.; Yang, N.; Lv, 
W.; and Zhou, M. 2018. I know there is no answer: Model-
ing answer validation for machine reading comprehension. 
In CCF International Conference on Natural Language Pro-
cessing and Chinese Computing, 85-97. Springer. 
[Vaswani et al. 2017] Vaswani, A.; Shazeer, N.; Parmar, N.; 
Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and 
Polosukhin, I. 2017. Attention is all you need. CoRR 
abs/1706.03762.
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    -   [Seo et al. 2016] Seo, M.; Kembhavi, A.; Farhadi, A.; and 
Hajishirzi, H. 2016. Bidirectional attention flow for ma-
chine comprehension. arXiv preprint arXiv:1611.01603. 
[Shen et al. 2016] Shen, Y.; Huang, P.-S.; Gao, J.; and Chen, 
W. 2016. Reasonet: Learning to stop reading in machine 
comprehension. arXiv preprint arXiv:1609.05284. 
[Srivastava et al. 2014] Srivastava, N.; Hinton, G. E.; 
Krizhevsky, A.; Sutskever, I.; and Salakhutdinov, R.
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    -   [Huang et al. 2017] Huang, H.; Zhu, C.; Shen, Y.; and Chen, 
W. 
2017. 
Fusionnet: Fusing via fully-aware atten-
tion with application to machine comprehension. CoRR 
abs/1711.07341. 
[Huang, Liu, and Weinberger 2016] Huang, G.; Liu, Z.; and 
Weinberger, K. Q. 2016. Densely connected convolutional 
networks. CoRR abs/1608.06993. 
[Kingma and Ba 2014] Kingma, D. P., and Ba, J. 2014. 
Adam: A method for stochastic optimization. 
CoRR 
abs/1412.6980. 
[Kumar et al. 2015] Kumar, A.; Irsoy, O.; Su, J.; Bradbury, 
J.; English, R.; Pierce, B.; Ondruska, P.; Gulrajani, I.; and 
Socher, R. 2015. Ask me anything: Dynamic memory 
networks for natural language processing. arXiv preprint 
arXiv:1506.07285. 
[Lee et al. 2016] Lee, K.; Kwiatkowski, T.; Parikh, A. P.; and 
Das, D. 2016. Learning recurrent span representations for 
extractive question answering. CoRR abs/1611.01436. 
[Levy et al. 2017] Levy, O.; Seo, M.; Choi, E.; and Zettle-
moyer, L. 2017. Zero-shot relation extraction via reading 
comprehension. arXiv preprint arXiv:1706.04115. 
[Liu et al. 2017] Liu, X.; Shen, Y.; Duh, K.; and Gao, J. 
2017. Stochastic answer networks for machine reading com-
prehension. CoRR abs/1712.03556. 
[Pennington, Socher, and Manning 2014] Pennington, 
J.;
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    -   Vinyals, Fortunato, and Jaitly 2015] Vinyals, O.; Fortunato, 
M.; and Jaitly, N. 2015. Pointer Networks. ArXiv e-prints. 
[Wang and Jiang 2016] Wang, S., and Jiang, J. 2016. Ma-
chine comprehension using match-lstm and answer pointer. 
CoRR abs/1608.07905. 
[Wang et al. 2017] Wang, W.; Yang, N.; Wei, F.; Chang, B.; 
and Zhou, M. 2017. Gated self-matching networks for read-
ing comprehension and question answering. In Proceedings 
of the 55th Annual Meeting of the Association for Computa-
tional Linguistics, ACL 2017, Vancouver, Canada, July 30 -
August 4, Volume 1: Long Papers, 189-198.
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    -   [Huang et al. 2017] Huang, H.; Zhu, C.; Shen, Y.; and Chen, 
W. 
2017. 
Fusionnet: Fusing via fully-aware atten-
tion with application to machine comprehension. CoRR 
abs/1711.07341. 
[Huang, Liu, and Weinberger 2016] Huang, G.; Liu, Z.; and 
Weinberger, K. Q. 2016. Densely connected convolutional 
networks. CoRR abs/1608.06993. 
[Kingma and Ba 2014] Kingma, D. P., and Ba, J. 2014. 
Adam: A method for stochastic optimization. 
CoRR 
abs/1412.6980. 
[Kumar et al. 2015] Kumar, A.; Irsoy, O.; Su, J.; Bradbury, 
J.; English, R.; Pierce, B.; Ondruska, P.; Gulrajani, I.; and 
Socher, R. 2015. Ask me anything: Dynamic memory 
networks for natural language processing. arXiv preprint 
arXiv:1506.07285. 
[Lee et al. 2016] Lee, K.; Kwiatkowski, T.; Parikh, A. P.; and 
Das, D. 2016. Learning recurrent span representations for 
extractive question answering. CoRR abs/1611.01436. 
[Levy et al. 2017] Levy, O.; Seo, M.; Choi, E.; and Zettle-
moyer, L. 2017. Zero-shot relation extraction via reading 
comprehension. arXiv preprint arXiv:1706.04115. 
[Liu et al. 2017] Liu, X.; Shen, Y.; Duh, K.; and Gao, J. 
2017. Stochastic answer networks for machine reading com-
prehension. CoRR abs/1712.03556. 
[Pennington, Socher, and Manning 2014] Pennington, 
J.;
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    -   [Hu et al. 2017] Hu, M.; Peng, Y.; Huang, Z.; Qiu, X.; 
Wei, F.; and Zhou, M. 2017. Reinforced mnemonic 
reader for machine reading comprehension. arXiv preprint 
arXiv:1705.02798. 
[Hu et al. 2018] Hu, M.; Peng, Y.; Huang, Z.; Yang, N.; 
Zhou, M.; et al. 2018. Read+ verify: Machine reading 
comprehension with unanswerable questions. arXiv preprint 
arXiv:1808.05759.
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    -   [Chen et al. 2017] Chen, D.; Fisch, A.; Weston, J.; and Bor-
des, A. 2017. Reading wikipedia to answer open-domain 
questions. CoRR abs/1704.00051. 
[Clark and Gardner 2017] Clark, C., and Gardner, M. 2017. 
Simple and effective multi-paragraph reading comprehen-
sion. arXiv preprint arXiv:1710.10723. 
[Cui et al. 2016] Cui, Y.; Chen, Z.; Wei, S.; Wang, S.; Liu, 
T.; and Hu, G. 2016. Attention-over-attention neu-
ral networks for reading comprehension. arXiv preprint 
arXiv:1607.04423. 
[Dhingra et al. 2016] Dhingra, B.; Liu, H.; Cohen, W. W.; 
and Salakhutdinov, R. 2016. Gated-attention readers for 
text comprehension. arXiv preprint arXiv:1606.01549. 
[Hermann et al. 2015] Hermann, K. M.; Kocisky, T.; Grefen-
stette, E.; Espeholt, L.; Kay, W.; Suleyman, M.; and Blun-
som, P. 2015. Teaching machines to read and compre-
hend. In Advances in Neural Information Processing Sys-
tems, 1684-1692.
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    -   [Sukhbaatar et al. 2015] Sukhbaatar, S.; Weston, J.; Fergus, 
R.; et al. 2015. End-to-end memory networks. In Advances 
in Neural Information Processing Systems, 2431-2439. 
[Tan et al. 2018] Tan, C.; Wei, F.; Zhou, Q.; Yang, N.; Lv, 
W.; and Zhou, M. 2018. I know there is no answer: Model-
ing answer validation for machine reading comprehension. 
In CCF International Conference on Natural Language Pro-
cessing and Chinese Computing, 85-97. Springer. 
[Vaswani et al. 2017] Vaswani, A.; Shazeer, N.; Parmar, N.; 
Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and 
Polosukhin, I. 2017. Attention is all you need. CoRR 
abs/1706.03762.
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    -   , Yan, and Wu 2018] Wang, W.; Yan, M.; and Wu, C. 
2018. Multi-granularity hierarchical attention fusion net-
works for reading comprehension and question answering. 
In Proceedings of the 56th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long Papers), 
volume 1, 1705-1714.
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    -   [Peters et al. 2018] Peters, M. E.; Neumann, M.; Iyyer, M.; 
Gardner, M.; Clark, C.; Lee, K.; and Zettlemoyer, L. 2018. 
Deep contextualized word representations. In Proc. of 
NAACL. 
[Rajpurkar et al. 2016] Rajpurkar, P.; Zhang, J.; Lopyrev, 
K.; and Liang, P. 
2016. 
SQuAD: 100,000+ ques-
tions for machine comprehension of text. arXiv preprint 
arXiv:1606.05250. 
[Rajpurkar, Jia, and Liang 2018] Rajpurkar, P.; Jia, R.; and 
Liang, P. 2018. Know What You Don't Know: Unanswer-
able Questions for SQuAD. ArXiv e-prints.
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    -   [Hu et al. 2017] Hu, M.; Peng, Y.; Huang, Z.; Qiu, X.; 
Wei, F.; and Zhou, M. 2017. Reinforced mnemonic 
reader for machine reading comprehension. arXiv preprint 
arXiv:1705.02798. 
[Hu et al. 2018] Hu, M.; Peng, Y.; Huang, Z.; Yang, N.; 
Zhou, M.; et al. 2018. Read+ verify: Machine reading 
comprehension with unanswerable questions. arXiv preprint 
arXiv:1808.05759.
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:37.51 [INFO ] ReferenceMarkerMatcher    -   [Sukhbaatar et al. 2015] Sukhbaatar, S.; Weston, J.; Fergus, 
R.; et al. 2015. End-to-end memory networks. In Advances 
in Neural Information Processing Systems, 2431-2439. 
[Tan et al. 2018] Tan, C.; Wei, F.; Zhou, Q.; Yang, N.; Lv, 
W.; and Zhou, M. 2018. I know there is no answer: Model-
ing answer validation for machine reading comprehension. 
In CCF International Conference on Natural Language Pro-
cessing and Chinese Computing, 85-97. Springer. 
[Vaswani et al. 2017] Vaswani, A.; Shazeer, N.; Parmar, N.; 
Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and 
Polosukhin, I. 2017. Attention is all you need. CoRR 
abs/1706.03762.
16 Dec 2020 18:44.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:44.17 [INFO ] ReferenceMarkerMatcher    -   Wang, H., and Wang, L. 2017. Modeling temporal dynamics and 
spatial configurations of actions using two-stream recurrent neural 
networks. In e Conference on Computer Vision and Pa ern Recog-
nition (CVPR).
16 Dec 2020 18:44.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:44.17 [INFO ] ReferenceMarkerMatcher    -   Wang, H.; Wang, P.; Song, Z.; and Li, W. 2017. Large-scale multi-
modal gesture recognition using heterogeneous networks. In Pro-
ceedings of the IEEE Conference on Computer Vision and Pattern 
Recognition, 3129-3137.
16 Dec 2020 18:44.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:44.17 [INFO ] ReferenceMarkerMatcher    -   Yang, W.; Jin, L.; and Liu, M. 2015. Chinese character-level 
writer identification using path signature feature, dropstroke and 
deep cnn. In Document Analysis and Recognition (ICDAR), 2015 
13th International Conference on, 546-550. IEEE.
16 Dec 2020 18:44.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:44.17 [INFO ] ReferenceMarkerMatcher    -   Yang, W.; Jin, L.; Xie, Z.; and Feng, Z. 2015. Improved deep 
convolutional neural network for online handwritten chinese char-
acter recognition using domain-specific knowledge. arXiv preprint 
arXiv:1505.07675.
16 Dec 2020 18:44.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:44.24 [INFO ] ReferenceMarkerMatcher    -   Wang, H., and Wang, L. 2017. Modeling temporal dynamics and 
spatial configurations of actions using two-stream recurrent neural 
networks. In e Conference on Computer Vision and Pa ern Recog-
nition (CVPR).
16 Dec 2020 18:44.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:44.24 [INFO ] ReferenceMarkerMatcher    -   Wang, H.; Wang, P.; Song, Z.; and Li, W. 2017. Large-scale multi-
modal gesture recognition using heterogeneous networks. In Pro-
ceedings of the IEEE Conference on Computer Vision and Pattern 
Recognition, 3129-3137.
16 Dec 2020 18:44.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:44.24 [INFO ] ReferenceMarkerMatcher    -   Yang, W.; Jin, L.; and Liu, M. 2015. Chinese character-level 
writer identification using path signature feature, dropstroke and 
deep cnn. In Document Analysis and Recognition (ICDAR), 2015 
13th International Conference on, 546-550. IEEE.
16 Dec 2020 18:44.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:44.24 [INFO ] ReferenceMarkerMatcher    -   Yang, W.; Jin, L.; Xie, Z.; and Feng, Z. 2015. Improved deep 
convolutional neural network for online handwritten chinese char-
acter recognition using domain-specific knowledge. arXiv preprint 
arXiv:1505.07675.
16 Dec 2020 18:48.25 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:48.25 [INFO ] ReferenceMarkerMatcher    -   Zheng, Z.; Zheng, L.; and Yang, Y. 2016. Pedestrian 
alignment network for large-scale person re-identification. 
arXiv:1707.00408.
16 Dec 2020 18:48.25 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:48.25 [INFO ] ReferenceMarkerMatcher    -   Zheng, L.; Bie, Z.; Sun, Y.; Wang, J.; Su, C.; Wang, S.; and 
Tian, Q. 2016. Mars: A video benchmark for large-scale 
person re-identification. In ECCV.
16 Dec 2020 18:48.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:48.31 [INFO ] ReferenceMarkerMatcher    -   Zheng, Z.; Zheng, L.; and Yang, Y. 2016. Pedestrian 
alignment network for large-scale person re-identification. 
arXiv:1707.00408.
16 Dec 2020 18:48.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:48.31 [INFO ] ReferenceMarkerMatcher    -   Zheng, L.; Bie, Z.; Sun, Y.; Wang, J.; Su, C.; Wang, S.; and 
Tian, Q. 2016. Mars: A video benchmark for large-scale 
person re-identification. In ECCV.
16 Dec 2020 18:50.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:50.19 [INFO ] ReferenceMarkerMatcher    -   Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., Xu, B.: Joint Extraction of Entities and 
Relations Based on a Novel Tagging Scheme. In: Proceedings of the 55th Annual Meeting 
of the Association for Computational Linguistics (Volume 1: Long Papers). pp. 1227-1236 
(2017)
16 Dec 2020 18:50.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:50.19 [INFO ] ReferenceMarkerMatcher    -   Zheng, S., Hao, Y., Lu, D., Bao, H., Xu, J., Hao, H., Xu, B.: Joint entity and relation extrac-
tion based on a hybrid neural network. Neurocomputing 257, 59-66 (2017)
16 Dec 2020 18:50.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:50.19 [INFO ] ReferenceMarkerMatcher    -   Bekoulis, G., Deleu, J., Demeester, T., Develder, C.: Adversarial training for multi-context 
joint entity and relation extraction. In: Proceedings of the 2018 Conference on Empirical 
Methods in Natural Language Processing. pp. 2830-2836 (2018)
16 Dec 2020 18:50.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:50.19 [INFO ] ReferenceMarkerMatcher    -   Bekoulis, G., Deleu, J., Demeester, T., Develder, C.: Joint entity recognition and relation 
extraction as a multi-head selection problem. Expert Systems with Applications 114, 34 -45 
(2018)
16 Dec 2020 18:50.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:50.24 [INFO ] ReferenceMarkerMatcher    -   Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., Xu, B.: Joint Extraction of Entities and 
Relations Based on a Novel Tagging Scheme. In: Proceedings of the 55th Annual Meeting 
of the Association for Computational Linguistics (Volume 1: Long Papers). pp. 1227-1236 
(2017)
16 Dec 2020 18:50.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:50.24 [INFO ] ReferenceMarkerMatcher    -   Zheng, S., Hao, Y., Lu, D., Bao, H., Xu, J., Hao, H., Xu, B.: Joint entity and relation extrac-
tion based on a hybrid neural network. Neurocomputing 257, 59-66 (2017)
16 Dec 2020 18:50.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:50.24 [INFO ] ReferenceMarkerMatcher    -   Bekoulis, G., Deleu, J., Demeester, T., Develder, C.: Adversarial training for multi-context 
joint entity and relation extraction. In: Proceedings of the 2018 Conference on Empirical 
Methods in Natural Language Processing. pp. 2830-2836 (2018)
16 Dec 2020 18:50.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:50.24 [INFO ] ReferenceMarkerMatcher    -   Bekoulis, G., Deleu, J., Demeester, T., Develder, C.: Joint entity recognition and relation 
extraction as a multi-head selection problem. Expert Systems with Applications 114, 34 -45 
(2018)
16 Dec 2020 18:52.16 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:52.16 [INFO ] ReferenceMarkerMatcher    -   Chen, Q.; Ling, Z.; and Zhu, X. 2018. Enhancing sentence 
embedding with generalized pooling. In Proceedings of the 
27th International Conference on Computational Linguis-
tics, COLING 2018, 1815-1826.
16 Dec 2020 18:52.16 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:52.16 [INFO ] ReferenceMarkerMatcher    -   Chen, Q.; Zhu, X.; Ling, Z.; Inkpen, D.; and Wei, S. 2018. 
Neural natural language inference models enhanced with ex-
ternal knowledge. In Proceedings of the 56th Annual Meet-
ing of the Association for Computational Linguistics, ACL 
2018, 2406-2417.
16 Dec 2020 18:52.21 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:52.21 [INFO ] ReferenceMarkerMatcher    -   Chen, Q.; Ling, Z.; and Zhu, X. 2018. Enhancing sentence 
embedding with generalized pooling. In Proceedings of the 
27th International Conference on Computational Linguis-
tics, COLING 2018, 1815-1826.
16 Dec 2020 18:52.21 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:52.21 [INFO ] ReferenceMarkerMatcher    -   Chen, Q.; Zhu, X.; Ling, Z.; Inkpen, D.; and Wei, S. 2018. 
Neural natural language inference models enhanced with ex-
ternal knowledge. In Proceedings of the 56th Annual Meet-
ing of the Association for Computational Linguistics, ACL 
2018, 2406-2417.
16 Dec 2020 18:53.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:53.00 [INFO ] ReferenceMarkerMatcher    -   Zhao, H.; Chen, W.; and Kit, C. 2009. Semantic de-
pendency parsing of NomBank and PropBank: An efficient 
integrated approach via a large-scale feature selection. In 
EMNLP.
16 Dec 2020 18:53.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:53.00 [INFO ] ReferenceMarkerMatcher    -   Zhao, H.; Chen, W.; Kazama, J.; Uchimoto, K.; and 
Torisawa, K. 2009. Multilingual dependency learning: Ex-
ploiting rich features for tagging syntactic and semantic de-
pendencies. In CoNLL.
16 Dec 2020 18:53.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:53.00 [INFO ] ReferenceMarkerMatcher    -   Marcheggiani, D., and Titov, I. 2017. Encoding sen-
tences with graph convolutional networks for semantic role 
labeling. In EMNLP.
16 Dec 2020 18:53.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:53.00 [INFO ] ReferenceMarkerMatcher    -   Marcheggiani, D.; Frolov, A.; and Titov, I. 2017. 
A simple and accurate syntax-agnostic neural model for 
dependency-based semantic role labeling. In CoNLL.
16 Dec 2020 18:53.06 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:53.06 [INFO ] ReferenceMarkerMatcher    -   Zhao, H.; Chen, W.; and Kit, C. 2009. Semantic de-
pendency parsing of NomBank and PropBank: An efficient 
integrated approach via a large-scale feature selection. In 
EMNLP.
16 Dec 2020 18:53.06 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:53.06 [INFO ] ReferenceMarkerMatcher    -   Zhao, H.; Chen, W.; Kazama, J.; Uchimoto, K.; and 
Torisawa, K. 2009. Multilingual dependency learning: Ex-
ploiting rich features for tagging syntactic and semantic de-
pendencies. In CoNLL.
16 Dec 2020 18:53.06 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:53.06 [INFO ] ReferenceMarkerMatcher    -   Marcheggiani, D., and Titov, I. 2017. Encoding sen-
tences with graph convolutional networks for semantic role 
labeling. In EMNLP.
16 Dec 2020 18:53.06 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:53.06 [INFO ] ReferenceMarkerMatcher    -   Marcheggiani, D.; Frolov, A.; and Titov, I. 2017. 
A simple and accurate syntax-agnostic neural model for 
dependency-based semantic role labeling. In CoNLL.
16 Dec 2020 18:56.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:56.17 [INFO ] ReferenceMarkerMatcher    -   Kiros, R.; Salakhutdinov, R.; and Zemel, R. S. 2015. Uni-
fying visual-semantic embeddings with multimodal neural 
language models. TACL.
16 Dec 2020 18:56.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:56.17 [INFO ] ReferenceMarkerMatcher    -   Kiros, R.; Zhu, Y.; Salakhutdinov, R.; Zemel, R. S.; Torralba, 
A.; Urtasun, R.; and Fidler, S. 2015. Skip-thought vectors. 
In NIPS.
16 Dec 2020 18:56.22 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:56.22 [INFO ] ReferenceMarkerMatcher    -   Kiros, R.; Salakhutdinov, R.; and Zemel, R. S. 2015. Uni-
fying visual-semantic embeddings with multimodal neural 
language models. TACL.
16 Dec 2020 18:56.22 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 18:56.22 [INFO ] ReferenceMarkerMatcher    -   Kiros, R.; Zhu, Y.; Salakhutdinov, R.; Zemel, R. S.; Torralba, 
A.; Urtasun, R.; and Fidler, S. 2015. Skip-thought vectors. 
In NIPS.
16 Dec 2020 19:02.39 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 19:02.39 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 19:02.39 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 19:02.39 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 19:02.44 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 19:02.44 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 19:02.44 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 19:02.44 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 19:13.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:13.19 [INFO ] ReferenceMarkerMatcher    -   Yao, K.-L. and Li, W.-J. Convolutional geometric matrix 
completion. arXiv preprint arXiv:1803.00754, 2018.
16 Dec 2020 19:13.19 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:13.19 [INFO ] ReferenceMarkerMatcher    -   Yao, L., Mao, C., and Luo, Y. Graph convolutional networks 
for text classification. arXiv preprint arXiv:1809.05679, 
2018.
16 Dec 2020 19:13.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:13.26 [INFO ] ReferenceMarkerMatcher    -   Yao, K.-L. and Li, W.-J. Convolutional geometric matrix 
completion. arXiv preprint arXiv:1803.00754, 2018.
16 Dec 2020 19:13.26 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:13.26 [INFO ] ReferenceMarkerMatcher    -   Yao, L., Mao, C., and Luo, Y. Graph convolutional networks 
for text classification. arXiv preprint arXiv:1809.05679, 
2018.
16 Dec 2020 19:20.14 [ERROR] FullTextParser            - DocumentPointer for block 83 points to 137 token, but block token size is 125
16 Dec 2020 19:20.21 [ERROR] FullTextParser            - DocumentPointer for block 83 points to 137 token, but block token size is 125
16 Dec 2020 19:20.24 [ERROR] FullTextParser            - DocumentPointer for block 83 points to 137 token, but block token size is 125
16 Dec 2020 19:29.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:29.52 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2300 0.243 4.27 44.1 53.2 
323 0.279 19.8 37.6 44.1
16 Dec 2020 19:29.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:29.52 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2100 0.401 34.4 47.2 50.1 
6.8 0.309 0.9 64.3 84.1
16 Dec 2020 19:29.58 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:29.58 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2300 0.243 4.27 44.1 53.2 
323 0.279 19.8 37.6 44.1
16 Dec 2020 19:29.58 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:29.58 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2100 0.401 34.4 47.2 50.1 
6.8 0.309 0.9 64.3 84.1
16 Dec 2020 19:30.06 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:30.06 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2300 0.243 4.27 44.1 53.2 
323 0.279 19.8 37.6 44.1
16 Dec 2020 19:30.06 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:30.06 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2100 0.401 34.4 47.2 50.1 
6.8 0.309 0.9 64.3 84.1
16 Dec 2020 19:30.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:30.12 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2300 0.243 4.27 44.1 53.2 
323 0.279 19.8 37.6 44.1
16 Dec 2020 19:30.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:30.12 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2100 0.401 34.4 47.2 50.1 
6.8 0.309 0.9 64.3 84.1
16 Dec 2020 19:37.24 [WARN ] GrobidHomeFinder          - No Grobid property was provided. Attempting to find Grobid home in the current directory...
16 Dec 2020 19:37.24 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 19:37.24 [WARN ] GrobidHomeFinder          - *** USING GROBID HOME: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home
16 Dec 2020 19:37.24 [WARN ] GrobidHomeFinder          - ***************************************************************
16 Dec 2020 19:37.24 [WARN ] GrobidHomeFinder          - Grobid property file location was not explicitly set via 'org.grobid.property' system variable, defaulting to: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\config\grobid.properties
16 Dec 2020 19:37.24 [INFO ] LibraryLoader             - Loading external native CRF library
16 Dec 2020 19:37.24 [INFO ] LibraryLoader             - Loading Wapiti native library...
16 Dec 2020 19:37.24 [INFO ] LibraryLoader             - Library crfpp loaded
16 Dec 2020 19:37.25 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\fulltext\model.wapiti (size: 20462507)
16 Dec 2020 19:37.31 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\segmentation\model.wapiti (size: 15807193)
16 Dec 2020 19:37.35 [INFO ] Lexicon                   - Initiating dictionary
16 Dec 2020 19:37.35 [INFO ] Lexicon                   - End of Initialization of dictionary
16 Dec 2020 19:37.35 [INFO ] Lexicon                   - Initiating names
16 Dec 2020 19:37.35 [INFO ] Lexicon                   - End of initialization of names
16 Dec 2020 19:37.36 [INFO ] Lexicon                   - Initiating country codes
16 Dec 2020 19:37.36 [INFO ] Lexicon                   - End of initialization of country codes
16 Dec 2020 19:37.39 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\figure\model.wapiti (size: 679648)
16 Dec 2020 19:37.40 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\table\model.wapiti (size: 1337339)
16 Dec 2020 19:37.40 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\header\model.wapiti (size: 36094028)
16 Dec 2020 19:37.51 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\header\model.wapiti (size: 2225578)
16 Dec 2020 19:37.52 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\name\citation\model.wapiti (size: 393118)
16 Dec 2020 19:37.52 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\affiliation-address\model.wapiti (size: 2700194)
16 Dec 2020 19:37.56 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\date\model.wapiti (size: 102435)
16 Dec 2020 19:37.57 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\citation\model.wapiti (size: 16235248)
16 Dec 2020 19:38.01 [INFO ] WapitiModel               - Loading model: U:\Documents\ORKG\NLP\task-dataset-metric-extraction\..\grobid-0.5.3\grobid-home\models\reference-segmenter\model.wapiti (size: 4829569)
16 Dec 2020 19:54.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:54.17 [INFO ] ReferenceMarkerMatcher    -   Bengio, Y, Ducharme, R, and Vincent, P. A neural probabilis-
tic language model. Journal of Machine Learning Research, 
2003. URL http://ukpmc.ac.uk/abstract/CIT/ 
412956.
16 Dec 2020 19:54.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:54.17 [INFO ] ReferenceMarkerMatcher    -   Bengio, Yoshua and Senecal, J-S. Adaptive importance sampling 
to accelerate training of a neural probabilistic language model. 
Neural Networks, IEEE Transactions on, 19(4):713-722, 2008. 
Och, Franz Josef and Ney, Hermann. A systematic comparison of 
various statistical alignment models. Computational Linguis-
tics, 29(1):19-51, 2003.
16 Dec 2020 19:54.22 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:54.22 [INFO ] ReferenceMarkerMatcher    -   Bengio, Y, Ducharme, R, and Vincent, P. A neural probabilis-
tic language model. Journal of Machine Learning Research, 
2003. URL http://ukpmc.ac.uk/abstract/CIT/ 
412956.
16 Dec 2020 19:54.22 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:54.22 [INFO ] ReferenceMarkerMatcher    -   Bengio, Yoshua and Senecal, J-S. Adaptive importance sampling 
to accelerate training of a neural probabilistic language model. 
Neural Networks, IEEE Transactions on, 19(4):713-722, 2008. 
Och, Franz Josef and Ney, Hermann. A systematic comparison of 
various statistical alignment models. Computational Linguis-
tics, 29(1):19-51, 2003.
16 Dec 2020 19:59.04 [ERROR] FullTextParser            - DocumentPointer for block 14 points to 50 token, but block token size is 49
16 Dec 2020 19:59.11 [ERROR] FullTextParser            - DocumentPointer for block 14 points to 50 token, but block token size is 49
16 Dec 2020 19:59.14 [ERROR] FullTextParser            - DocumentPointer for block 14 points to 50 token, but block token size is 49
16 Dec 2020 19:59.34 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:59.34 [INFO ] ReferenceMarkerMatcher    -   Srivastava, Nitish and Salakhutdinov, Ruslan. Discriminative transfer learning with tree-based pri-
ors. In NIPS. 2013.
16 Dec 2020 19:59.34 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:59.34 [INFO ] ReferenceMarkerMatcher    -   Srivastava, Rupesh K, Masci, Jonathan, Kazerounian, Sohrob, Gomez, Faustino, and Schmidhuber, 
Jürgen. Compete to compute. In NIPS. 2013.
16 Dec 2020 19:59.34 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:59.34 [INFO ] ReferenceMarkerMatcher    -   Simonyan, Karen and Zisserman, Andrew. Very deep convolutional networks for large-scale image 
recognition. In arxiv:cs/arXiv:1409.1556, 2014.
16 Dec 2020 19:59.34 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:59.34 [INFO ] ReferenceMarkerMatcher    -   Simonyan, Karen, Vedaldi, Andrea, and Zisserman, Andrew. Deep inside convolutional networks: 
Visualising image classification models and saliency maps. In 1312.6034, also appeared at ICLR 
Workshop 2014, 2014. URL http://arxiv.org/abs/1312.6034.
16 Dec 2020 19:59.40 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:59.40 [INFO ] ReferenceMarkerMatcher    -   Srivastava, Nitish and Salakhutdinov, Ruslan. Discriminative transfer learning with tree-based pri-
ors. In NIPS. 2013.
16 Dec 2020 19:59.40 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:59.40 [INFO ] ReferenceMarkerMatcher    -   Srivastava, Rupesh K, Masci, Jonathan, Kazerounian, Sohrob, Gomez, Faustino, and Schmidhuber, 
Jürgen. Compete to compute. In NIPS. 2013.
16 Dec 2020 19:59.40 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:59.40 [INFO ] ReferenceMarkerMatcher    -   Simonyan, Karen and Zisserman, Andrew. Very deep convolutional networks for large-scale image 
recognition. In arxiv:cs/arXiv:1409.1556, 2014.
16 Dec 2020 19:59.40 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 19:59.40 [INFO ] ReferenceMarkerMatcher    -   Simonyan, Karen, Vedaldi, Andrea, and Zisserman, Andrew. Deep inside convolutional networks: 
Visualising image classification models and saliency maps. In 1312.6034, also appeared at ICLR 
Workshop 2014, 2014. URL http://arxiv.org/abs/1312.6034.
16 Dec 2020 20:00.01 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:00.01 [INFO ] ReferenceMarkerMatcher    -   Chen, X. and Yuille, A. L. Articulated pose estimation by a graphical model with image dependent 
pairwise relations. In NIPS, 2014.
16 Dec 2020 20:00.01 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:00.01 [INFO ] ReferenceMarkerMatcher    -   Chen, L.-C., Schwing, A., Yuille, A., and Urtasun, R. Learning deep structured models. 
arXiv:1407.2538, 2014.
16 Dec 2020 20:00.08 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:00.08 [INFO ] ReferenceMarkerMatcher    -   Chen, X. and Yuille, A. L. Articulated pose estimation by a graphical model with image dependent 
pairwise relations. In NIPS, 2014.
16 Dec 2020 20:00.08 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:00.08 [INFO ] ReferenceMarkerMatcher    -   Chen, L.-C., Schwing, A., Yuille, A., and Urtasun, R. Learning deep structured models. 
arXiv:1407.2538, 2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.24 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Mnih, Andriy and Gregor, Karol. Neural variational infer-
ence and learning in belief networks. In Proceedings of 
the 31st International Conference on Machine Learning, 
2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Ba, Jimmy, Mnih, Volodymyr, and Kavukcuoglu, Koray. 
Multiple object recognition with visual attention. arXiv 
preprint arXiv:1412.7755, 2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, et al. Re-
current models of visual attention. In Advances in Neural 
Information Processing Systems, pp. 2204-2212, 2014.
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:03.29 [INFO ] ReferenceMarkerMatcher    -   Gregor, Karol, Danihelka, Ivo, Mnih, Andriy, Blundell, 
Charles, and Wierstra, Daan. Deep autoregressive net-
works. In Proceedings of the 31st International Confer-
ence on Machine Learning, 2014.
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.17 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding variational bayes. International Conference 
on Learning Representations (ICLR), 2014.
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:26.28 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, Danilo Jimenez, and Welling, Max. Semi-
supervised learning with deep generative models. In Advances in Neural Information Processing 
Systems, pp. 3581-3589, 2014.
16 Dec 2020 20:28.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:28.56 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding 
variational bayes. In Proceedings of ICLR, 2014.
16 Dec 2020 20:28.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:28.56 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Proceedings 
of NIPS, 2014.
16 Dec 2020 20:28.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:28.56 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding 
variational bayes. In Proceedings of ICLR, 2014.
16 Dec 2020 20:28.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:28.56 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Proceedings 
of NIPS, 2014.
16 Dec 2020 20:29.05 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:29.05 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding 
variational bayes. In Proceedings of ICLR, 2014.
16 Dec 2020 20:29.05 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:29.05 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Proceedings 
of NIPS, 2014.
16 Dec 2020 20:29.05 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:29.05 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P and Welling, Max. Auto-encoding 
variational bayes. In Proceedings of ICLR, 2014.
16 Dec 2020 20:29.05 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:29.05 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Proceedings 
of NIPS, 2014.
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    -   Hochreiter, S. The vanishing gradient problem during learning recurrent neural nets and problem solutions. 
International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(2):107-116, 1998.
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    -   Schraudolph, N. N. Centering neural network gradient factor. In Orr, G. B. and Müller, K.-R. (eds.), Neural 
Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 207-226. Springer, 
1998.
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    -   Yang, H. H. and Amari, S.-I. Complexity issues in natural gradient descent method for training multilayer 
perceptrons. Neural Computation, 10(8), 1998.
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    -   Amari, S.-I. Natural gradient works efficiently in learning. Neural Computation, 10(2):251-276, 1998. 
Clevert, D.-A., Unterthiner, T., Mayr, A., and Hochreiter, S. Rectified factor networks. In Cortes, C., Lawrence, 
N. D., Lee, D. D., Sugiyama, M., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 
28. Curran Associates, Inc., 2015.
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    -   LeCun, Y., Bottou, L., Orr, G. B., and Müller, K.-R. Efficient backprop. In Orr, G. B. and Müller, K.-R. 
(eds.), Neural Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 9-50. 
Springer, 1998.
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    -   Hochreiter, S. The vanishing gradient problem during learning recurrent neural nets and problem solutions. 
International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(2):107-116, 1998.
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    -   Schraudolph, N. N. Centering neural network gradient factor. In Orr, G. B. and Müller, K.-R. (eds.), Neural 
Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 207-226. Springer, 
1998.
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    -   Yang, H. H. and Amari, S.-I. Complexity issues in natural gradient descent method for training multilayer 
perceptrons. Neural Computation, 10(8), 1998.
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    -   Amari, S.-I. Natural gradient works efficiently in learning. Neural Computation, 10(2):251-276, 1998. 
Clevert, D.-A., Unterthiner, T., Mayr, A., and Hochreiter, S. Rectified factor networks. In Cortes, C., Lawrence, 
N. D., Lee, D. D., Sugiyama, M., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 
28. Curran Associates, Inc., 2015.
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.37 [INFO ] ReferenceMarkerMatcher    -   LeCun, Y., Bottou, L., Orr, G. B., and Müller, K.-R. Efficient backprop. In Orr, G. B. and Müller, K.-R. 
(eds.), Neural Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 9-50. 
Springer, 1998.
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    -   Hochreiter, S. The vanishing gradient problem during learning recurrent neural nets and problem solutions. 
International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(2):107-116, 1998.
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    -   Schraudolph, N. N. Centering neural network gradient factor. In Orr, G. B. and Müller, K.-R. (eds.), Neural 
Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 207-226. Springer, 
1998.
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    -   Yang, H. H. and Amari, S.-I. Complexity issues in natural gradient descent method for training multilayer 
perceptrons. Neural Computation, 10(8), 1998.
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    -   Amari, S.-I. Natural gradient works efficiently in learning. Neural Computation, 10(2):251-276, 1998. 
Clevert, D.-A., Unterthiner, T., Mayr, A., and Hochreiter, S. Rectified factor networks. In Cortes, C., Lawrence, 
N. D., Lee, D. D., Sugiyama, M., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 
28. Curran Associates, Inc., 2015.
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    -   LeCun, Y., Bottou, L., Orr, G. B., and Müller, K.-R. Efficient backprop. In Orr, G. B. and Müller, K.-R. 
(eds.), Neural Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 9-50. 
Springer, 1998.
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    -   Hochreiter, S. The vanishing gradient problem during learning recurrent neural nets and problem solutions. 
International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(2):107-116, 1998.
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    -   Schraudolph, N. N. Centering neural network gradient factor. In Orr, G. B. and Müller, K.-R. (eds.), Neural 
Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 207-226. Springer, 
1998.
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    -   Yang, H. H. and Amari, S.-I. Complexity issues in natural gradient descent method for training multilayer 
perceptrons. Neural Computation, 10(8), 1998.
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    -   Amari, S.-I. Natural gradient works efficiently in learning. Neural Computation, 10(2):251-276, 1998. 
Clevert, D.-A., Unterthiner, T., Mayr, A., and Hochreiter, S. Rectified factor networks. In Cortes, C., Lawrence, 
N. D., Lee, D. D., Sugiyama, M., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 
28. Curran Associates, Inc., 2015.
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:30.43 [INFO ] ReferenceMarkerMatcher    -   LeCun, Y., Bottou, L., Orr, G. B., and Müller, K.-R. Efficient backprop. In Orr, G. B. and Müller, K.-R. 
(eds.), Neural Networks: Tricks of the Trade, volume 1524 of Lecture Notes in Computer Science, pp. 9-50. 
Springer, 1998.
16 Dec 2020 20:35.42 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:35.42 [INFO ] ReferenceMarkerMatcher    -   [Luong et al.2015] Thang Luong, Ilya Sutskever, 
Quoc V. Le, Oriol Vinyals, and Wojciech Zaremba. 
2015. Addressing the rare word problem in neural 
machine translation. In Proceedings of the 53rd
16 Dec 2020 20:35.42 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:35.42 [INFO ] ReferenceMarkerMatcher    -   [Li et al.2015] Jiwei Li, Minh-Thang Luong, and Dan 
Jurafsky. 2015. A hierarchical neural autoen-
coder for paragraphs and documents. 
CoRR, 
abs/1506.01057. 
[Wong et al.2008a] Kam-Fai Wong, Mingli Wu, and 
Wenjie Li. 2008a. Extractive summarization using 
supervised and semi-supervised learning. In Pro-
ceedings of the 22Nd International Conference on 
Computational Linguistics -Volume 1, pages 985-
992.
16 Dec 2020 20:35.49 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:35.49 [INFO ] ReferenceMarkerMatcher    -   [Luong et al.2015] Thang Luong, Ilya Sutskever, 
Quoc V. Le, Oriol Vinyals, and Wojciech Zaremba. 
2015. Addressing the rare word problem in neural 
machine translation. In Proceedings of the 53rd
16 Dec 2020 20:35.49 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:35.49 [INFO ] ReferenceMarkerMatcher    -   [Li et al.2015] Jiwei Li, Minh-Thang Luong, and Dan 
Jurafsky. 2015. A hierarchical neural autoen-
coder for paragraphs and documents. 
CoRR, 
abs/1506.01057. 
[Wong et al.2008a] Kam-Fai Wong, Mingli Wu, and 
Wenjie Li. 2008a. Extractive summarization using 
supervised and semi-supervised learning. In Pro-
ceedings of the 22Nd International Conference on 
Computational Linguistics -Volume 1, pages 985-
992.
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    -   DT42. Squeezenet keras implementation. https://github.com/DT42/squeezenet_ 
demo, 2016.
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    -   Guo Haria. convert squeezenet to mxnet. https://github.com/haria/SqueezeNet/ 
commit/0cf57539375fd5429275af36fc94c774503427c3, 2016.
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    -   Eddie Bell. A implementation of squeezenet in chainer. https://github.com/ejlb/ 
squeezenet-chainer, 2016.
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    -   Francois Chollet. Keras: Deep learning library for theano and tensorflow. https://keras.io, 
2016.
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    -   David Gschwend. Zynqnet: An fpga-accelerated embedded convolutional neural network. Master's 
thesis, Swiss Federal Institute of Technology Zurich (ETH-Zurich), 2016.
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    -   Philipp Gysel. Ristretto: Hardware-oriented approximation of convolutional neural networks. 
arXiv:1605.06402, 2016.
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    -   Sagar M Waghmare. FireModule.lua. https://github.com/Element-Research/dpnn/ 
blob/master/FireModule.lua, 2016.
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    -   Ronan Collobert, Koray Kavukcuoglu, and Clement Farabet. Torch7: A matlab-like environment 
for machine learning. In NIPS BigLearn Workshop, 2011. 
Consumer 
Reports. 
Teslas 
new 
autopilot: 
Better 
but 
still 
needs 
improvement. 
http://www.consumerreports.org/tesla/ 
tesla-new-autopilot-better-but-needs-improvement, 2016.
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    -   Dmytro Mishkin, Nikolay Sergievskiy, and Jiri Matas. Systematic evaluation of cnn advances on 
the imagenet. arXiv:1606.02228, 2016.
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.12 [INFO ] ReferenceMarkerMatcher    -   Christian Szegedy, Sergey Ioffe, and Vincent Vanhoucke. Inception-v4, inception-resnet and the 
impact of residual connections on learning. arXiv:1602.07261, 2016.
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    -   DT42. Squeezenet keras implementation. https://github.com/DT42/squeezenet_ 
demo, 2016.
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    -   Guo Haria. convert squeezenet to mxnet. https://github.com/haria/SqueezeNet/ 
commit/0cf57539375fd5429275af36fc94c774503427c3, 2016.
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    -   Eddie Bell. A implementation of squeezenet in chainer. https://github.com/ejlb/ 
squeezenet-chainer, 2016.
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    -   Francois Chollet. Keras: Deep learning library for theano and tensorflow. https://keras.io, 
2016.
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    -   David Gschwend. Zynqnet: An fpga-accelerated embedded convolutional neural network. Master's 
thesis, Swiss Federal Institute of Technology Zurich (ETH-Zurich), 2016.
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    -   Philipp Gysel. Ristretto: Hardware-oriented approximation of convolutional neural networks. 
arXiv:1605.06402, 2016.
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    -   Sagar M Waghmare. FireModule.lua. https://github.com/Element-Research/dpnn/ 
blob/master/FireModule.lua, 2016.
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    -   Ronan Collobert, Koray Kavukcuoglu, and Clement Farabet. Torch7: A matlab-like environment 
for machine learning. In NIPS BigLearn Workshop, 2011. 
Consumer 
Reports. 
Teslas 
new 
autopilot: 
Better 
but 
still 
needs 
improvement. 
http://www.consumerreports.org/tesla/ 
tesla-new-autopilot-better-but-needs-improvement, 2016.
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    -   Dmytro Mishkin, Nikolay Sergievskiy, and Jiri Matas. Systematic evaluation of cnn advances on 
the imagenet. arXiv:1606.02228, 2016.
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:36.18 [INFO ] ReferenceMarkerMatcher    -   Christian Szegedy, Sergey Ioffe, and Vincent Vanhoucke. Inception-v4, inception-resnet and the 
impact of residual connections on learning. arXiv:1602.07261, 2016.
16 Dec 2020 20:46.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:46.17 [INFO ] ReferenceMarkerMatcher    -   Song, Le and Dai, Bo. Robust low rank kernel embeddings 
of multivariate distributions. In Advances in Neural In-
formation Processing Systems (NIPS), pp. 3228-3236, 
2013.
16 Dec 2020 20:46.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:46.17 [INFO ] ReferenceMarkerMatcher    -   Song, Le, Fukumizu, Kenji, and Gretton, Arthur. Kernel 
embeddings of conditional distributions: A unified kernel 
framework for nonparametric inference in graphical mod-
els. IEEE Signal Processing Magazine, 30(4):98-111, 
2013.
16 Dec 2020 20:46.25 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:46.25 [INFO ] ReferenceMarkerMatcher    -   Song, Le and Dai, Bo. Robust low rank kernel embeddings 
of multivariate distributions. In Advances in Neural In-
formation Processing Systems (NIPS), pp. 3228-3236, 
2013.
16 Dec 2020 20:46.25 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 20:46.25 [INFO ] ReferenceMarkerMatcher    -   Song, Le, Fukumizu, Kenji, and Gretton, Arthur. Kernel 
embeddings of conditional distributions: A unified kernel 
framework for nonparametric inference in graphical mod-
els. IEEE Signal Processing Magazine, 30(4):98-111, 
2013.
16 Dec 2020 20:59.53 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 20:59.53 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 20:59.59 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 20:59.59 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 21:06.39 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:06.39 [INFO ] ReferenceMarkerMatcher    -   Related Work 
Natural language sentence matching (NLSM) has been stud-
ied for many years. Early approaches focused on designing 
hand-craft features to capture n-gram overlapping, word re-
ordering and syntactic alignments phenomena [Heilman and 
Smith, 2010; Wang and Ittycheriah, 2015]. This kind of 
method can work well on a specific task or dataset, but it's 
hard to generalize well to other tasks. 
With the availability of large-scale annotated 
datasets [Bowman et al., 2015], many deep learning models 
were proposed for NLSM. The first kind of framework 
is based the Siamese architecture [Bromley et al., 1993], 
where sentences are encoded into sentence vectors based 
on some neural network encoders, and then the relationship 
between two sentences was decided solely based on the two 
sentence vectors [Bowman et al., 2015; Yang et al., 2015;
16 Dec 2020 21:06.39 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:06.39 [INFO ] ReferenceMarkerMatcher    -   However, this kind of framework ignores 
the fact that the lower level interactive features between two 
4 [Rao et al., 2016] pointed out that there are two versions of 
TREC-QA dataset: raw-version and clean-version. In this work, 
we utilized the clean-version. Therefore, we only compare with ap-
proaches reporting performance on this dataset. 
5 http://trec.nist.gove/trec eval/ 
[Bowman et al., 2015] Samuel R Bowman, Gabor Angeli, 
Christopher Potts, and Christopher D Manning. A large 
annotated corpus for learning natural language inference. 
arXiv preprint arXiv:1508.05326, 2015. 
[Bromley et al., 1993] Jane Bromley, James W. Bentz, Léon 
Bottou, Isabelle Guyon, Yann LeCun, Cliff Moore, Eduard 
Säckinger, and Roopak Shah. Signature verification using 
a "siamese" time delay neural network. IJPRAI, 7(4):669-
688, 1993. 
[Chen et al., 2016] Qian Chen, Xiaodan Zhu, Zhenhua Ling, 
Si Wei, and Hui Jiang. Enhancing and combining sequen-
tial and tree lstm for natural language inference. arXiv 
preprint arXiv:1609.06038, 2016. 
[Cheng et al., 2016] Jianpeng Cheng, Li Dong, and Mirella 
Lapata. Long short-term memory-networks for machine 
reading. arXiv preprint arXiv:1601.06733, 2016. 
[He and Lin, 2016] Hua He and Jimmy Lin. Pairwise word 
interaction modeling with deep neural networks for se-
mantic similarity measurement. In NAACL, 2016. 
[Heilman and Smith, 2010] Michael Heilman and Noah A 
Smith. Tree edit models for recognizing textual entail-
ments, paraphrases, and answers to questions. In NAACL, 
2010. 
[Hochreiter and Schmidhuber, 1997] Sepp Hochreiter and 
Jürgen Schmidhuber. Long short-term memory. Neural 
computation, 9(8):1735-1780, 1997. 
[Kingma and Ba, 2014] Diederik Kingma and Jimmy Ba. 
Adam: A method for stochastic optimization. arXiv 
preprint arXiv:1412.6980, 2014. 
[LeCun et al., 2015] Yann LeCun, Yoshua Bengio, and Ge-
offrey Hinton. Deep learning. Nature, 521(7553):436-
444, 2015.
16 Dec 2020 21:06.44 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:06.44 [INFO ] ReferenceMarkerMatcher    -   Related Work 
Natural language sentence matching (NLSM) has been stud-
ied for many years. Early approaches focused on designing 
hand-craft features to capture n-gram overlapping, word re-
ordering and syntactic alignments phenomena [Heilman and 
Smith, 2010; Wang and Ittycheriah, 2015]. This kind of 
method can work well on a specific task or dataset, but it's 
hard to generalize well to other tasks. 
With the availability of large-scale annotated 
datasets [Bowman et al., 2015], many deep learning models 
were proposed for NLSM. The first kind of framework 
is based the Siamese architecture [Bromley et al., 1993], 
where sentences are encoded into sentence vectors based 
on some neural network encoders, and then the relationship 
between two sentences was decided solely based on the two 
sentence vectors [Bowman et al., 2015; Yang et al., 2015;
16 Dec 2020 21:06.44 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:06.44 [INFO ] ReferenceMarkerMatcher    -   However, this kind of framework ignores 
the fact that the lower level interactive features between two 
4 [Rao et al., 2016] pointed out that there are two versions of 
TREC-QA dataset: raw-version and clean-version. In this work, 
we utilized the clean-version. Therefore, we only compare with ap-
proaches reporting performance on this dataset. 
5 http://trec.nist.gove/trec eval/ 
[Bowman et al., 2015] Samuel R Bowman, Gabor Angeli, 
Christopher Potts, and Christopher D Manning. A large 
annotated corpus for learning natural language inference. 
arXiv preprint arXiv:1508.05326, 2015. 
[Bromley et al., 1993] Jane Bromley, James W. Bentz, Léon 
Bottou, Isabelle Guyon, Yann LeCun, Cliff Moore, Eduard 
Säckinger, and Roopak Shah. Signature verification using 
a "siamese" time delay neural network. IJPRAI, 7(4):669-
688, 1993. 
[Chen et al., 2016] Qian Chen, Xiaodan Zhu, Zhenhua Ling, 
Si Wei, and Hui Jiang. Enhancing and combining sequen-
tial and tree lstm for natural language inference. arXiv 
preprint arXiv:1609.06038, 2016. 
[Cheng et al., 2016] Jianpeng Cheng, Li Dong, and Mirella 
Lapata. Long short-term memory-networks for machine 
reading. arXiv preprint arXiv:1601.06733, 2016. 
[He and Lin, 2016] Hua He and Jimmy Lin. Pairwise word 
interaction modeling with deep neural networks for se-
mantic similarity measurement. In NAACL, 2016. 
[Heilman and Smith, 2010] Michael Heilman and Noah A 
Smith. Tree edit models for recognizing textual entail-
ments, paraphrases, and answers to questions. In NAACL, 
2010. 
[Hochreiter and Schmidhuber, 1997] Sepp Hochreiter and 
Jürgen Schmidhuber. Long short-term memory. Neural 
computation, 9(8):1735-1780, 1997. 
[Kingma and Ba, 2014] Diederik Kingma and Jimmy Ba. 
Adam: A method for stochastic optimization. arXiv 
preprint arXiv:1412.6980, 2014. 
[LeCun et al., 2015] Yann LeCun, Yoshua Bengio, and Ge-
offrey Hinton. Deep learning. Nature, 521(7553):436-
444, 2015.
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.02 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik and Ba, Jimmy. 
Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014.
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:07.09 [INFO ] ReferenceMarkerMatcher    -   Kingma, Diederik P, Mohamed, Shakir, Rezende, 
Danilo Jimenez, and Welling, Max. Semi-supervised 
learning with deep generative models. In Advances in 
Neural Information Processing Systems, pp. 3581-3589, 
2014.
16 Dec 2020 21:10.36 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 21:10.36 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 21:10.42 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 21:10.42 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Rosasco, L.; and Poggio, T. A. 2016. Holo-
graphic Embeddings of Knowledge Graphs. In Proceedings 
of AAAI, 1955-1961.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Murphy, K.; Tresp, V.; and Gabrilovich, E. 
2016. A review of relational machine learning for knowledge 
graphs. Proceedings of the IEEE 104(1):11-33.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Rosasco, L.; and Poggio, T. A. 2016. Holo-
graphic Embeddings of Knowledge Graphs. In Proceedings 
of AAAI, 1955-1961.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Murphy, K.; Tresp, V.; and Gabrilovich, E. 
2016. A review of relational machine learning for knowledge 
graphs. Proceedings of the IEEE 104(1):11-33.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.27 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Rosasco, L.; and Poggio, T. A. 2016. Holo-
graphic Embeddings of Knowledge Graphs. In Proceedings 
of AAAI, 1955-1961.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Murphy, K.; Tresp, V.; and Gabrilovich, E. 
2016. A review of relational machine learning for knowledge 
graphs. Proceedings of the IEEE 104(1):11-33.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Rosasco, L.; and Poggio, T. A. 2016. Holo-
graphic Embeddings of Knowledge Graphs. In Proceedings 
of AAAI, 1955-1961.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Nickel, M.; Murphy, K.; Tresp, V.; and Gabrilovich, E. 
2016. A review of relational machine learning for knowledge 
graphs. Proceedings of the IEEE 104(1):11-33.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K., and Chen, D. 2015. Observed Versus 
Latent Features for Knowledge Base and Text Inference. In 
Proceedings of the 3rd Workshop on Continuous Vector Space 
Models and their Compositionality, 57-66.
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:20.33 [INFO ] ReferenceMarkerMatcher    -   Toutanova, K.; Chen, D.; Pantel, P.; Poon, H.; Choud-
hury, P.; and Gamon, M. 2015. Representing Text for Joint 
Embedding of Text and Knowledge Bases. In Proceedings of 
EMNLP 2015, volume 15, 1499-1509.
16 Dec 2020 21:21.10 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:21.10 [INFO ] ReferenceMarkerMatcher    -   Dai, A. M. and Le, Q. V. (2015). Semi-supervised sequence learning. In Advances in Neural 
Information Processing Systems, pages 3079-3087.
16 Dec 2020 21:21.10 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:21.10 [INFO ] ReferenceMarkerMatcher    -   Dai, A. M., Olah, C., and Le, Q. V. (2015). Document embedding with paragraph vectors. arXiv 
preprint arXiv:1507.07998.
16 Dec 2020 21:21.16 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:21.16 [INFO ] ReferenceMarkerMatcher    -   Dai, A. M. and Le, Q. V. (2015). Semi-supervised sequence learning. In Advances in Neural 
Information Processing Systems, pages 3079-3087.
16 Dec 2020 21:21.16 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:21.16 [INFO ] ReferenceMarkerMatcher    -   Dai, A. M., Olah, C., and Le, Q. V. (2015). Document embedding with paragraph vectors. arXiv 
preprint arXiv:1507.07998.
16 Dec 2020 21:29.05 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:29.05 [INFO ] ReferenceMarkerMatcher    -   Mobley, D. L., and Guthrie, J. P. 2014. Freesolv: a database 
of experimental and calculated hydration free energies, with 
input files. Journal of computer-aided molecular design 
28(7):711.
16 Dec 2020 21:29.05 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:29.05 [INFO ] ReferenceMarkerMatcher    -   Mobley, D. L.; Wymer, K. L.; Lim, N. M.; and Guthrie, J. P. 
2014. Blind prediction of solvation free energies from the 
sampl4 challenge. J Comput Aided Mol Des 28(3):135-150.
16 Dec 2020 21:29.10 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:29.10 [INFO ] ReferenceMarkerMatcher    -   Mobley, D. L., and Guthrie, J. P. 2014. Freesolv: a database 
of experimental and calculated hydration free energies, with 
input files. Journal of computer-aided molecular design 
28(7):711.
16 Dec 2020 21:29.10 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:29.10 [INFO ] ReferenceMarkerMatcher    -   Mobley, D. L.; Wymer, K. L.; Lim, N. M.; and Guthrie, J. P. 
2014. Blind prediction of solvation free energies from the 
sampl4 challenge. J Comput Aided Mol Des 28(3):135-150.
16 Dec 2020 21:38.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:38.52 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Bethge, M.; Hertzmann, A.; and Shecht-
man, E. 2016. Preserving color in neural artistic style trans-
fer. arXiv preprint arXiv:1606.05897.
16 Dec 2020 21:38.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:38.52 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Ecker, A. S.; and Bethge, M. 2016. Im-
age style transfer using convolutional neural networks. In 
Proceedings of the IEEE Conference on Computer Vision 
and Pattern Recognition, 2414-2423.
16 Dec 2020 21:38.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:38.52 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Bethge, M.; Hertzmann, A.; and Shecht-
man, E. 2016. Preserving color in neural artistic style trans-
fer. arXiv preprint arXiv:1606.05897.
16 Dec 2020 21:38.52 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:38.52 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Ecker, A. S.; and Bethge, M. 2016. Im-
age style transfer using convolutional neural networks. In 
Proceedings of the IEEE Conference on Computer Vision 
and Pattern Recognition, 2414-2423.
16 Dec 2020 21:38.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:38.57 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Bethge, M.; Hertzmann, A.; and Shecht-
man, E. 2016. Preserving color in neural artistic style trans-
fer. arXiv preprint arXiv:1606.05897.
16 Dec 2020 21:38.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:38.57 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Ecker, A. S.; and Bethge, M. 2016. Im-
age style transfer using convolutional neural networks. In 
Proceedings of the IEEE Conference on Computer Vision 
and Pattern Recognition, 2414-2423.
16 Dec 2020 21:38.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:38.57 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Bethge, M.; Hertzmann, A.; and Shecht-
man, E. 2016. Preserving color in neural artistic style trans-
fer. arXiv preprint arXiv:1606.05897.
16 Dec 2020 21:38.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:38.57 [INFO ] ReferenceMarkerMatcher    -   Gatys, L. A.; Ecker, A. S.; and Bethge, M. 2016. Im-
age style transfer using convolutional neural networks. In 
Proceedings of the IEEE Conference on Computer Vision 
and Pattern Recognition, 2414-2423.
16 Dec 2020 21:39.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:39.56 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; and Mei, Q. 2015. Pte: Predictive text em-
bedding through large-scale heterogeneous text networks. In 
KDD, 1165-1174. ACM.
16 Dec 2020 21:39.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:39.56 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, 
Q. 2015. Line: Large-scale information network embed-
ding. In WWW, 1067-1077. International World Wide Web 
Conferences Steering Committee.
16 Dec 2020 21:39.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:39.56 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; and Mei, Q. 2015. Pte: Predictive text em-
bedding through large-scale heterogeneous text networks. In 
KDD, 1165-1174. ACM.
16 Dec 2020 21:39.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:39.56 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, 
Q. 2015. Line: Large-scale information network embed-
ding. In WWW, 1067-1077. International World Wide Web 
Conferences Steering Committee.
16 Dec 2020 21:40.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:40.03 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; and Mei, Q. 2015. Pte: Predictive text em-
bedding through large-scale heterogeneous text networks. In 
KDD, 1165-1174. ACM.
16 Dec 2020 21:40.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:40.03 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, 
Q. 2015. Line: Large-scale information network embed-
ding. In WWW, 1067-1077. International World Wide Web 
Conferences Steering Committee.
16 Dec 2020 21:40.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:40.03 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; and Mei, Q. 2015. Pte: Predictive text em-
bedding through large-scale heterogeneous text networks. In 
KDD, 1165-1174. ACM.
16 Dec 2020 21:40.03 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:40.03 [INFO ] ReferenceMarkerMatcher    -   Tang, J.; Qu, M.; Wang, M.; Zhang, M.; Yan, J.; and Mei, 
Q. 2015. Line: Large-scale information network embed-
ding. In WWW, 1067-1077. International World Wide Web 
Conferences Steering Committee.
16 Dec 2020 21:42.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:42.17 [INFO ] ReferenceMarkerMatcher    -   Paulus, R.; Xiong, C.; and Socher, R. 2017. A deep rein-
forced model for abstractive summarization. arXiv preprint 
arXiv:1705.04304.
16 Dec 2020 21:42.17 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:42.17 [INFO ] ReferenceMarkerMatcher    -   Paulus, Xiong, and Socher (2017) combined reinforcement 
learning and self-attention to capture the long distance de-
pendencies nature of abstractive summarization. Vaswani et 
al. (2017) applied self-attention to neural machine transla-
tion and achieved the state-of-the-art results. Very recently, 
Shen et al. (2017) applied self-attention to language under-
standing task and achieved the state-of-the-art on various 
datasets. Our work follows this line to apply self-attention 
for learning long distance dependencies. Our experiments 
also show the effectiveness of self-attention mechanism on 
the sequence labeling task. 
Conclusion 
We proposed a deep attentional neural network for the task 
of semantic role labeling. We trained our SRL models with a 
depth of 10 and evaluated them on the CoNLL-2005 shared 
task dataset and the CoNLL-2012 shared task dataset. Our 
experimental results indicate that our models substantially 
improve SRL performances, leading to the new state-of-the-
art.
16 Dec 2020 21:42.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:42.24 [INFO ] ReferenceMarkerMatcher    -   Paulus, R.; Xiong, C.; and Socher, R. 2017. A deep rein-
forced model for abstractive summarization. arXiv preprint 
arXiv:1705.04304.
16 Dec 2020 21:42.24 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:42.24 [INFO ] ReferenceMarkerMatcher    -   Paulus, Xiong, and Socher (2017) combined reinforcement 
learning and self-attention to capture the long distance de-
pendencies nature of abstractive summarization. Vaswani et 
al. (2017) applied self-attention to neural machine transla-
tion and achieved the state-of-the-art results. Very recently, 
Shen et al. (2017) applied self-attention to language under-
standing task and achieved the state-of-the-art on various 
datasets. Our work follows this line to apply self-attention 
for learning long distance dependencies. Our experiments 
also show the effectiveness of self-attention mechanism on 
the sequence labeling task. 
Conclusion 
We proposed a deep attentional neural network for the task 
of semantic role labeling. We trained our SRL models with a 
depth of 10 and evaluated them on the CoNLL-2005 shared 
task dataset and the CoNLL-2012 shared task dataset. Our 
experimental results indicate that our models substantially 
improve SRL performances, leading to the new state-of-the-
art.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.53 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:46.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.54 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:46.54 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:46.54 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Li, Z., Zhou, F., Chen, F., and Li, H. Meta-SGD: Learning 
to Learn Quickly for Few Shot Learning, 2017. Preprint 
arXiv:1707.09835.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. M. Learn-
ing to Generalize: Meta-Learning for Domain General-
ization. Proceedings of the AAAI National Conference on 
Artificial Intelligence (AAAI), 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C. and Levine, S. Meta-learning and universal-
ity: Deep representations and gradient descent can 
approximate any learning algorithm, 2017. Preprint 
arXiv:1710.11622.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   Finn, C., Abbeel., P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In Pro-
ceedings of the International Conference on Machine 
Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.00 [INFO ] ReferenceMarkerMatcher    -   C. Finn, P. Abbeel., and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 
In Proceedings of the International Conference on Machine Learning (ICML), Sydney, Australia, 2017.
16 Dec 2020 21:47.42 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.42 [INFO ] ReferenceMarkerMatcher    -   Wang, S., and Jiang, J. 2017. Machine comprehension using 
Match-LSTM and answer pointer. In Proceedings of ICLR.
16 Dec 2020 21:47.42 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.42 [INFO ] ReferenceMarkerMatcher    -   Cui, Y.; Chen, Z.; Wei, S.; Wang, S.; Liu, T.; and Hu, G. 
2017. Attention-over-attention neural networks for reading 
comprehension. In Proceedings of ACL.
16 Dec 2020 21:47.42 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.42 [INFO ] ReferenceMarkerMatcher    -   Wang, W.; Yang, N.; Wei, F.; Chang, B.; and Zhou, M. 2017. 
Gated self-matching networks for reading comprehension 
and question answering. In Proceedings of ACL.
16 Dec 2020 21:47.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.47 [INFO ] ReferenceMarkerMatcher    -   Wang, S., and Jiang, J. 2017. Machine comprehension using 
Match-LSTM and answer pointer. In Proceedings of ICLR.
16 Dec 2020 21:47.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.47 [INFO ] ReferenceMarkerMatcher    -   Cui, Y.; Chen, Z.; Wei, S.; Wang, S.; Liu, T.; and Hu, G. 
2017. Attention-over-attention neural networks for reading 
comprehension. In Proceedings of ACL.
16 Dec 2020 21:47.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 21:47.47 [INFO ] ReferenceMarkerMatcher    -   Wang, W.; Yang, N.; Wei, F.; Chang, B.; and Zhou, M. 2017. 
Gated self-matching networks for reading comprehension 
and question answering. In Proceedings of ACL.
16 Dec 2020 21:56.07 [WARN ] CybozuLanguageDetector    - Cannot detect language because of: com.cybozu.labs.langdetect.LangDetectException: no features in text
16 Dec 2020 21:56.11 [WARN ] CybozuLanguageDetector    - Cannot detect language because of: com.cybozu.labs.langdetect.LangDetectException: no features in text
16 Dec 2020 21:56.17 [WARN ] CybozuLanguageDetector    - Cannot detect language because of: com.cybozu.labs.langdetect.LangDetectException: no features in text
16 Dec 2020 21:56.19 [WARN ] CybozuLanguageDetector    - Cannot detect language because of: com.cybozu.labs.langdetect.LangDetectException: no features in text
16 Dec 2020 22:22.10 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:22.10 [INFO ] ReferenceMarkerMatcher    -   Conneau, A. and D. Kiela 2018, May 7-12. SentEval: An evaluation toolkit for universal 
sentence representations. In N. Calzolari (Ed.), LREC 2018, Eleventh International 
Conference on Language Resources and Evaluation, Phoenix Seagaia Conference Center, 
Miyazaki, Japan, pp. 1699-1704.
16 Dec 2020 22:22.10 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:22.10 [INFO ] ReferenceMarkerMatcher    -   Conneau, A., G. Kruszewski, G. Lample, L. Barrault, and M. Baroni 2018. What you 
can cram into a single vector: Probing sentence embeddings for linguistic properties. In 
ACL.
16 Dec 2020 22:22.16 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:22.16 [INFO ] ReferenceMarkerMatcher    -   Conneau, A. and D. Kiela 2018, May 7-12. SentEval: An evaluation toolkit for universal 
sentence representations. In N. Calzolari (Ed.), LREC 2018, Eleventh International 
Conference on Language Resources and Evaluation, Phoenix Seagaia Conference Center, 
Miyazaki, Japan, pp. 1699-1704.
16 Dec 2020 22:22.16 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:22.16 [INFO ] ReferenceMarkerMatcher    -   Conneau, A., G. Kruszewski, G. Lample, L. Barrault, and M. Baroni 2018. What you 
can cram into a single vector: Probing sentence embeddings for linguistic properties. In 
ACL.
16 Dec 2020 22:25.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:25.47 [INFO ] ReferenceMarkerMatcher    -   Feynman Liang. Bachbot: Automatic composition in the style of bach chorales. Masters thesis, 
University of Cambridge, 2016.
16 Dec 2020 22:25.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:25.47 [INFO ] ReferenceMarkerMatcher    -   Elliot Waite. Generating long-term structure in songs and stories. https://magenta. 
tensorflow.org/2016/07/15/lookback-rnn-attention-rnn, 2016.
16 Dec 2020 22:25.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:25.47 [INFO ] ReferenceMarkerMatcher    -   Gaëtan Hadjeres, Jason Sakellariou, and François Pachet. Style imitation and chord invention in 
polyphonic music with exponential families. arXiv preprint arXiv:1609.05152, 2016.
16 Dec 2020 22:25.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:25.47 [INFO ] ReferenceMarkerMatcher    -   Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention 
model for natural language inference. In Proceedings of the Conference on Empirical Methods in 
Natural Language Processing, 2016.
16 Dec 2020 22:25.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:25.47 [INFO ] ReferenceMarkerMatcher    -   Benigno Uria, Marc-Alexandre Côté, Karol Gregor, Iain Murray, and Hugo Larochelle. Neural 
autoregressive distribution estimation. The Journal of Machine Learning Research, 17(1):7184-
7220, 2016.
16 Dec 2020 22:25.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:25.53 [INFO ] ReferenceMarkerMatcher    -   Feynman Liang. Bachbot: Automatic composition in the style of bach chorales. Masters thesis, 
University of Cambridge, 2016.
16 Dec 2020 22:25.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:25.53 [INFO ] ReferenceMarkerMatcher    -   Elliot Waite. Generating long-term structure in songs and stories. https://magenta. 
tensorflow.org/2016/07/15/lookback-rnn-attention-rnn, 2016.
16 Dec 2020 22:25.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:25.53 [INFO ] ReferenceMarkerMatcher    -   Gaëtan Hadjeres, Jason Sakellariou, and François Pachet. Style imitation and chord invention in 
polyphonic music with exponential families. arXiv preprint arXiv:1609.05152, 2016.
16 Dec 2020 22:25.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:25.53 [INFO ] ReferenceMarkerMatcher    -   Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention 
model for natural language inference. In Proceedings of the Conference on Empirical Methods in 
Natural Language Processing, 2016.
16 Dec 2020 22:25.53 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:25.53 [INFO ] ReferenceMarkerMatcher    -   Benigno Uria, Marc-Alexandre Côté, Karol Gregor, Iain Murray, and Hugo Larochelle. Neural 
autoregressive distribution estimation. The Journal of Machine Learning Research, 17(1):7184-
7220, 2016.
16 Dec 2020 22:27.19 [ERROR] FullTextParser            - DocumentPointer for block 46 points to 296 token, but block token size is 243
16 Dec 2020 22:27.22 [ERROR] FullTextParser            - DocumentPointer for block 46 points to 296 token, but block token size is 243
16 Dec 2020 22:27.23 [ERROR] FullTextParser            - DocumentPointer for block 46 points to 296 token, but block token size is 243
16 Dec 2020 22:32.01 [ERROR] FullTextParser            - DocumentPointer for block 327 points to 43 token, but block token size is 37
16 Dec 2020 22:32.09 [ERROR] FullTextParser            - DocumentPointer for block 327 points to 43 token, but block token size is 37
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    -   [Seo et al. 2016] Seo, M.; Kembhavi, A.; Farhadi, A.; and 
Hajishirzi, H. 2016. Bidirectional attention flow for ma-
chine comprehension. arXiv preprint arXiv:1611.01603. 
[Shen et al. 2016] Shen, Y.; Huang, P.-S.; Gao, J.; and Chen, 
W. 2016. Reasonet: Learning to stop reading in machine 
comprehension. arXiv preprint arXiv:1609.05284. 
[Srivastava et al. 2014] Srivastava, N.; Hinton, G. E.; 
Krizhevsky, A.; Sutskever, I.; and Salakhutdinov, R.
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    -   [Huang et al. 2017] Huang, H.; Zhu, C.; Shen, Y.; and Chen, 
W. 
2017. 
Fusionnet: Fusing via fully-aware atten-
tion with application to machine comprehension. CoRR 
abs/1711.07341. 
[Huang, Liu, and Weinberger 2016] Huang, G.; Liu, Z.; and 
Weinberger, K. Q. 2016. Densely connected convolutional 
networks. CoRR abs/1608.06993. 
[Kingma and Ba 2014] Kingma, D. P., and Ba, J. 2014. 
Adam: A method for stochastic optimization. 
CoRR 
abs/1412.6980. 
[Kumar et al. 2015] Kumar, A.; Irsoy, O.; Su, J.; Bradbury, 
J.; English, R.; Pierce, B.; Ondruska, P.; Gulrajani, I.; and 
Socher, R. 2015. Ask me anything: Dynamic memory 
networks for natural language processing. arXiv preprint 
arXiv:1506.07285. 
[Lee et al. 2016] Lee, K.; Kwiatkowski, T.; Parikh, A. P.; and 
Das, D. 2016. Learning recurrent span representations for 
extractive question answering. CoRR abs/1611.01436. 
[Levy et al. 2017] Levy, O.; Seo, M.; Choi, E.; and Zettle-
moyer, L. 2017. Zero-shot relation extraction via reading 
comprehension. arXiv preprint arXiv:1706.04115. 
[Liu et al. 2017] Liu, X.; Shen, Y.; Duh, K.; and Gao, J. 
2017. Stochastic answer networks for machine reading com-
prehension. CoRR abs/1712.03556. 
[Pennington, Socher, and Manning 2014] Pennington, 
J.;
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    -   Vinyals, Fortunato, and Jaitly 2015] Vinyals, O.; Fortunato, 
M.; and Jaitly, N. 2015. Pointer Networks. ArXiv e-prints. 
[Wang and Jiang 2016] Wang, S., and Jiang, J. 2016. Ma-
chine comprehension using match-lstm and answer pointer. 
CoRR abs/1608.07905. 
[Wang et al. 2017] Wang, W.; Yang, N.; Wei, F.; Chang, B.; 
and Zhou, M. 2017. Gated self-matching networks for read-
ing comprehension and question answering. In Proceedings 
of the 55th Annual Meeting of the Association for Computa-
tional Linguistics, ACL 2017, Vancouver, Canada, July 30 -
August 4, Volume 1: Long Papers, 189-198.
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    -   [Huang et al. 2017] Huang, H.; Zhu, C.; Shen, Y.; and Chen, 
W. 
2017. 
Fusionnet: Fusing via fully-aware atten-
tion with application to machine comprehension. CoRR 
abs/1711.07341. 
[Huang, Liu, and Weinberger 2016] Huang, G.; Liu, Z.; and 
Weinberger, K. Q. 2016. Densely connected convolutional 
networks. CoRR abs/1608.06993. 
[Kingma and Ba 2014] Kingma, D. P., and Ba, J. 2014. 
Adam: A method for stochastic optimization. 
CoRR 
abs/1412.6980. 
[Kumar et al. 2015] Kumar, A.; Irsoy, O.; Su, J.; Bradbury, 
J.; English, R.; Pierce, B.; Ondruska, P.; Gulrajani, I.; and 
Socher, R. 2015. Ask me anything: Dynamic memory 
networks for natural language processing. arXiv preprint 
arXiv:1506.07285. 
[Lee et al. 2016] Lee, K.; Kwiatkowski, T.; Parikh, A. P.; and 
Das, D. 2016. Learning recurrent span representations for 
extractive question answering. CoRR abs/1611.01436. 
[Levy et al. 2017] Levy, O.; Seo, M.; Choi, E.; and Zettle-
moyer, L. 2017. Zero-shot relation extraction via reading 
comprehension. arXiv preprint arXiv:1706.04115. 
[Liu et al. 2017] Liu, X.; Shen, Y.; Duh, K.; and Gao, J. 
2017. Stochastic answer networks for machine reading com-
prehension. CoRR abs/1712.03556. 
[Pennington, Socher, and Manning 2014] Pennington, 
J.;
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    -   [Hu et al. 2017] Hu, M.; Peng, Y.; Huang, Z.; Qiu, X.; 
Wei, F.; and Zhou, M. 2017. Reinforced mnemonic 
reader for machine reading comprehension. arXiv preprint 
arXiv:1705.02798. 
[Hu et al. 2018] Hu, M.; Peng, Y.; Huang, Z.; Yang, N.; 
Zhou, M.; et al. 2018. Read+ verify: Machine reading 
comprehension with unanswerable questions. arXiv preprint 
arXiv:1808.05759.
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    -   [Chen et al. 2017] Chen, D.; Fisch, A.; Weston, J.; and Bor-
des, A. 2017. Reading wikipedia to answer open-domain 
questions. CoRR abs/1704.00051. 
[Clark and Gardner 2017] Clark, C., and Gardner, M. 2017. 
Simple and effective multi-paragraph reading comprehen-
sion. arXiv preprint arXiv:1710.10723. 
[Cui et al. 2016] Cui, Y.; Chen, Z.; Wei, S.; Wang, S.; Liu, 
T.; and Hu, G. 2016. Attention-over-attention neu-
ral networks for reading comprehension. arXiv preprint 
arXiv:1607.04423. 
[Dhingra et al. 2016] Dhingra, B.; Liu, H.; Cohen, W. W.; 
and Salakhutdinov, R. 2016. Gated-attention readers for 
text comprehension. arXiv preprint arXiv:1606.01549. 
[Hermann et al. 2015] Hermann, K. M.; Kocisky, T.; Grefen-
stette, E.; Espeholt, L.; Kay, W.; Suleyman, M.; and Blun-
som, P. 2015. Teaching machines to read and compre-
hend. In Advances in Neural Information Processing Sys-
tems, 1684-1692.
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    -   [Sukhbaatar et al. 2015] Sukhbaatar, S.; Weston, J.; Fergus, 
R.; et al. 2015. End-to-end memory networks. In Advances 
in Neural Information Processing Systems, 2431-2439. 
[Tan et al. 2018] Tan, C.; Wei, F.; Zhou, Q.; Yang, N.; Lv, 
W.; and Zhou, M. 2018. I know there is no answer: Model-
ing answer validation for machine reading comprehension. 
In CCF International Conference on Natural Language Pro-
cessing and Chinese Computing, 85-97. Springer. 
[Vaswani et al. 2017] Vaswani, A.; Shazeer, N.; Parmar, N.; 
Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and 
Polosukhin, I. 2017. Attention is all you need. CoRR 
abs/1706.03762.
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    -   , Yan, and Wu 2018] Wang, W.; Yan, M.; and Wu, C. 
2018. Multi-granularity hierarchical attention fusion net-
works for reading comprehension and question answering. 
In Proceedings of the 56th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long Papers), 
volume 1, 1705-1714.
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    -   [Peters et al. 2018] Peters, M. E.; Neumann, M.; Iyyer, M.; 
Gardner, M.; Clark, C.; Lee, K.; and Zettlemoyer, L. 2018. 
Deep contextualized word representations. In Proc. of 
NAACL. 
[Rajpurkar et al. 2016] Rajpurkar, P.; Zhang, J.; Lopyrev, 
K.; and Liang, P. 
2016. 
SQuAD: 100,000+ ques-
tions for machine comprehension of text. arXiv preprint 
arXiv:1606.05250. 
[Rajpurkar, Jia, and Liang 2018] Rajpurkar, P.; Jia, R.; and 
Liang, P. 2018. Know What You Don't Know: Unanswer-
able Questions for SQuAD. ArXiv e-prints.
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    -   [Hu et al. 2017] Hu, M.; Peng, Y.; Huang, Z.; Qiu, X.; 
Wei, F.; and Zhou, M. 2017. Reinforced mnemonic 
reader for machine reading comprehension. arXiv preprint 
arXiv:1705.02798. 
[Hu et al. 2018] Hu, M.; Peng, Y.; Huang, Z.; Yang, N.; 
Zhou, M.; et al. 2018. Read+ verify: Machine reading 
comprehension with unanswerable questions. arXiv preprint 
arXiv:1808.05759.
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.50 [INFO ] ReferenceMarkerMatcher    -   [Sukhbaatar et al. 2015] Sukhbaatar, S.; Weston, J.; Fergus, 
R.; et al. 2015. End-to-end memory networks. In Advances 
in Neural Information Processing Systems, 2431-2439. 
[Tan et al. 2018] Tan, C.; Wei, F.; Zhou, Q.; Yang, N.; Lv, 
W.; and Zhou, M. 2018. I know there is no answer: Model-
ing answer validation for machine reading comprehension. 
In CCF International Conference on Natural Language Pro-
cessing and Chinese Computing, 85-97. Springer. 
[Vaswani et al. 2017] Vaswani, A.; Shazeer, N.; Parmar, N.; 
Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and 
Polosukhin, I. 2017. Attention is all you need. CoRR 
abs/1706.03762.
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    -   [Seo et al. 2016] Seo, M.; Kembhavi, A.; Farhadi, A.; and 
Hajishirzi, H. 2016. Bidirectional attention flow for ma-
chine comprehension. arXiv preprint arXiv:1611.01603. 
[Shen et al. 2016] Shen, Y.; Huang, P.-S.; Gao, J.; and Chen, 
W. 2016. Reasonet: Learning to stop reading in machine 
comprehension. arXiv preprint arXiv:1609.05284. 
[Srivastava et al. 2014] Srivastava, N.; Hinton, G. E.; 
Krizhevsky, A.; Sutskever, I.; and Salakhutdinov, R.
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    -   [Huang et al. 2017] Huang, H.; Zhu, C.; Shen, Y.; and Chen, 
W. 
2017. 
Fusionnet: Fusing via fully-aware atten-
tion with application to machine comprehension. CoRR 
abs/1711.07341. 
[Huang, Liu, and Weinberger 2016] Huang, G.; Liu, Z.; and 
Weinberger, K. Q. 2016. Densely connected convolutional 
networks. CoRR abs/1608.06993. 
[Kingma and Ba 2014] Kingma, D. P., and Ba, J. 2014. 
Adam: A method for stochastic optimization. 
CoRR 
abs/1412.6980. 
[Kumar et al. 2015] Kumar, A.; Irsoy, O.; Su, J.; Bradbury, 
J.; English, R.; Pierce, B.; Ondruska, P.; Gulrajani, I.; and 
Socher, R. 2015. Ask me anything: Dynamic memory 
networks for natural language processing. arXiv preprint 
arXiv:1506.07285. 
[Lee et al. 2016] Lee, K.; Kwiatkowski, T.; Parikh, A. P.; and 
Das, D. 2016. Learning recurrent span representations for 
extractive question answering. CoRR abs/1611.01436. 
[Levy et al. 2017] Levy, O.; Seo, M.; Choi, E.; and Zettle-
moyer, L. 2017. Zero-shot relation extraction via reading 
comprehension. arXiv preprint arXiv:1706.04115. 
[Liu et al. 2017] Liu, X.; Shen, Y.; Duh, K.; and Gao, J. 
2017. Stochastic answer networks for machine reading com-
prehension. CoRR abs/1712.03556. 
[Pennington, Socher, and Manning 2014] Pennington, 
J.;
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    -   Vinyals, Fortunato, and Jaitly 2015] Vinyals, O.; Fortunato, 
M.; and Jaitly, N. 2015. Pointer Networks. ArXiv e-prints. 
[Wang and Jiang 2016] Wang, S., and Jiang, J. 2016. Ma-
chine comprehension using match-lstm and answer pointer. 
CoRR abs/1608.07905. 
[Wang et al. 2017] Wang, W.; Yang, N.; Wei, F.; Chang, B.; 
and Zhou, M. 2017. Gated self-matching networks for read-
ing comprehension and question answering. In Proceedings 
of the 55th Annual Meeting of the Association for Computa-
tional Linguistics, ACL 2017, Vancouver, Canada, July 30 -
August 4, Volume 1: Long Papers, 189-198.
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    -   [Huang et al. 2017] Huang, H.; Zhu, C.; Shen, Y.; and Chen, 
W. 
2017. 
Fusionnet: Fusing via fully-aware atten-
tion with application to machine comprehension. CoRR 
abs/1711.07341. 
[Huang, Liu, and Weinberger 2016] Huang, G.; Liu, Z.; and 
Weinberger, K. Q. 2016. Densely connected convolutional 
networks. CoRR abs/1608.06993. 
[Kingma and Ba 2014] Kingma, D. P., and Ba, J. 2014. 
Adam: A method for stochastic optimization. 
CoRR 
abs/1412.6980. 
[Kumar et al. 2015] Kumar, A.; Irsoy, O.; Su, J.; Bradbury, 
J.; English, R.; Pierce, B.; Ondruska, P.; Gulrajani, I.; and 
Socher, R. 2015. Ask me anything: Dynamic memory 
networks for natural language processing. arXiv preprint 
arXiv:1506.07285. 
[Lee et al. 2016] Lee, K.; Kwiatkowski, T.; Parikh, A. P.; and 
Das, D. 2016. Learning recurrent span representations for 
extractive question answering. CoRR abs/1611.01436. 
[Levy et al. 2017] Levy, O.; Seo, M.; Choi, E.; and Zettle-
moyer, L. 2017. Zero-shot relation extraction via reading 
comprehension. arXiv preprint arXiv:1706.04115. 
[Liu et al. 2017] Liu, X.; Shen, Y.; Duh, K.; and Gao, J. 
2017. Stochastic answer networks for machine reading com-
prehension. CoRR abs/1712.03556. 
[Pennington, Socher, and Manning 2014] Pennington, 
J.;
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    -   [Hu et al. 2017] Hu, M.; Peng, Y.; Huang, Z.; Qiu, X.; 
Wei, F.; and Zhou, M. 2017. Reinforced mnemonic 
reader for machine reading comprehension. arXiv preprint 
arXiv:1705.02798. 
[Hu et al. 2018] Hu, M.; Peng, Y.; Huang, Z.; Yang, N.; 
Zhou, M.; et al. 2018. Read+ verify: Machine reading 
comprehension with unanswerable questions. arXiv preprint 
arXiv:1808.05759.
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    -   [Chen et al. 2017] Chen, D.; Fisch, A.; Weston, J.; and Bor-
des, A. 2017. Reading wikipedia to answer open-domain 
questions. CoRR abs/1704.00051. 
[Clark and Gardner 2017] Clark, C., and Gardner, M. 2017. 
Simple and effective multi-paragraph reading comprehen-
sion. arXiv preprint arXiv:1710.10723. 
[Cui et al. 2016] Cui, Y.; Chen, Z.; Wei, S.; Wang, S.; Liu, 
T.; and Hu, G. 2016. Attention-over-attention neu-
ral networks for reading comprehension. arXiv preprint 
arXiv:1607.04423. 
[Dhingra et al. 2016] Dhingra, B.; Liu, H.; Cohen, W. W.; 
and Salakhutdinov, R. 2016. Gated-attention readers for 
text comprehension. arXiv preprint arXiv:1606.01549. 
[Hermann et al. 2015] Hermann, K. M.; Kocisky, T.; Grefen-
stette, E.; Espeholt, L.; Kay, W.; Suleyman, M.; and Blun-
som, P. 2015. Teaching machines to read and compre-
hend. In Advances in Neural Information Processing Sys-
tems, 1684-1692.
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    -   [Sukhbaatar et al. 2015] Sukhbaatar, S.; Weston, J.; Fergus, 
R.; et al. 2015. End-to-end memory networks. In Advances 
in Neural Information Processing Systems, 2431-2439. 
[Tan et al. 2018] Tan, C.; Wei, F.; Zhou, Q.; Yang, N.; Lv, 
W.; and Zhou, M. 2018. I know there is no answer: Model-
ing answer validation for machine reading comprehension. 
In CCF International Conference on Natural Language Pro-
cessing and Chinese Computing, 85-97. Springer. 
[Vaswani et al. 2017] Vaswani, A.; Shazeer, N.; Parmar, N.; 
Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and 
Polosukhin, I. 2017. Attention is all you need. CoRR 
abs/1706.03762.
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    -   , Yan, and Wu 2018] Wang, W.; Yan, M.; and Wu, C. 
2018. Multi-granularity hierarchical attention fusion net-
works for reading comprehension and question answering. 
In Proceedings of the 56th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long Papers), 
volume 1, 1705-1714.
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    -   [Peters et al. 2018] Peters, M. E.; Neumann, M.; Iyyer, M.; 
Gardner, M.; Clark, C.; Lee, K.; and Zettlemoyer, L. 2018. 
Deep contextualized word representations. In Proc. of 
NAACL. 
[Rajpurkar et al. 2016] Rajpurkar, P.; Zhang, J.; Lopyrev, 
K.; and Liang, P. 
2016. 
SQuAD: 100,000+ ques-
tions for machine comprehension of text. arXiv preprint 
arXiv:1606.05250. 
[Rajpurkar, Jia, and Liang 2018] Rajpurkar, P.; Jia, R.; and 
Liang, P. 2018. Know What You Don't Know: Unanswer-
able Questions for SQuAD. ArXiv e-prints.
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    -   [Hu et al. 2017] Hu, M.; Peng, Y.; Huang, Z.; Qiu, X.; 
Wei, F.; and Zhou, M. 2017. Reinforced mnemonic 
reader for machine reading comprehension. arXiv preprint 
arXiv:1705.02798. 
[Hu et al. 2018] Hu, M.; Peng, Y.; Huang, Z.; Yang, N.; 
Zhou, M.; et al. 2018. Read+ verify: Machine reading 
comprehension with unanswerable questions. arXiv preprint 
arXiv:1808.05759.
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:33.56 [INFO ] ReferenceMarkerMatcher    -   [Sukhbaatar et al. 2015] Sukhbaatar, S.; Weston, J.; Fergus, 
R.; et al. 2015. End-to-end memory networks. In Advances 
in Neural Information Processing Systems, 2431-2439. 
[Tan et al. 2018] Tan, C.; Wei, F.; Zhou, Q.; Yang, N.; Lv, 
W.; and Zhou, M. 2018. I know there is no answer: Model-
ing answer validation for machine reading comprehension. 
In CCF International Conference on Natural Language Pro-
cessing and Chinese Computing, 85-97. Springer. 
[Vaswani et al. 2017] Vaswani, A.; Shazeer, N.; Parmar, N.; 
Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and 
Polosukhin, I. 2017. Attention is all you need. CoRR 
abs/1706.03762.
16 Dec 2020 22:40.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:40.33 [INFO ] ReferenceMarkerMatcher    -   Wang, H., and Wang, L. 2017. Modeling temporal dynamics and 
spatial configurations of actions using two-stream recurrent neural 
networks. In e Conference on Computer Vision and Pa ern Recog-
nition (CVPR).
16 Dec 2020 22:40.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:40.33 [INFO ] ReferenceMarkerMatcher    -   Wang, H.; Wang, P.; Song, Z.; and Li, W. 2017. Large-scale multi-
modal gesture recognition using heterogeneous networks. In Pro-
ceedings of the IEEE Conference on Computer Vision and Pattern 
Recognition, 3129-3137.
16 Dec 2020 22:40.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:40.33 [INFO ] ReferenceMarkerMatcher    -   Yang, W.; Jin, L.; and Liu, M. 2015. Chinese character-level 
writer identification using path signature feature, dropstroke and 
deep cnn. In Document Analysis and Recognition (ICDAR), 2015 
13th International Conference on, 546-550. IEEE.
16 Dec 2020 22:40.33 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:40.33 [INFO ] ReferenceMarkerMatcher    -   Yang, W.; Jin, L.; Xie, Z.; and Feng, Z. 2015. Improved deep 
convolutional neural network for online handwritten chinese char-
acter recognition using domain-specific knowledge. arXiv preprint 
arXiv:1505.07675.
16 Dec 2020 22:40.40 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:40.40 [INFO ] ReferenceMarkerMatcher    -   Wang, H., and Wang, L. 2017. Modeling temporal dynamics and 
spatial configurations of actions using two-stream recurrent neural 
networks. In e Conference on Computer Vision and Pa ern Recog-
nition (CVPR).
16 Dec 2020 22:40.40 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:40.40 [INFO ] ReferenceMarkerMatcher    -   Wang, H.; Wang, P.; Song, Z.; and Li, W. 2017. Large-scale multi-
modal gesture recognition using heterogeneous networks. In Pro-
ceedings of the IEEE Conference on Computer Vision and Pattern 
Recognition, 3129-3137.
16 Dec 2020 22:40.40 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:40.40 [INFO ] ReferenceMarkerMatcher    -   Yang, W.; Jin, L.; and Liu, M. 2015. Chinese character-level 
writer identification using path signature feature, dropstroke and 
deep cnn. In Document Analysis and Recognition (ICDAR), 2015 
13th International Conference on, 546-550. IEEE.
16 Dec 2020 22:40.40 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:40.40 [INFO ] ReferenceMarkerMatcher    -   Yang, W.; Jin, L.; Xie, Z.; and Feng, Z. 2015. Improved deep 
convolutional neural network for online handwritten chinese char-
acter recognition using domain-specific knowledge. arXiv preprint 
arXiv:1505.07675.
16 Dec 2020 22:44.49 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:44.49 [INFO ] ReferenceMarkerMatcher    -   Zheng, Z.; Zheng, L.; and Yang, Y. 2016. Pedestrian 
alignment network for large-scale person re-identification. 
arXiv:1707.00408.
16 Dec 2020 22:44.49 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:44.49 [INFO ] ReferenceMarkerMatcher    -   Zheng, L.; Bie, Z.; Sun, Y.; Wang, J.; Su, C.; Wang, S.; and 
Tian, Q. 2016. Mars: A video benchmark for large-scale 
person re-identification. In ECCV.
16 Dec 2020 22:44.55 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:44.55 [INFO ] ReferenceMarkerMatcher    -   Zheng, Z.; Zheng, L.; and Yang, Y. 2016. Pedestrian 
alignment network for large-scale person re-identification. 
arXiv:1707.00408.
16 Dec 2020 22:44.55 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:44.55 [INFO ] ReferenceMarkerMatcher    -   Zheng, L.; Bie, Z.; Sun, Y.; Wang, J.; Su, C.; Wang, S.; and 
Tian, Q. 2016. Mars: A video benchmark for large-scale 
person re-identification. In ECCV.
16 Dec 2020 22:46.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:46.43 [INFO ] ReferenceMarkerMatcher    -   Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., Xu, B.: Joint Extraction of Entities and 
Relations Based on a Novel Tagging Scheme. In: Proceedings of the 55th Annual Meeting 
of the Association for Computational Linguistics (Volume 1: Long Papers). pp. 1227-1236 
(2017)
16 Dec 2020 22:46.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:46.43 [INFO ] ReferenceMarkerMatcher    -   Zheng, S., Hao, Y., Lu, D., Bao, H., Xu, J., Hao, H., Xu, B.: Joint entity and relation extrac-
tion based on a hybrid neural network. Neurocomputing 257, 59-66 (2017)
16 Dec 2020 22:46.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:46.43 [INFO ] ReferenceMarkerMatcher    -   Bekoulis, G., Deleu, J., Demeester, T., Develder, C.: Adversarial training for multi-context 
joint entity and relation extraction. In: Proceedings of the 2018 Conference on Empirical 
Methods in Natural Language Processing. pp. 2830-2836 (2018)
16 Dec 2020 22:46.43 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:46.43 [INFO ] ReferenceMarkerMatcher    -   Bekoulis, G., Deleu, J., Demeester, T., Develder, C.: Joint entity recognition and relation 
extraction as a multi-head selection problem. Expert Systems with Applications 114, 34 -45 
(2018)
16 Dec 2020 22:46.48 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:46.48 [INFO ] ReferenceMarkerMatcher    -   Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., Xu, B.: Joint Extraction of Entities and 
Relations Based on a Novel Tagging Scheme. In: Proceedings of the 55th Annual Meeting 
of the Association for Computational Linguistics (Volume 1: Long Papers). pp. 1227-1236 
(2017)
16 Dec 2020 22:46.48 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:46.48 [INFO ] ReferenceMarkerMatcher    -   Zheng, S., Hao, Y., Lu, D., Bao, H., Xu, J., Hao, H., Xu, B.: Joint entity and relation extrac-
tion based on a hybrid neural network. Neurocomputing 257, 59-66 (2017)
16 Dec 2020 22:46.48 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:46.48 [INFO ] ReferenceMarkerMatcher    -   Bekoulis, G., Deleu, J., Demeester, T., Develder, C.: Adversarial training for multi-context 
joint entity and relation extraction. In: Proceedings of the 2018 Conference on Empirical 
Methods in Natural Language Processing. pp. 2830-2836 (2018)
16 Dec 2020 22:46.48 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:46.48 [INFO ] ReferenceMarkerMatcher    -   Bekoulis, G., Deleu, J., Demeester, T., Develder, C.: Joint entity recognition and relation 
extraction as a multi-head selection problem. Expert Systems with Applications 114, 34 -45 
(2018)
16 Dec 2020 22:48.41 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:48.41 [INFO ] ReferenceMarkerMatcher    -   Chen, Q.; Ling, Z.; and Zhu, X. 2018. Enhancing sentence 
embedding with generalized pooling. In Proceedings of the 
27th International Conference on Computational Linguis-
tics, COLING 2018, 1815-1826.
16 Dec 2020 22:48.41 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:48.41 [INFO ] ReferenceMarkerMatcher    -   Chen, Q.; Zhu, X.; Ling, Z.; Inkpen, D.; and Wei, S. 2018. 
Neural natural language inference models enhanced with ex-
ternal knowledge. In Proceedings of the 56th Annual Meet-
ing of the Association for Computational Linguistics, ACL 
2018, 2406-2417.
16 Dec 2020 22:48.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:48.46 [INFO ] ReferenceMarkerMatcher    -   Chen, Q.; Ling, Z.; and Zhu, X. 2018. Enhancing sentence 
embedding with generalized pooling. In Proceedings of the 
27th International Conference on Computational Linguis-
tics, COLING 2018, 1815-1826.
16 Dec 2020 22:48.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:48.46 [INFO ] ReferenceMarkerMatcher    -   Chen, Q.; Zhu, X.; Ling, Z.; Inkpen, D.; and Wei, S. 2018. 
Neural natural language inference models enhanced with ex-
ternal knowledge. In Proceedings of the 56th Annual Meet-
ing of the Association for Computational Linguistics, ACL 
2018, 2406-2417.
16 Dec 2020 22:49.25 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:49.25 [INFO ] ReferenceMarkerMatcher    -   Zhao, H.; Chen, W.; and Kit, C. 2009. Semantic de-
pendency parsing of NomBank and PropBank: An efficient 
integrated approach via a large-scale feature selection. In 
EMNLP.
16 Dec 2020 22:49.25 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:49.25 [INFO ] ReferenceMarkerMatcher    -   Zhao, H.; Chen, W.; Kazama, J.; Uchimoto, K.; and 
Torisawa, K. 2009. Multilingual dependency learning: Ex-
ploiting rich features for tagging syntactic and semantic de-
pendencies. In CoNLL.
16 Dec 2020 22:49.25 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:49.25 [INFO ] ReferenceMarkerMatcher    -   Marcheggiani, D., and Titov, I. 2017. Encoding sen-
tences with graph convolutional networks for semantic role 
labeling. In EMNLP.
16 Dec 2020 22:49.25 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:49.25 [INFO ] ReferenceMarkerMatcher    -   Marcheggiani, D.; Frolov, A.; and Titov, I. 2017. 
A simple and accurate syntax-agnostic neural model for 
dependency-based semantic role labeling. In CoNLL.
16 Dec 2020 22:49.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:49.31 [INFO ] ReferenceMarkerMatcher    -   Zhao, H.; Chen, W.; and Kit, C. 2009. Semantic de-
pendency parsing of NomBank and PropBank: An efficient 
integrated approach via a large-scale feature selection. In 
EMNLP.
16 Dec 2020 22:49.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:49.31 [INFO ] ReferenceMarkerMatcher    -   Zhao, H.; Chen, W.; Kazama, J.; Uchimoto, K.; and 
Torisawa, K. 2009. Multilingual dependency learning: Ex-
ploiting rich features for tagging syntactic and semantic de-
pendencies. In CoNLL.
16 Dec 2020 22:49.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:49.31 [INFO ] ReferenceMarkerMatcher    -   Marcheggiani, D., and Titov, I. 2017. Encoding sen-
tences with graph convolutional networks for semantic role 
labeling. In EMNLP.
16 Dec 2020 22:49.31 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:49.31 [INFO ] ReferenceMarkerMatcher    -   Marcheggiani, D.; Frolov, A.; and Titov, I. 2017. 
A simple and accurate syntax-agnostic neural model for 
dependency-based semantic role labeling. In CoNLL.
16 Dec 2020 22:52.41 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:52.41 [INFO ] ReferenceMarkerMatcher    -   Kiros, R.; Salakhutdinov, R.; and Zemel, R. S. 2015. Uni-
fying visual-semantic embeddings with multimodal neural 
language models. TACL.
16 Dec 2020 22:52.41 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:52.41 [INFO ] ReferenceMarkerMatcher    -   Kiros, R.; Zhu, Y.; Salakhutdinov, R.; Zemel, R. S.; Torralba, 
A.; Urtasun, R.; and Fidler, S. 2015. Skip-thought vectors. 
In NIPS.
16 Dec 2020 22:52.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:52.47 [INFO ] ReferenceMarkerMatcher    -   Kiros, R.; Salakhutdinov, R.; and Zemel, R. S. 2015. Uni-
fying visual-semantic embeddings with multimodal neural 
language models. TACL.
16 Dec 2020 22:52.47 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 22:52.47 [INFO ] ReferenceMarkerMatcher    -   Kiros, R.; Zhu, Y.; Salakhutdinov, R.; Zemel, R. S.; Torralba, 
A.; Urtasun, R.; and Fidler, S. 2015. Skip-thought vectors. 
In NIPS.
16 Dec 2020 22:59.15 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 22:59.15 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 22:59.15 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 22:59.15 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 22:59.19 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 22:59.19 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 22:59.19 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 22:59.19 [INFO ] PDF2XMLAnnotationSaxHandler - the link annotation type is not recognized: GoToR
16 Dec 2020 23:10.08 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:10.08 [INFO ] ReferenceMarkerMatcher    -   Yao, K.-L. and Li, W.-J. Convolutional geometric matrix 
completion. arXiv preprint arXiv:1803.00754, 2018.
16 Dec 2020 23:10.08 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:10.08 [INFO ] ReferenceMarkerMatcher    -   Yao, L., Mao, C., and Luo, Y. Graph convolutional networks 
for text classification. arXiv preprint arXiv:1809.05679, 
2018.
16 Dec 2020 23:10.15 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:10.15 [INFO ] ReferenceMarkerMatcher    -   Yao, K.-L. and Li, W.-J. Convolutional geometric matrix 
completion. arXiv preprint arXiv:1803.00754, 2018.
16 Dec 2020 23:10.15 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:10.15 [INFO ] ReferenceMarkerMatcher    -   Yao, L., Mao, C., and Luo, Y. Graph convolutional networks 
for text classification. arXiv preprint arXiv:1809.05679, 
2018.
16 Dec 2020 23:17.18 [ERROR] FullTextParser            - DocumentPointer for block 83 points to 137 token, but block token size is 125
16 Dec 2020 23:17.25 [ERROR] FullTextParser            - DocumentPointer for block 83 points to 137 token, but block token size is 125
16 Dec 2020 23:17.28 [ERROR] FullTextParser            - DocumentPointer for block 83 points to 137 token, but block token size is 125
16 Dec 2020 23:25.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:25.46 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2300 0.243 4.27 44.1 53.2 
323 0.279 19.8 37.6 44.1
16 Dec 2020 23:25.46 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:25.46 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2100 0.401 34.4 47.2 50.1 
6.8 0.309 0.9 64.3 84.1
16 Dec 2020 23:25.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:25.51 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2300 0.243 4.27 44.1 53.2 
323 0.279 19.8 37.6 44.1
16 Dec 2020 23:25.51 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:25.51 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2100 0.401 34.4 47.2 50.1 
6.8 0.309 0.9 64.3 84.1
16 Dec 2020 23:25.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:25.57 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2300 0.243 4.27 44.1 53.2 
323 0.279 19.8 37.6 44.1
16 Dec 2020 23:25.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:25.57 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2100 0.401 34.4 47.2 50.1 
6.8 0.309 0.9 64.3 84.1
16 Dec 2020 23:26.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:26.02 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2300 0.243 4.27 44.1 53.2 
323 0.279 19.8 37.6 44.1
16 Dec 2020 23:26.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:26.02 [INFO ] ReferenceMarkerMatcher    -   TransE (Bordes et al., 2013) 
2100 0.401 34.4 47.2 50.1 
6.8 0.309 0.9 64.3 84.1
16 Dec 2020 23:34.06 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:34.06 [INFO ] ReferenceMarkerMatcher    -   Frankle, J. and Carbin, M. (2019). The lottery ticket hypothesis: Finding sparse, trainable neural 
networks. In ICLR 2019.
16 Dec 2020 23:34.06 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:34.06 [INFO ] ReferenceMarkerMatcher    -   Frankle, J., Dziugaite, G. K., Roy, D. M., and Carbin, M. (2019). The lottery ticket hypothesis at 
scale. CoRR, abs/1903.01611.
16 Dec 2020 23:34.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:34.12 [INFO ] ReferenceMarkerMatcher    -   Frankle, J. and Carbin, M. (2019). The lottery ticket hypothesis: Finding sparse, trainable neural 
networks. In ICLR 2019.
16 Dec 2020 23:34.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:34.12 [INFO ] ReferenceMarkerMatcher    -   Frankle, J., Dziugaite, G. K., Roy, D. M., and Carbin, M. (2019). The lottery ticket hypothesis at 
scale. CoRR, abs/1903.01611.
16 Dec 2020 23:40.15 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:40.15 [INFO ] ReferenceMarkerMatcher    -   [Ding et al., 2018] B. Ding, Q. Wang, B. Wang, and L. Guo. 
Improving knowledge graph embedding using simple con-
straints. In ACL, 2018.
16 Dec 2020 23:40.15 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:40.15 [INFO ] ReferenceMarkerMatcher    -   References 
[Akrami et al., 2018] F. Akrami, L. Guo, W. Hu, and C. Li. 
Re-evaluating embedding-based knowledge graph com-
pletion methods. In ACM-CIKM, 2018. 
[Bordes et al., 2013] A. Bordes, N. Usunier, A. Garcia-
Duran, J. Weston, and O. Yakhnenko. Translating embed-
dings for modeling multi-relational data. In NIPS, 2013. 
[Demeester et al., 2016] T. Demeester, T. Rocktäschel, and 
S. Riedel. Lifted rule injection for relation embeddings. 
arXiv:1606.08359, 2016. 
[Dettmers et al., 2018] T. Dettmers, P. Minervini, P. Stene-
torp, and S. Riedel. Convolutional 2d knowledge graph 
embeddings. In AAAI, 2018. 
[Ding et al., 2018] B. Ding, Q. Wang, B. Wang, and L. Guo. 
Improving knowledge graph embedding using simple con-
straints. In ACL, 2018. 
[Dong et al., 2014] X. Dong, E. Gabrilovich, G. Heitz, 
W. Horn, Ni Lao, K. Murphy, T. Strohmann, S. Sun, and 
W. Zhang. Knowledge vault: A web-scale approach to 
probabilistic knowledge fusion. In ACM-SIGKDD, 2014. 
[Guan et al., 2018] S. Guan, X. Jin, Y. Wang, and X. Cheng. 
Shared embedding based neural networks for knowledge 
graph completion. In 27th ACM-CIKM, 2018. 
[Guo et al., 2016] S. Guo, Q. Wang, L. Wang, B. Wang, and 
Li Guo. Jointly embedding knowledge graphs and logical 
rules. In EMNLP, 2016. 
[Guo et al., 2018] S. Guo, Q. Wang, L. Wang, B. Wang, and 
Li Guo. Knowledge graph embedding with iterative guid-
ance from soft rules. In AAAI, 2018. 
[Guu et al., 2015] K. Guu, J. Miller, and P. Liang. Traversing 
knowledge graphs in vector space. In EMNLP, 2015. 
[Han et al., 2018] X. Han, C. Zhang, T. Sun, Y. Ji, and Z. Hu. 
A triple-branch neural network for knowledge graph em-
bedding. IEEE Access, 6, 2018. 
[Huang et al., 2000] G.B Huang, Y.Q Chen, and H.A Babri. 
Classification ability of single hidden layer feedforward 
neural networks. IEEE TNN, 11(3), 2000. 
[Kazemi and Poole, 2018] S.M Kazemi and D. Poole. Sim-
ple embedding for link prediction in knowledge graphs. 
arXiv:1802.04868, 2018.
16 Dec 2020 23:40.21 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:40.21 [INFO ] ReferenceMarkerMatcher    -   [Ding et al., 2018] B. Ding, Q. Wang, B. Wang, and L. Guo. 
Improving knowledge graph embedding using simple con-
straints. In ACL, 2018.
16 Dec 2020 23:40.21 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:40.21 [INFO ] ReferenceMarkerMatcher    -   References 
[Akrami et al., 2018] F. Akrami, L. Guo, W. Hu, and C. Li. 
Re-evaluating embedding-based knowledge graph com-
pletion methods. In ACM-CIKM, 2018. 
[Bordes et al., 2013] A. Bordes, N. Usunier, A. Garcia-
Duran, J. Weston, and O. Yakhnenko. Translating embed-
dings for modeling multi-relational data. In NIPS, 2013. 
[Demeester et al., 2016] T. Demeester, T. Rocktäschel, and 
S. Riedel. Lifted rule injection for relation embeddings. 
arXiv:1606.08359, 2016. 
[Dettmers et al., 2018] T. Dettmers, P. Minervini, P. Stene-
torp, and S. Riedel. Convolutional 2d knowledge graph 
embeddings. In AAAI, 2018. 
[Ding et al., 2018] B. Ding, Q. Wang, B. Wang, and L. Guo. 
Improving knowledge graph embedding using simple con-
straints. In ACL, 2018. 
[Dong et al., 2014] X. Dong, E. Gabrilovich, G. Heitz, 
W. Horn, Ni Lao, K. Murphy, T. Strohmann, S. Sun, and 
W. Zhang. Knowledge vault: A web-scale approach to 
probabilistic knowledge fusion. In ACM-SIGKDD, 2014. 
[Guan et al., 2018] S. Guan, X. Jin, Y. Wang, and X. Cheng. 
Shared embedding based neural networks for knowledge 
graph completion. In 27th ACM-CIKM, 2018. 
[Guo et al., 2016] S. Guo, Q. Wang, L. Wang, B. Wang, and 
Li Guo. Jointly embedding knowledge graphs and logical 
rules. In EMNLP, 2016. 
[Guo et al., 2018] S. Guo, Q. Wang, L. Wang, B. Wang, and 
Li Guo. Knowledge graph embedding with iterative guid-
ance from soft rules. In AAAI, 2018. 
[Guu et al., 2015] K. Guu, J. Miller, and P. Liang. Traversing 
knowledge graphs in vector space. In EMNLP, 2015. 
[Han et al., 2018] X. Han, C. Zhang, T. Sun, Y. Ji, and Z. Hu. 
A triple-branch neural network for knowledge graph em-
bedding. IEEE Access, 6, 2018. 
[Huang et al., 2000] G.B Huang, Y.Q Chen, and H.A Babri. 
Classification ability of single hidden layer feedforward 
neural networks. IEEE TNN, 11(3), 2000. 
[Kazemi and Poole, 2018] S.M Kazemi and D. Poole. Sim-
ple embedding for link prediction in knowledge graphs. 
arXiv:1802.04868, 2018.
16 Dec 2020 23:46.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:46.57 [INFO ] ReferenceMarkerMatcher    -   Xie, R.; Liu, Z.; and Sun, M. 2016. Representation learn-
ing of knowledge graphs with hierarchical types. In IJCAI, 
2965-2971.
16 Dec 2020 23:46.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:46.57 [INFO ] ReferenceMarkerMatcher    -   Xie, R.; Liu, Z.; Jia, J.; Luan, H.; and Sun, M. 2016. Repre-
sentation learning of knowledge graphs with entity descrip-
tions. In AAAI.
16 Dec 2020 23:46.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:46.57 [INFO ] ReferenceMarkerMatcher    -   Xie, R.; Liu, Z.; and Sun, M. 2016. Representation learn-
ing of knowledge graphs with hierarchical types. In IJCAI, 
2965-2971.
16 Dec 2020 23:46.57 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:46.57 [INFO ] ReferenceMarkerMatcher    -   Xie, R.; Liu, Z.; Jia, J.; Luan, H.; and Sun, M. 2016. Repre-
sentation learning of knowledge graphs with entity descrip-
tions. In AAAI.
16 Dec 2020 23:47.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:47.02 [INFO ] ReferenceMarkerMatcher    -   Xie, R.; Liu, Z.; and Sun, M. 2016. Representation learn-
ing of knowledge graphs with hierarchical types. In IJCAI, 
2965-2971.
16 Dec 2020 23:47.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:47.02 [INFO ] ReferenceMarkerMatcher    -   Xie, R.; Liu, Z.; Jia, J.; Luan, H.; and Sun, M. 2016. Repre-
sentation learning of knowledge graphs with entity descrip-
tions. In AAAI.
16 Dec 2020 23:47.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:47.02 [INFO ] ReferenceMarkerMatcher    -   Xie, R.; Liu, Z.; and Sun, M. 2016. Representation learn-
ing of knowledge graphs with hierarchical types. In IJCAI, 
2965-2971.
16 Dec 2020 23:47.02 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:47.02 [INFO ] ReferenceMarkerMatcher    -   Xie, R.; Liu, Z.; Jia, J.; Luan, H.; and Sun, M. 2016. Repre-
sentation learning of knowledge graphs with entity descrip-
tions. In AAAI.
16 Dec 2020 23:50.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:50.27 [INFO ] ReferenceMarkerMatcher    -   Adam Kilgarriff. 2001. English lex-
ical sample task description. In Proceedings of 
SENSEVAL-2 Second International Workshop on 
Evaluating Word Sense Disambiguation Systems, 
pages 17-20, Toulouse, France.
16 Dec 2020 23:50.27 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:50.27 [INFO ] ReferenceMarkerMatcher    -   [Devlin et al.2019] Jacob Devlin, Ming-Wei Chang, 
Kenton Lee, and Kristina Toutanova. 2019. BERT: 
Pre-training of deep bidirectional transformers for 
language understanding. In Proceedings of the 
2019 Conference of the North American Chapter 
of the Association for Computational Linguistics: 
Human Language Technologies, pages 4171-4186, 
Minneapolis, MN, USA. 
[Mihalcea et al.2004] Rada 
Mihalcea, 
Timothy 
Chklovski, and Adam Kilgarriff. 2004. The 
senseval-3 English lexical sample task. In Pro-
ceedings of SENSEVAL-3, the Third International 
Workshop on the Evaluation of Systems for the 
Semantic Analysis of Text, pages 25-28, Barcelona, 
Spain. 
[Edmonds and Cotton2001] Philip Edmonds and Scott 
Cotton. 2001. SENSEVAL-2: Overview. In 
Proceedings of SENSEVAL-2: Second International 
Workshop on Evaluating Word Sense Disambigua-
tion Systems, pages 1-5, Toulouse, France. 
[Mikolov et al.2013] Tomas Mikolov, Kai Chen, Greg 
Corrado, and Jeffrey Dean. 2013. Efficient esti-
mation of word representations in vector space. In 
Yoshua Bengio and Yann LeCun, editors, 1st Inter-
national Conference on Learning Representations, 
ICLR 2013, Scottsdale, AZ, USA.
16 Dec 2020 23:50.32 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:50.32 [INFO ] ReferenceMarkerMatcher    -   Adam Kilgarriff. 2001. English lex-
ical sample task description. In Proceedings of 
SENSEVAL-2 Second International Workshop on 
Evaluating Word Sense Disambiguation Systems, 
pages 17-20, Toulouse, France.
16 Dec 2020 23:50.32 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:50.32 [INFO ] ReferenceMarkerMatcher    -   [Devlin et al.2019] Jacob Devlin, Ming-Wei Chang, 
Kenton Lee, and Kristina Toutanova. 2019. BERT: 
Pre-training of deep bidirectional transformers for 
language understanding. In Proceedings of the 
2019 Conference of the North American Chapter 
of the Association for Computational Linguistics: 
Human Language Technologies, pages 4171-4186, 
Minneapolis, MN, USA. 
[Mihalcea et al.2004] Rada 
Mihalcea, 
Timothy 
Chklovski, and Adam Kilgarriff. 2004. The 
senseval-3 English lexical sample task. In Pro-
ceedings of SENSEVAL-3, the Third International 
Workshop on the Evaluation of Systems for the 
Semantic Analysis of Text, pages 25-28, Barcelona, 
Spain. 
[Edmonds and Cotton2001] Philip Edmonds and Scott 
Cotton. 2001. SENSEVAL-2: Overview. In 
Proceedings of SENSEVAL-2: Second International 
Workshop on Evaluating Word Sense Disambigua-
tion Systems, pages 1-5, Toulouse, France. 
[Mikolov et al.2013] Tomas Mikolov, Kai Chen, Greg 
Corrado, and Jeffrey Dean. 2013. Efficient esti-
mation of word representations in vector space. In 
Yoshua Bengio and Yann LeCun, editors, 1st Inter-
national Conference on Learning Representations, 
ICLR 2013, Scottsdale, AZ, USA.
16 Dec 2020 23:51.22 [ERROR] FullTextParser            - DocumentPointer for block 68 points to 194 token, but block token size is 178
16 Dec 2020 23:51.30 [ERROR] FullTextParser            - DocumentPointer for block 68 points to 194 token, but block token size is 178
16 Dec 2020 23:51.34 [ERROR] FullTextParser            - DocumentPointer for block 68 points to 194 token, but block token size is 178
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    -   SQuAD SQuAD is an extractive question answering dataset built from Wikipedia. The answers 
are segments from the context paragraphs and the task is to predict answer spans. We evaluate our 
models on two versions of SQuAD: v1.1 and v2.0. SQuAD v1.1 has 100,000 human-annotated 
question/answer pairs. SQuAD v2.0 additionally introduced 50,000 unanswerable questions. For 
SQuAD v1.1, we use the same training procedure as BERT, whereas for SQuAD v2.0, models are 
jointly trained with a span extraction loss and an additional classifier for predicting answerabil-
ity (Yang et al., 2019; Liu et al., 2019). We report both development set and test set performance.
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    -   RACE RACE is a large-scale dataset for multi-choice reading comprehension, collected from En-
glish examinations in China with nearly 100,000 questions. Each instance in RACE has 4 candidate 
answers. Following prior work (Yang et al., 2019; Liu et al., 2019), we use the concatenation of the 
passage, question, and each candidate answer as the input to models. Then, we use the represen-
tations from the "[CLS]" token for predicting the probability of each answer. The dataset consists 
of two domains: middle school and high school. We train our models on both domains and report 
accuracies on both the development set and test set.
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    -   Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. Deep equilibrium models. In Neural Information 
Processing Systems (NeurIPS), 2019.
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    -   Allen Nie, Erin Bennett, and Noah Goodman. DisSent: Learning sentence representations from ex-
plicit discourse relations. In Proceedings of the 57th Annual Meeting of the Association for Com-
putational Linguistics, pp. 4497-4510, Florence, Italy, July 2019. Association for Computational 
Linguistics. doi: 10.18653/v1/P19-1442. URL https://www.aclweb.org/anthology/ 
P19-1442.
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    -   Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. Generating long sequences with sparse 
transformers. arXiv preprint arXiv:1904.10509, 2019.
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    -   Kevin Clark, Minh-Thang Luong, Urvashi Khandelwal, Christopher D Manning, and Quoc V 
Le. Bam! born-again multi-task networks for natural language understanding. arXiv preprint 
arXiv:1907.04829, 2019.
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    -   Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep 
bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of 
the North American Chapter of the Association for Computational Linguistics: Human Language 
Technologies, Volume 1 (Long and Short Papers), pp. 4171-4186, Minneapolis, Minnesota, June 
2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https: 
//www.aclweb.org/anthology/N19-1423.
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    -   Linyuan Gong, Di He, Zhuohan Li, Tao Qin, Liwei Wang, and Tieyan Liu. Efficient training of bert 
by progressively stacking. In International Conference on Machine Learning, pp. 2337-2346, 
2019.
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    -   Jie Hao, Xing Wang, Baosong Yang, Longyue Wang, Jinfeng Zhang, and Zhaopeng Tu. Modeling 
recurrence for transformer. Proceedings of the 2019 Conference of the North, 2019. doi: 10. 
18653/v1/n19-1122. URL http://dx.doi.org/10.18653/v1/n19-1122.
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.04 [INFO ] ReferenceMarkerMatcher    -   Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S Weld, Luke Zettlemoyer, and Omer Levy. 
SpanBERT: Improving pre-training by representing and predicting spans. arXiv preprint 
arXiv:1907.10529, 2019.
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    -   SQuAD SQuAD is an extractive question answering dataset built from Wikipedia. The answers 
are segments from the context paragraphs and the task is to predict answer spans. We evaluate our 
models on two versions of SQuAD: v1.1 and v2.0. SQuAD v1.1 has 100,000 human-annotated 
question/answer pairs. SQuAD v2.0 additionally introduced 50,000 unanswerable questions. For 
SQuAD v1.1, we use the same training procedure as BERT, whereas for SQuAD v2.0, models are 
jointly trained with a span extraction loss and an additional classifier for predicting answerabil-
ity (Yang et al., 2019; Liu et al., 2019). We report both development set and test set performance.
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    -   RACE RACE is a large-scale dataset for multi-choice reading comprehension, collected from En-
glish examinations in China with nearly 100,000 questions. Each instance in RACE has 4 candidate 
answers. Following prior work (Yang et al., 2019; Liu et al., 2019), we use the concatenation of the 
passage, question, and each candidate answer as the input to models. Then, we use the represen-
tations from the "[CLS]" token for predicting the probability of each answer. The dataset consists 
of two domains: middle school and high school. We train our models on both domains and report 
accuracies on both the development set and test set.
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    -   Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. Deep equilibrium models. In Neural Information 
Processing Systems (NeurIPS), 2019.
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    -   Allen Nie, Erin Bennett, and Noah Goodman. DisSent: Learning sentence representations from ex-
plicit discourse relations. In Proceedings of the 57th Annual Meeting of the Association for Com-
putational Linguistics, pp. 4497-4510, Florence, Italy, July 2019. Association for Computational 
Linguistics. doi: 10.18653/v1/P19-1442. URL https://www.aclweb.org/anthology/ 
P19-1442.
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    -   Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. Generating long sequences with sparse 
transformers. arXiv preprint arXiv:1904.10509, 2019.
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    -   Kevin Clark, Minh-Thang Luong, Urvashi Khandelwal, Christopher D Manning, and Quoc V 
Le. Bam! born-again multi-task networks for natural language understanding. arXiv preprint 
arXiv:1907.04829, 2019.
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    -   Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep 
bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of 
the North American Chapter of the Association for Computational Linguistics: Human Language 
Technologies, Volume 1 (Long and Short Papers), pp. 4171-4186, Minneapolis, Minnesota, June 
2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https: 
//www.aclweb.org/anthology/N19-1423.
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    -   Linyuan Gong, Di He, Zhuohan Li, Tao Qin, Liwei Wang, and Tieyan Liu. Efficient training of bert 
by progressively stacking. In International Conference on Machine Learning, pp. 2337-2346, 
2019.
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    -   Jie Hao, Xing Wang, Baosong Yang, Longyue Wang, Jinfeng Zhang, and Zhaopeng Tu. Modeling 
recurrence for transformer. Proceedings of the 2019 Conference of the North, 2019. doi: 10. 
18653/v1/n19-1122. URL http://dx.doi.org/10.18653/v1/n19-1122.
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    - +++++
16 Dec 2020 23:52.12 [INFO ] ReferenceMarkerMatcher    -   Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S Weld, Luke Zettlemoyer, and Omer Levy. 
SpanBERT: Improving pre-training by representing and predicting spans. arXiv preprint 
arXiv:1907.10529, 2019.
